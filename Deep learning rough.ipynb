{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x1 = np.array([0, 0])\n",
    "x2 = np.array([0, 1])\n",
    "x3 = np.array([1, 0])\n",
    "\n",
    "# x4 = np.array([0, 1])\n",
    "# x5 = np.array([1, 0])\n",
    "# x6 = np.array([1, 1])\n",
    "\n",
    "x = np.array([x1, x2, x3])\n",
    "wt = [0,0,1]\n",
    "eo =[0,1,1]\n",
    "co = []\n",
    "c = [0,0,0]\n",
    "a = 0\n",
    "n = -1\n",
    "m = 0\n",
    "\n",
    "#pre-processing array\n",
    "x1 = np.append(x1, 1)\n",
    "x2 = np.append(x2, 1)\n",
    "x3 = np.append(x3, 1)\n",
    "# x4 = np.append(x4, 1)\n",
    "# x5 = np.append(x5, 1)\n",
    "# x6 = np.append(x6, 1)\n",
    "x = np.array([x1, x2, x3])\n",
    "\n",
    "#while loop\n",
    "while(n < 0):\n",
    "    if (co == eo):\n",
    "        n = 1\n",
    "    for i in range(len(eo)):\n",
    "        c[i] = np.dot(x[i], wt)\n",
    "        #print(c[i])\n",
    "        if (c[i] > 0):\n",
    "            co.append(1)\n",
    "        else:\n",
    "            co.append(-1)\n",
    "    print(co)\n",
    "    if (co == eo):\n",
    "        n = 1\n",
    "    else:\n",
    "        for i in range(6):\n",
    "            if eo[i] != co[i]:\n",
    "                print(i)\n",
    "                a = i\n",
    "                break\n",
    "    wt = wt + (eo[a] * x[a])\n",
    "    co = []\n",
    "    m = m + 1\n",
    "\n",
    "print(\"Total Iterations : \", m)   \n",
    "print(\"final Weight is : \", wt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a230f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter weight 1: 2\n",
      "Enter weight 2: 3\n",
      "[[0, 0], [0, 1], [1, 1]]\n",
      "Efficiency: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "w1=int(input(\"Enter weight 1: \"))\n",
    "w2=int(input(\"Enter weight 2: \"))\n",
    "#bias=int(input(\"Enter bias: \"))\n",
    "w=[w1,w2]\n",
    "coord=[[0,0],[0,1],[1,1]]\n",
    "print(coord)\n",
    "xorgate=[0,1,1]\n",
    "\n",
    "eff=0\n",
    "i=0\n",
    "for r in coord:\n",
    "    z=(np.dot(r,w))\n",
    "    if z>0:\n",
    "        out=1\n",
    "    else:\n",
    "        out=0\n",
    "    if out==xorgate[i]:\n",
    "        eff=eff+1\n",
    "    i=i+1\n",
    "per=(eff/3)*100\n",
    "print(\"Efficiency:\",per,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "861ab9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter weight 1: -2\n",
      "Enter weight 2: -3\n",
      "Enter bias: 4\n",
      "[[0, 1], [1, 0], [1, 1]]\n",
      "Efficiency: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "w1=int(input(\"Enter weight 1: \"))\n",
    "w2=int(input(\"Enter weight 2: \"))\n",
    "bias=int(input(\"Enter bias: \"))\n",
    "w=[w1,w2]\n",
    "coord=[[0,1],[1,0],[1,1]]\n",
    "print(coord)\n",
    "xorgate=[1,1,0]\n",
    "\n",
    "eff=0\n",
    "i=0\n",
    "for r in coord:\n",
    "    z=(np.dot(r,w)+bias)\n",
    "    if z>0:\n",
    "        out=1\n",
    "    else:\n",
    "        out=0\n",
    "    if out==xorgate[i]:\n",
    "        eff=eff+1\n",
    "    i=i+1\n",
    "per=(eff/3)*100\n",
    "print(\"Efficiency:\",per,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9f6508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.12.0 in c:\\users\\91960\\appdata\\roaming\\python\\python39\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\91960\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.24.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (16.0.6)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.22.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\91960\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\91960\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\91960\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.14)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.57.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (61.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.1.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (23.5.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (21.3)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\91960\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.37.1)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.7.3)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\91960\\appdata\\roaming\\python\\python39\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.7.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.2.2)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.26.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\91960\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install --user tensorflow==2.12.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1604e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\91960\\appdata\\roaming\\python\\python39\\site-packages (2.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a9b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflearn in c:\\users\\91960\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tflearn) (1.22.4)\n",
      "Requirement already satisfied: six in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tflearn) (1.16.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\91960\\anaconda3\\lib\\site-packages (from tflearn) (9.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tflearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19c2e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "from tflearn import DNN\n",
    "from tflearn.layers.core import input_data,dropout,fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5378634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: BB53RQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.120s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.62383\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 002 | loss: 0.62383 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.68054\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 003 | loss: 0.68054 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.69000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 004 | loss: 0.69000 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.69218\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 005 | loss: 0.69218 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.69280\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 006 | loss: 0.69280 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.69301\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 007 | loss: 0.69301 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 008 | loss: 0.69309 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 009 | loss: 0.69312 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 010 | loss: 0.69313 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 011 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 012 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 013 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 014 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 015 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 016 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 017 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 018 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 019 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 020 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 021 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 022 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 023 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 024 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 025 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 026 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 027 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 028 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 029 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 030 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 031 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 032 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 033 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 034 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 035 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 036 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 037 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 038 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 039 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 040 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 041 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 042 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 043 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 044 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 045 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 046 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 047 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 048 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 049 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 050 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 051 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 052 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 053 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 054 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 055 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 056 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 057 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 058 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 059 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 060 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 061 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 062 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 063 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 064 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 065 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 066 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 067 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 068 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 069 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 070 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 071 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 072 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 073 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 074 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 075 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 076 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 077 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 078 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 079 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 080 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 081 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 082 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 083 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 084 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 085 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 086 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 087 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 088 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 089 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 090 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 091 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 092 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 093 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 094 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 095 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 096 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 097 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 098 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 099 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 100 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 101 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 102 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 103 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 104 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 105 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 106 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 107 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 108 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 109 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 110 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 111 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 112 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 113 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 114 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 115 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 116 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 117 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 118 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 119 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 120 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 121 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 122 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 123 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 124 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 125 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 126 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 127 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 128 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 129 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 130 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 131 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 132 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 133 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 134 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 135 | loss: 0.69315 - binary_acc: 0.5250 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 136 | loss: 0.69315 - binary_acc: 0.5225 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 137 | loss: 0.69315 - binary_acc: 0.5202 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 138 | loss: 0.69315 - binary_acc: 0.5182 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 139 | loss: 0.69315 - binary_acc: 0.5164 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 140 | loss: 0.69315 - binary_acc: 0.5148 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 141 | loss: 0.69315 - binary_acc: 0.5133 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 142 | loss: 0.69315 - binary_acc: 0.5120 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 143 | loss: 0.69315 - binary_acc: 0.5108 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 144 | loss: 0.69315 - binary_acc: 0.5097 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 145 | loss: 0.69315 - binary_acc: 0.5087 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 146 | loss: 0.69315 - binary_acc: 0.5078 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 147 | loss: 0.69315 - binary_acc: 0.5071 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 148 | loss: 0.69315 - binary_acc: 0.5064 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 149 | loss: 0.69315 - binary_acc: 0.5057 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 150 | loss: 0.69315 - binary_acc: 0.5051 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 151 | loss: 0.69315 - binary_acc: 0.5046 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 152 | loss: 0.69315 - binary_acc: 0.5042 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 153 | loss: 0.69315 - binary_acc: 0.5038 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 154 | loss: 0.69315 - binary_acc: 0.5034 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 155 | loss: 0.69315 - binary_acc: 0.5030 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 156 | loss: 0.69315 - binary_acc: 0.5027 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 157 | loss: 0.69315 - binary_acc: 0.5025 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 158 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 159 | loss: 0.69315 - binary_acc: 0.5020 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 160 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 161 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 162 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 163 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 164 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 165 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 166 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 167 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 168 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 169 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 170 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 171 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 172 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 173 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 174 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 175 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 176 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 177 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 178 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 179 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 180 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 181 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 182 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 183 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 184 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 185 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 186 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 187 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 188 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 189 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 190 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 191 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 192 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 193 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 194 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 195 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 196 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 197 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 198 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 199 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 200 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 201 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 202 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 203 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 204 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 205 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 206 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 207 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 208 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 209 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 210 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 211 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 212 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 213 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 214 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 215 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 216 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 217 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 218 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 219 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 220 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 221 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 222 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 223 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 224 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 225 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 226 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 227 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 228 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 229 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 230 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 231 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 232 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 233 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 234 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 235 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 236 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 237 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 238 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 239 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 240 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 241 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 242 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 243 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 244 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 245 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 246 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 247 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 248 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 249 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 250 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 251 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 252 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 253 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 254 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 255 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 256 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 257 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 258 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 259 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 260 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 261 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 262 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 263 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 264 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 265 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 266 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 267 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 268 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 269 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 270 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 271 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 272 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 273 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 274 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 275 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 276 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 277 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 278 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 279 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 280 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 281 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 282 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 283 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 284 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 285 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 286 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 287 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 288 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 289 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 290 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 291 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 292 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 293 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 294 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 295 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 296 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 297 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 298 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 299 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 300 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 301 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 302 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 303 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 304 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 305 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 306 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 307 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 308 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 309 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 310 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 311 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 312 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 313 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 314 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 315 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 316 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 317 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 318 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 319 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 320 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 321 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 322 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 323 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 324 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 325 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 326 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 327 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 328 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 329 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 330 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 331 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 332 | loss: 0.69319 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 333 | loss: 0.69319 - binary_acc: 0.4550 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 334 | loss: 0.69318 - binary_acc: 0.4845 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 335 | loss: 0.69318 - binary_acc: 0.4861 -- iter: 4/4\n",
      "--\n",
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 336 | loss: 0.69318 - binary_acc: 0.4874 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 337 | loss: 0.69317 - binary_acc: 0.4887 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 338 | loss: 0.69317 - binary_acc: 0.4898 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 339 | loss: 0.69317 - binary_acc: 0.4908 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 340 | loss: 0.69317 - binary_acc: 0.4918 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 341 | loss: 0.69316 - binary_acc: 0.4926 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 342 | loss: 0.69316 - binary_acc: 0.4933 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 343 | loss: 0.69316 - binary_acc: 0.4940 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 344 | loss: 0.69316 - binary_acc: 0.4946 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 345 | loss: 0.69316 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 346 | loss: 0.69316 - binary_acc: 0.4956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 347 | loss: 0.69316 - binary_acc: 0.4961 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 348 | loss: 0.69316 - binary_acc: 0.4965 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 349 | loss: 0.69315 - binary_acc: 0.4968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 350 | loss: 0.69315 - binary_acc: 0.4971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 351 | loss: 0.69315 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 352 | loss: 0.69315 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 353 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 354 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 355 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 356 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 357 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 358 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 359 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 360 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 361 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 362 | loss: 0.69314 - binary_acc: 0.5492 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 363 | loss: 0.69314 - binary_acc: 0.5443 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 364 | loss: 0.69314 - binary_acc: 0.5398 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 365 | loss: 0.69314 - binary_acc: 0.5359 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 366 | loss: 0.69314 - binary_acc: 0.5323 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 367 | loss: 0.69314 - binary_acc: 0.5290 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 368 | loss: 0.69314 - binary_acc: 0.5261 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 369 | loss: 0.69314 - binary_acc: 0.5235 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 370 | loss: 0.69314 - binary_acc: 0.5212 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 371 | loss: 0.69314 - binary_acc: 0.5191 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 372 | loss: 0.69314 - binary_acc: 0.5172 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 373 | loss: 0.69314 - binary_acc: 0.5154 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 374 | loss: 0.69314 - binary_acc: 0.5139 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 375 | loss: 0.69314 - binary_acc: 0.5125 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 376 | loss: 0.69314 - binary_acc: 0.5113 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 377 | loss: 0.69315 - binary_acc: 0.5101 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 378 | loss: 0.69315 - binary_acc: 0.5091 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 379 | loss: 0.69315 - binary_acc: 0.5082 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 380 | loss: 0.69315 - binary_acc: 0.5074 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 381 | loss: 0.69315 - binary_acc: 0.5066 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 382 | loss: 0.69315 - binary_acc: 0.5060 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 383 | loss: 0.69315 - binary_acc: 0.5054 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 384 | loss: 0.69315 - binary_acc: 0.5048 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 385 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 386 | loss: 0.69315 - binary_acc: 0.5039 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 387 | loss: 0.69315 - binary_acc: 0.5035 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 388 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 389 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 390 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 391 | loss: 0.69315 - binary_acc: 0.5023 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 392 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 393 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 394 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 395 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 396 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 397 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 398 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 399 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 400 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 401 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 402 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 403 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 404 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 405 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 406 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 407 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 408 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 409 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 410 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 411 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 412 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 413 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 414 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 415 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 416 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 417 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 418 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 419 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 420 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 421 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 422 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 423 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 424 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 425 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 426 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 427 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 428 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 429 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 430 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 431 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 432 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 433 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 434 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 435 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 436 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 437 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 438 | loss: 0.69313 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 439 | loss: 0.69313 - binary_acc: 0.4750 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 440 | loss: 0.69314 - binary_acc: 0.4775 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 441 | loss: 0.69314 - binary_acc: 0.4798 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 442 | loss: 0.69314 - binary_acc: 0.4818 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 443 | loss: 0.69314 - binary_acc: 0.4836 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 444 | loss: 0.69314 - binary_acc: 0.4852 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 445 | loss: 0.69314 - binary_acc: 0.4867 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 446 | loss: 0.69314 - binary_acc: 0.4880 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 447 | loss: 0.69314 - binary_acc: 0.4892 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 448 | loss: 0.69314 - binary_acc: 0.4903 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 449 | loss: 0.69314 - binary_acc: 0.4913 -- iter: 4/4\n",
      "--\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 450 | loss: 0.69314 - binary_acc: 0.4922 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 451 | loss: 0.69314 - binary_acc: 0.4929 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 452 | loss: 0.69314 - binary_acc: 0.4936 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 453 | loss: 0.69315 - binary_acc: 0.4943 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 454 | loss: 0.69315 - binary_acc: 0.4949 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 455 | loss: 0.69315 - binary_acc: 0.4954 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 456 | loss: 0.69315 - binary_acc: 0.4958 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 457 | loss: 0.69315 - binary_acc: 0.4962 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 458 | loss: 0.69315 - binary_acc: 0.4966 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 459 | loss: 0.69315 - binary_acc: 0.4970 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 460 | loss: 0.69315 - binary_acc: 0.4973 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 461 | loss: 0.69315 - binary_acc: 0.4975 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 462 | loss: 0.69315 - binary_acc: 0.4978 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 463 | loss: 0.69315 - binary_acc: 0.4980 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 464 | loss: 0.69315 - binary_acc: 0.4982 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 465 | loss: 0.69315 - binary_acc: 0.4984 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 466 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 467 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 468 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 469 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 470 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 471 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 472 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 473 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 474 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 475 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 476 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 477 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 478 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 479 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 480 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 481 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 482 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 483 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 484 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 485 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 486 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 487 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 488 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 489 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 490 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 491 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 492 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 493 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 494 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 495 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 496 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 497 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 498 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 499 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.69308\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 500 | loss: 0.69308 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Expected:  [False, True, True, False]\n",
      "Predicted:  [True, True, False, False]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'net_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;124m\"\u001b[39m,[i[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m Y])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted: \u001b[39m\u001b[38;5;124m\"\u001b[39m,[i[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(X)])\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of network inputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mnet_inputs\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "X=[[0,0],[0,1],[1,0],[1,1]]\n",
    "Y=[[0],[1],[1],[0]]\n",
    "input_layer=input_data(shape=[None,2])\n",
    "hidden_layer=fully_connected(input_layer,2,activation='tanh')\n",
    "output_layer=fully_connected(hidden_layer,1,activation='tanh')\n",
    "regression=regression(output_layer,optimizer='sgd',loss='binary_crossentropy',learning_rate=5)\n",
    "model=DNN(regression)\n",
    "model.fit(X,Y,n_epoch=500,show_metric=True)\n",
    "print(\"Expected: \",[i[0]>0 for i in Y])\n",
    "print(\"Predicted: \",[i[0]>0 for i in model.predict(X)])\n",
    "print(\"Number of network inputs:\", len(net_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c66bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\91960\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: MNFRK9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.140s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.62383\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 002 | loss: 0.62383 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.68054\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 003 | loss: 0.68054 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.69000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 004 | loss: 0.69000 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.69218\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 005 | loss: 0.69218 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.69280\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 006 | loss: 0.69280 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.69301\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 007 | loss: 0.69301 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 008 | loss: 0.69309 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 009 | loss: 0.69312 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 010 | loss: 0.69313 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 011 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 012 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 013 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 014 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 015 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 016 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 017 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 018 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 019 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 020 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 021 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 022 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 023 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 024 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 025 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 026 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 027 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 028 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 029 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 030 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 031 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 032 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 033 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 034 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 035 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 036 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 037 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 038 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 039 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 040 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 041 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 042 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 043 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 044 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 045 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 046 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 047 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 048 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 049 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 050 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 051 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 052 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 053 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 054 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 055 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 056 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 057 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 058 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 059 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 060 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 061 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 062 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 063 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 064 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 065 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 066 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 067 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 068 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 069 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 070 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 071 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 072 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 073 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 074 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 075 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 076 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 077 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 078 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 079 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 080 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 081 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 082 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 083 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 084 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 085 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 086 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 087 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 088 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 089 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 090 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 091 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 092 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 093 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 094 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 095 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 096 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 097 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 098 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 099 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 100 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 101 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 102 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 103 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 104 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 105 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 106 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 107 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 108 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 109 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 110 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 111 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 112 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 113 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 114 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 115 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 116 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 117 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 118 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 119 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 120 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 121 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 122 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 123 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 124 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 125 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 126 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 127 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 128 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 129 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 130 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 131 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 132 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 133 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 134 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 135 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 136 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 137 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 138 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 139 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 140 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 141 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 142 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 143 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 144 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 145 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 146 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 147 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 148 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 149 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 150 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 151 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 152 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 153 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 154 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 155 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 156 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 157 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 158 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 159 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 160 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 161 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 162 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 163 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 164 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 165 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 166 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 167 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 168 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 169 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 170 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 171 | loss: 0.69315 - binary_acc: 0.4750 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 172 | loss: 0.69315 - binary_acc: 0.4775 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 173 | loss: 0.69315 - binary_acc: 0.4797 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 174 | loss: 0.69315 - binary_acc: 0.4818 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 175 | loss: 0.69315 - binary_acc: 0.4836 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 176 | loss: 0.69315 - binary_acc: 0.4852 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 177 | loss: 0.69315 - binary_acc: 0.4867 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 178 | loss: 0.69315 - binary_acc: 0.4880 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 179 | loss: 0.69315 - binary_acc: 0.4892 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 180 | loss: 0.69315 - binary_acc: 0.4903 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 181 | loss: 0.69315 - binary_acc: 0.4913 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 182 | loss: 0.69315 - binary_acc: 0.4922 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 183 | loss: 0.69315 - binary_acc: 0.4929 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 184 | loss: 0.69315 - binary_acc: 0.4936 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 185 | loss: 0.69315 - binary_acc: 0.4943 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 186 | loss: 0.69315 - binary_acc: 0.4949 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 187 | loss: 0.69315 - binary_acc: 0.4954 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 188 | loss: 0.69315 - binary_acc: 0.4958 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 189 | loss: 0.69315 - binary_acc: 0.4962 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 190 | loss: 0.69310 - binary_acc: 0.4966 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 191 | loss: 0.69311 - binary_acc: 0.4720 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 192 | loss: 0.69311 - binary_acc: 0.4748 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 193 | loss: 0.69312 - binary_acc: 0.4773 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 194 | loss: 0.69312 - binary_acc: 0.4796 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 195 | loss: 0.69313 - binary_acc: 0.4816 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 196 | loss: 0.69313 - binary_acc: 0.4834 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 197 | loss: 0.69313 - binary_acc: 0.4851 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 198 | loss: 0.69313 - binary_acc: 0.4866 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 199 | loss: 0.69314 - binary_acc: 0.4879 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 200 | loss: 0.69340 - binary_acc: 0.4391 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 201 | loss: 0.69338 - binary_acc: 0.4452 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 202 | loss: 0.69335 - binary_acc: 0.4507 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 203 | loss: 0.69333 - binary_acc: 0.4556 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 204 | loss: 0.69331 - binary_acc: 0.4601 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 205 | loss: 0.69330 - binary_acc: 0.4641 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 206 | loss: 0.69328 - binary_acc: 0.4677 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 207 | loss: 0.69327 - binary_acc: 0.4709 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 208 | loss: 0.69326 - binary_acc: 0.4738 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 209 | loss: 0.69325 - binary_acc: 0.4764 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 210 | loss: 0.69324 - binary_acc: 0.4788 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 211 | loss: 0.69323 - binary_acc: 0.4809 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 212 | loss: 0.69322 - binary_acc: 0.4828 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 213 | loss: 0.69321 - binary_acc: 0.4845 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 214 | loss: 0.69321 - binary_acc: 0.4861 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 215 | loss: 0.69320 - binary_acc: 0.4875 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 216 | loss: 0.69319 - binary_acc: 0.4887 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 217 | loss: 0.69319 - binary_acc: 0.4898 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 218 | loss: 0.69319 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 219 | loss: 0.69318 - binary_acc: 0.4918 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 220 | loss: 0.69318 - binary_acc: 0.4926 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 221 | loss: 0.69318 - binary_acc: 0.4933 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 222 | loss: 0.69317 - binary_acc: 0.4940 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 223 | loss: 0.69317 - binary_acc: 0.4946 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 224 | loss: 0.69317 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 225 | loss: 0.69317 - binary_acc: 0.4956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 226 | loss: 0.69316 - binary_acc: 0.4961 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 227 | loss: 0.69316 - binary_acc: 0.4965 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 228 | loss: 0.69316 - binary_acc: 0.4968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 229 | loss: 0.69316 - binary_acc: 0.4971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 230 | loss: 0.69316 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 231 | loss: 0.69316 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 232 | loss: 0.69316 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 233 | loss: 0.69316 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 234 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 235 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 236 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 237 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 238 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 239 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 240 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 241 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 242 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 243 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 244 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 245 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 246 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 247 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 248 | loss: 0.69314 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 249 | loss: 0.69314 - binary_acc: 0.5247 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 250 | loss: 0.69314 - binary_acc: 0.4972 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 251 | loss: 0.69314 - binary_acc: 0.5225 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 252 | loss: 0.69314 - binary_acc: 0.5202 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 253 | loss: 0.69314 - binary_acc: 0.5182 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 254 | loss: 0.69314 - binary_acc: 0.5164 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 255 | loss: 0.69314 - binary_acc: 0.5147 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 256 | loss: 0.69314 - binary_acc: 0.5133 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 257 | loss: 0.69314 - binary_acc: 0.5119 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 258 | loss: 0.69322 - binary_acc: 0.4607 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 259 | loss: 0.69321 - binary_acc: 0.4647 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 260 | loss: 0.69320 - binary_acc: 0.4682 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 261 | loss: 0.69320 - binary_acc: 0.4714 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 262 | loss: 0.69319 - binary_acc: 0.4742 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 263 | loss: 0.69319 - binary_acc: 0.4768 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 264 | loss: 0.69318 - binary_acc: 0.4791 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 265 | loss: 0.69318 - binary_acc: 0.4812 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 266 | loss: 0.69318 - binary_acc: 0.4831 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 267 | loss: 0.69317 - binary_acc: 0.4848 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 268 | loss: 0.69317 - binary_acc: 0.4863 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 269 | loss: 0.69317 - binary_acc: 0.4877 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 270 | loss: 0.69317 - binary_acc: 0.4889 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 271 | loss: 0.69317 - binary_acc: 0.4900 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 272 | loss: 0.69316 - binary_acc: 0.4910 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 273 | loss: 0.69316 - binary_acc: 0.4919 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 274 | loss: 0.69316 - binary_acc: 0.4927 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 275 | loss: 0.69316 - binary_acc: 0.4935 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 276 | loss: 0.69316 - binary_acc: 0.4941 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 277 | loss: 0.69316 - binary_acc: 0.4947 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 278 | loss: 0.69316 - binary_acc: 0.4952 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 279 | loss: 0.69315 - binary_acc: 0.4957 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 280 | loss: 0.69315 - binary_acc: 0.4961 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 281 | loss: 0.69315 - binary_acc: 0.4965 -- iter: 4/4\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 282 | loss: 0.69315 - binary_acc: 0.4969 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 283 | loss: 0.69315 - binary_acc: 0.4972 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 284 | loss: 0.69315 - binary_acc: 0.4975 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 285 | loss: 0.69315 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 286 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 287 | loss: 0.69315 - binary_acc: 0.4982 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 288 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 289 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 290 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 291 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 292 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 293 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 294 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 295 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 296 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 297 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 298 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 299 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 300 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 301 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 302 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 303 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 304 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 305 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 306 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 307 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 308 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 309 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 310 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 311 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 312 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 313 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 314 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 315 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 316 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 317 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 318 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 319 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 320 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 321 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 322 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 323 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 324 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 325 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 326 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 327 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 328 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 329 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 330 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 331 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 332 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 333 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 334 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 335 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 336 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 337 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 338 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 339 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 340 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 341 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 342 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 343 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 344 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 345 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 346 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 347 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 348 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 349 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 350 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 351 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 352 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 353 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 354 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 355 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 356 | loss: 0.69313 - binary_acc: 0.5500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 357 | loss: 0.69313 - binary_acc: 0.5450 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 358 | loss: 0.69313 - binary_acc: 0.5405 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 359 | loss: 0.69313 - binary_acc: 0.5364 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 360 | loss: 0.69313 - binary_acc: 0.5328 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 361 | loss: 0.69314 - binary_acc: 0.5295 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 362 | loss: 0.69314 - binary_acc: 0.5266 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 363 | loss: 0.69314 - binary_acc: 0.5239 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 364 | loss: 0.69314 - binary_acc: 0.5215 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 365 | loss: 0.69314 - binary_acc: 0.5194 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 366 | loss: 0.69314 - binary_acc: 0.5174 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 367 | loss: 0.69314 - binary_acc: 0.5157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 368 | loss: 0.69314 - binary_acc: 0.5141 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 369 | loss: 0.69314 - binary_acc: 0.5127 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 370 | loss: 0.69314 - binary_acc: 0.5114 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 371 | loss: 0.69314 - binary_acc: 0.5103 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 372 | loss: 0.69314 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 373 | loss: 0.69314 - binary_acc: 0.5083 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 374 | loss: 0.69315 - binary_acc: 0.5075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 375 | loss: 0.69315 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 376 | loss: 0.69315 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 377 | loss: 0.69315 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 378 | loss: 0.69315 - binary_acc: 0.5049 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 379 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 380 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 381 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 382 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 383 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 384 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 385 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.69301\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 386 | loss: 0.69301 - binary_acc: 0.5521 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.69303\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 387 | loss: 0.69303 - binary_acc: 0.5469 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.69304\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 388 | loss: 0.69304 - binary_acc: 0.5422 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.69305\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 389 | loss: 0.69305 - binary_acc: 0.5380 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.69307\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 390 | loss: 0.69307 - binary_acc: 0.5342 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.69308\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 391 | loss: 0.69308 - binary_acc: 0.5308 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.69308\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 392 | loss: 0.69308 - binary_acc: 0.5277 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 393 | loss: 0.69309 - binary_acc: 0.5249 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 394 | loss: 0.69310 - binary_acc: 0.5224 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 395 | loss: 0.69311 - binary_acc: 0.5202 -- iter: 4/4\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 396 | loss: 0.69311 - binary_acc: 0.5182 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 397 | loss: 0.69312 - binary_acc: 0.5164 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 398 | loss: 0.69312 - binary_acc: 0.5147 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 399 | loss: 0.69313 - binary_acc: 0.5132 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 400 | loss: 0.69313 - binary_acc: 0.5119 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 401 | loss: 0.69313 - binary_acc: 0.5107 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 402 | loss: 0.69313 - binary_acc: 0.5097 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 403 | loss: 0.69314 - binary_acc: 0.5087 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 404 | loss: 0.69314 - binary_acc: 0.5078 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 405 | loss: 0.69314 - binary_acc: 0.5070 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 406 | loss: 0.69314 - binary_acc: 0.5063 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 407 | loss: 0.69314 - binary_acc: 0.5057 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 408 | loss: 0.69315 - binary_acc: 0.5051 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 409 | loss: 0.69315 - binary_acc: 0.5046 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 410 | loss: 0.69315 - binary_acc: 0.5042 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 411 | loss: 0.69315 - binary_acc: 0.5037 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 412 | loss: 0.69315 - binary_acc: 0.5034 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 413 | loss: 0.69315 - binary_acc: 0.5030 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 414 | loss: 0.69315 - binary_acc: 0.5027 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 415 | loss: 0.69315 - binary_acc: 0.5025 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 416 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 417 | loss: 0.69315 - binary_acc: 0.5020 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 418 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 419 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 420 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 421 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 422 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 423 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 424 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 425 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 426 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 427 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 428 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 429 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 430 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 431 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 432 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 433 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 434 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 435 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 436 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 437 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 438 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 439 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 440 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 441 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 442 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 443 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 444 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 445 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 446 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 447 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 448 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 449 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 450 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 451 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 452 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 453 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 454 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 455 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 456 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 457 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 458 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 459 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 460 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 461 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 462 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 463 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 464 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 465 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 466 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 467 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 468 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 469 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 470 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 471 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 472 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 473 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 474 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 475 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 476 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 477 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 478 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 479 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 480 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 481 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 482 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 483 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 484 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 485 | loss: 0.69327 - binary_acc: 0.5250 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 486 | loss: 0.69326 - binary_acc: 0.5225 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 487 | loss: 0.69325 - binary_acc: 0.5203 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 488 | loss: 0.69324 - binary_acc: 0.5182 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 489 | loss: 0.69323 - binary_acc: 0.5164 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 490 | loss: 0.69322 - binary_acc: 0.5148 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 491 | loss: 0.69321 - binary_acc: 0.5133 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 492 | loss: 0.69321 - binary_acc: 0.5120 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 493 | loss: 0.69320 - binary_acc: 0.5108 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 494 | loss: 0.69320 - binary_acc: 0.5347 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 495 | loss: 0.69319 - binary_acc: 0.5562 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 496 | loss: 0.69319 - binary_acc: 0.5756 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 497 | loss: 0.69318 - binary_acc: 0.5930 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 498 | loss: 0.69318 - binary_acc: 0.6087 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 499 | loss: 0.69318 - binary_acc: 0.6229 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 500 | loss: 0.69318 - binary_acc: 0.6356 -- iter: 4/4\n",
      "--\n",
      "Final Updated Weights: [[0.04535764]\n",
      " [0.00012494]]\n",
      "Expected:  [False, True, True, False]\n",
      "Predicted:  [True, True, False, False]\n",
      "Efficiency: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "Y = [[0], [1], [1], [0]]\n",
    "# Define the network architecture\n",
    "input_layer = input_data(shape=[None, 2])\n",
    "hidden_layer = fully_connected(input_layer, 2, activation='tanh')\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='tanh')\n",
    "# Define the regression layer using the output layer\n",
    "regression_layer = regression(output_layer, optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
    "# Create the model using the regression layer\n",
    "model = tflearn.DNN(regression_layer)\n",
    "# Train the model\n",
    "model.fit(X, Y, n_epoch=500, show_metric=True)\n",
    "# Get the final updated weights of the model\n",
    "final_weights = model.get_weights(output_layer.W)\n",
    "print(\"Final Updated Weights:\", final_weights)\n",
    "# Predict the output\n",
    "predicted = model.predict(X)\n",
    "predicted_classes = [i[0] > 0 for i in predicted]\n",
    "# Convert Y to list of bool values\n",
    "expected_classes = [i[0] > 0 for i in Y]\n",
    "# Compare and calculate efficiency\n",
    "correct_predictions = sum(1 for expected, predicted in zip(expected_classes, predicted_classes) if expected == predicted)\n",
    "total_predictions = len(expected_classes)\n",
    "efficiency = (correct_predictions / total_predictions) * 100\n",
    "print(\"Expected: \", expected_classes)\n",
    "print(\"Predicted: \", predicted_classes)\n",
    "print(\"Efficiency: {:.2f}%\".format(efficiency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76378dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\91960\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: 0VXR7L\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.295s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.62383\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 002 | loss: 0.62383 - binary_acc: 0.6750 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.68054\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 003 | loss: 0.68054 - binary_acc: 0.5318 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.69000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 004 | loss: 0.69000 - binary_acc: 0.5080 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.69218\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 005 | loss: 0.69218 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.69280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 006 | loss: 0.69280 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.69301\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 007 | loss: 0.69301 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 008 | loss: 0.69309 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 009 | loss: 0.69312 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 010 | loss: 0.69313 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 011 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 012 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 013 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 014 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 015 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 016 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 017 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 018 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 019 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 020 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 021 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 022 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 023 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 024 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 025 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 026 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 027 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 028 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 029 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 030 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 031 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 032 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 033 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 034 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 035 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 036 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 037 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 038 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 039 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 040 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 041 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 042 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 043 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 044 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 045 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 046 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 047 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 048 | loss: 0.69317 - binary_acc: 0.4196 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 049 | loss: 0.69317 - binary_acc: 0.4323 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 050 | loss: 0.69317 - binary_acc: 0.4428 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 051 | loss: 0.69316 - binary_acc: 0.4134 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 052 | loss: 0.69316 - binary_acc: 0.4264 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 053 | loss: 0.69316 - binary_acc: 0.4373 -- iter: 4/4\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 054 | loss: 0.69316 - binary_acc: 0.4464 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 055 | loss: 0.69316 - binary_acc: 0.4540 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 056 | loss: 0.69315 - binary_acc: 0.4605 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 057 | loss: 0.69315 - binary_acc: 0.4660 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 058 | loss: 0.69315 - binary_acc: 0.4706 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 059 | loss: 0.69315 - binary_acc: 0.4746 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 060 | loss: 0.69315 - binary_acc: 0.4779 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 061 | loss: 0.69315 - binary_acc: 0.4808 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 062 | loss: 0.69315 - binary_acc: 0.4833 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 063 | loss: 0.69315 - binary_acc: 0.4854 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 064 | loss: 0.69315 - binary_acc: 0.4872 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 065 | loss: 0.69315 - binary_acc: 0.4888 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 066 | loss: 0.69315 - binary_acc: 0.4902 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 067 | loss: 0.69315 - binary_acc: 0.4913 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 068 | loss: 0.69315 - binary_acc: 0.4924 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 069 | loss: 0.69315 - binary_acc: 0.4933 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 070 | loss: 0.69315 - binary_acc: 0.4940 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 071 | loss: 0.69315 - binary_acc: 0.4947 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 072 | loss: 0.69315 - binary_acc: 0.4953 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 073 | loss: 0.69315 - binary_acc: 0.4958 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 074 | loss: 0.69315 - binary_acc: 0.4963 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 075 | loss: 0.69315 - binary_acc: 0.4967 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 076 | loss: 0.69315 - binary_acc: 0.4970 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 077 | loss: 0.69315 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 078 | loss: 0.69315 - binary_acc: 0.4976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 079 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 080 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 081 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 082 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 083 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 084 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 085 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 086 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 087 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 088 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 089 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 090 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 091 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 092 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 093 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 094 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 095 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 096 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 097 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 098 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 099 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 100 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 101 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 102 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 103 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 104 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 105 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 106 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 107 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 108 | loss: 0.69315 - binary_acc: 0.5499 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 109 | loss: 0.69315 - binary_acc: 0.5449 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 110 | loss: 0.69315 - binary_acc: 0.5404 -- iter: 4/4\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 111 | loss: 0.69315 - binary_acc: 0.5364 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 112 | loss: 0.69315 - binary_acc: 0.5327 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 113 | loss: 0.69315 - binary_acc: 0.5295 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 114 | loss: 0.69315 - binary_acc: 0.5265 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 115 | loss: 0.69315 - binary_acc: 0.5239 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 116 | loss: 0.69315 - binary_acc: 0.5215 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 117 | loss: 0.69315 - binary_acc: 0.5193 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 118 | loss: 0.69315 - binary_acc: 0.5174 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 119 | loss: 0.69315 - binary_acc: 0.5157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 120 | loss: 0.69315 - binary_acc: 0.5141 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 121 | loss: 0.69315 - binary_acc: 0.5127 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 122 | loss: 0.69315 - binary_acc: 0.5114 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 123 | loss: 0.69315 - binary_acc: 0.5103 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 124 | loss: 0.69315 - binary_acc: 0.5092 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 125 | loss: 0.69315 - binary_acc: 0.5083 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 126 | loss: 0.69315 - binary_acc: 0.5075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 127 | loss: 0.69315 - binary_acc: 0.5067 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 128 | loss: 0.69315 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 129 | loss: 0.69315 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 130 | loss: 0.69315 - binary_acc: 0.5049 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 131 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 132 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 133 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 134 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 135 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 136 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 137 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 138 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 139 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 140 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 141 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 142 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 143 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 144 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 145 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 146 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 147 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 148 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 149 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 150 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 151 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 152 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 153 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 154 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 155 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 156 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 157 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 158 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 159 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 160 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 161 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 162 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 163 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 164 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 165 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 166 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 167 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 168 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 169 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 170 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 171 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 172 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 173 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 174 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 175 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 176 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 177 | loss: 0.69314 - binary_acc: 0.4750 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 178 | loss: 0.69315 - binary_acc: 0.4775 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 179 | loss: 0.69315 - binary_acc: 0.4798 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 180 | loss: 0.69315 - binary_acc: 0.4818 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 181 | loss: 0.69315 - binary_acc: 0.4836 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 182 | loss: 0.69315 - binary_acc: 0.4853 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 183 | loss: 0.69315 - binary_acc: 0.4867 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 184 | loss: 0.69315 - binary_acc: 0.4881 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 185 | loss: 0.69315 - binary_acc: 0.4893 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 186 | loss: 0.69315 - binary_acc: 0.4903 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 187 | loss: 0.69315 - binary_acc: 0.4913 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 188 | loss: 0.69315 - binary_acc: 0.4922 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 189 | loss: 0.69315 - binary_acc: 0.4929 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 190 | loss: 0.69315 - binary_acc: 0.4937 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 191 | loss: 0.69315 - binary_acc: 0.4943 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 192 | loss: 0.69315 - binary_acc: 0.4949 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 193 | loss: 0.69315 - binary_acc: 0.4954 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 194 | loss: 0.69315 - binary_acc: 0.4958 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 195 | loss: 0.69315 - binary_acc: 0.4963 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 196 | loss: 0.69315 - binary_acc: 0.4966 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 197 | loss: 0.69315 - binary_acc: 0.4970 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 198 | loss: 0.69315 - binary_acc: 0.4973 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 199 | loss: 0.69315 - binary_acc: 0.4975 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 200 | loss: 0.69315 - binary_acc: 0.4978 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 201 | loss: 0.69315 - binary_acc: 0.4980 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 202 | loss: 0.69315 - binary_acc: 0.4982 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 203 | loss: 0.69315 - binary_acc: 0.4984 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 204 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 205 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 206 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 207 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 208 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 209 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 210 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 211 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 212 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 213 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 214 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 215 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 216 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 217 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 218 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 219 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 220 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 221 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 222 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 223 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 224 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 225 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 226 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 227 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 228 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 229 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 230 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 231 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 232 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 233 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 234 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 235 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 236 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 237 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 238 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 239 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 240 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 241 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 242 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 243 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 244 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 245 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 246 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 247 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 248 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 249 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 250 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 251 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 252 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 253 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 254 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 255 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 256 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 257 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 258 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 259 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 260 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 261 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 262 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 263 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 264 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 265 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 266 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 267 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 268 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 269 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 270 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 271 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 272 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 273 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 274 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 275 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 276 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 277 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 278 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 279 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 280 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 281 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 282 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 283 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 284 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 285 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 286 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 287 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 288 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 289 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 290 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 291 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 292 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 293 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 294 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 295 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 296 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 297 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 298 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 299 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 300 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 301 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 302 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 303 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 304 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 305 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 306 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 307 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 308 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 309 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 310 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 311 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 312 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 313 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 314 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 315 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 316 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 317 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 318 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 319 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 320 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 321 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 322 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 323 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 324 | loss: 0.69313 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 325 | loss: 0.69313 - binary_acc: 0.5250 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 326 | loss: 0.69314 - binary_acc: 0.5225 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 327 | loss: 0.69314 - binary_acc: 0.5202 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 328 | loss: 0.69314 - binary_acc: 0.5182 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 329 | loss: 0.69314 - binary_acc: 0.5164 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 330 | loss: 0.69314 - binary_acc: 0.5148 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 331 | loss: 0.69314 - binary_acc: 0.5133 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 332 | loss: 0.69314 - binary_acc: 0.5120 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 333 | loss: 0.69314 - binary_acc: 0.5108 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 334 | loss: 0.69314 - binary_acc: 0.5097 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 335 | loss: 0.69314 - binary_acc: 0.5087 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 336 | loss: 0.69314 - binary_acc: 0.5078 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 337 | loss: 0.69314 - binary_acc: 0.5071 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 338 | loss: 0.69314 - binary_acc: 0.5064 -- iter: 4/4\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 339 | loss: 0.69314 - binary_acc: 0.5057 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 340 | loss: 0.69314 - binary_acc: 0.5051 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 341 | loss: 0.69314 - binary_acc: 0.5046 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 342 | loss: 0.69318 - binary_acc: 0.5042 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 343 | loss: 0.69318 - binary_acc: 0.5038 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 344 | loss: 0.69319 - binary_acc: 0.5034 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 345 | loss: 0.69319 - binary_acc: 0.5030 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 346 | loss: 0.69318 - binary_acc: 0.5027 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 347 | loss: 0.69318 - binary_acc: 0.5025 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 348 | loss: 0.69318 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 349 | loss: 0.69317 - binary_acc: 0.5020 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 350 | loss: 0.69317 - binary_acc: 0.5018 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 351 | loss: 0.69317 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 352 | loss: 0.69317 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 353 | loss: 0.69317 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 354 | loss: 0.69316 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 355 | loss: 0.69316 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 356 | loss: 0.69316 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 357 | loss: 0.69316 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 358 | loss: 0.69316 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 359 | loss: 0.69316 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 360 | loss: 0.69316 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 361 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 362 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 363 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 364 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 365 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 366 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 367 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 368 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 369 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 370 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 371 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 372 | loss: 0.69319 - binary_acc: 0.4502 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 373 | loss: 0.69319 - binary_acc: 0.4552 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 374 | loss: 0.69318 - binary_acc: 0.4846 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 375 | loss: 0.69318 - binary_acc: 0.4612 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 376 | loss: 0.69318 - binary_acc: 0.4901 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 377 | loss: 0.69317 - binary_acc: 0.4661 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 378 | loss: 0.69317 - binary_acc: 0.4694 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 379 | loss: 0.69317 - binary_acc: 0.4725 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 380 | loss: 0.69317 - binary_acc: 0.4753 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 381 | loss: 0.69316 - binary_acc: 0.4777 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 382 | loss: 0.69316 - binary_acc: 0.4800 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 383 | loss: 0.69316 - binary_acc: 0.4820 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 384 | loss: 0.69316 - binary_acc: 0.4838 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 385 | loss: 0.69316 - binary_acc: 0.4854 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 386 | loss: 0.69316 - binary_acc: 0.4868 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 387 | loss: 0.69316 - binary_acc: 0.4882 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 388 | loss: 0.69316 - binary_acc: 0.4893 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 389 | loss: 0.69315 - binary_acc: 0.4904 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 390 | loss: 0.69315 - binary_acc: 0.4914 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 391 | loss: 0.69315 - binary_acc: 0.4922 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 392 | loss: 0.69315 - binary_acc: 0.4930 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 393 | loss: 0.69315 - binary_acc: 0.4937 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 394 | loss: 0.69315 - binary_acc: 0.4943 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 395 | loss: 0.69315 - binary_acc: 0.4949 -- iter: 4/4\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 396 | loss: 0.69315 - binary_acc: 0.4954 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 397 | loss: 0.69315 - binary_acc: 0.4959 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 398 | loss: 0.69315 - binary_acc: 0.4963 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 399 | loss: 0.69315 - binary_acc: 0.4967 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 400 | loss: 0.69315 - binary_acc: 0.4970 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 401 | loss: 0.69315 - binary_acc: 0.4973 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 402 | loss: 0.69315 - binary_acc: 0.4976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 403 | loss: 0.69315 - binary_acc: 0.4978 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 404 | loss: 0.69315 - binary_acc: 0.4980 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 405 | loss: 0.69315 - binary_acc: 0.4982 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 406 | loss: 0.69315 - binary_acc: 0.4984 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 407 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 408 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 409 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 410 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 411 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 412 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 413 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 414 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 415 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 416 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 417 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 418 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 419 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 420 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 421 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 422 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 423 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 424 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 425 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 426 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 427 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 428 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 429 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 430 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 431 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 432 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 433 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 434 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 435 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 436 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 437 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 438 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 439 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 440 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 441 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 442 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 443 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 444 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 445 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 446 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 447 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 448 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 449 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 450 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 451 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 452 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 453 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 454 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 455 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 456 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 457 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 458 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 459 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 460 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 461 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 462 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 463 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 464 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 465 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 466 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 467 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 468 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 469 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 470 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 471 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 472 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 473 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 474 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 475 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 476 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 477 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 478 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 479 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 480 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 481 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 482 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 483 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 484 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 485 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 486 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 487 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 488 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 489 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 490 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 491 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 492 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 493 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 494 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 495 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 496 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 497 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 498 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 499 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 500 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 501 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 502 | loss: 0.69313 - binary_acc: 0.5500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 503 | loss: 0.69313 - binary_acc: 0.5200 -- iter: 4/4\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 504 | loss: 0.69314 - binary_acc: 0.5180 -- iter: 4/4\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 505 | loss: 0.69314 - binary_acc: 0.5162 -- iter: 4/4\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 506 | loss: 0.69314 - binary_acc: 0.5146 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 507 | loss: 0.69314 - binary_acc: 0.5131 -- iter: 4/4\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 508 | loss: 0.69314 - binary_acc: 0.5118 -- iter: 4/4\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 509 | loss: 0.69314 - binary_acc: 0.5106 -- iter: 4/4\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 510 | loss: 0.69314 - binary_acc: 0.5096 -- iter: 4/4\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 511 | loss: 0.69314 - binary_acc: 0.5086 -- iter: 4/4\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 512 | loss: 0.69314 - binary_acc: 0.5077 -- iter: 4/4\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 513 | loss: 0.69314 - binary_acc: 0.5070 -- iter: 4/4\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 514 | loss: 0.69314 - binary_acc: 0.5063 -- iter: 4/4\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 515 | loss: 0.69314 - binary_acc: 0.5056 -- iter: 4/4\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 516 | loss: 0.69314 - binary_acc: 0.5051 -- iter: 4/4\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 517 | loss: 0.69314 - binary_acc: 0.5046 -- iter: 4/4\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 518 | loss: 0.69315 - binary_acc: 0.5041 -- iter: 4/4\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 519 | loss: 0.69315 - binary_acc: 0.5037 -- iter: 4/4\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 520 | loss: 0.69315 - binary_acc: 0.5033 -- iter: 4/4\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 521 | loss: 0.69315 - binary_acc: 0.5030 -- iter: 4/4\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 522 | loss: 0.69315 - binary_acc: 0.5027 -- iter: 4/4\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 523 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 524 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 525 | loss: 0.69315 - binary_acc: 0.5020 -- iter: 4/4\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 526 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 527 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 528 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 529 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 530 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 531 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 532 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 533 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 534 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 535 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 536 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 537 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 538 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 539 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 540 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 541 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 542 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 543 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 544 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 545 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 546 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 547 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 548 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 549 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 550 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 551 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 552 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 553 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 554 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 555 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 556 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 557 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 558 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 559 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 560 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 561 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 562 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 563 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 564 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 565 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 566 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 567 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.69307\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 568 | loss: 0.69307 - binary_acc: 0.5500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.69308\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 569 | loss: 0.69308 - binary_acc: 0.5450 -- iter: 4/4\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 570 | loss: 0.69309 - binary_acc: 0.5405 -- iter: 4/4\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 571 | loss: 0.69310 - binary_acc: 0.5328 -- iter: 4/4\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 572 | loss: 0.69310 - binary_acc: 0.5328 -- iter: 4/4\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 573 | loss: 0.69311 - binary_acc: 0.5295 -- iter: 4/4\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 574 | loss: 0.69311 - binary_acc: 0.5266 -- iter: 4/4\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 575 | loss: 0.69312 - binary_acc: 0.5239 -- iter: 4/4\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 576 | loss: 0.69312 - binary_acc: 0.5215 -- iter: 4/4\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 577 | loss: 0.69312 - binary_acc: 0.5194 -- iter: 4/4\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 578 | loss: 0.69313 - binary_acc: 0.5174 -- iter: 4/4\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 579 | loss: 0.69313 - binary_acc: 0.5157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 580 | loss: 0.69313 - binary_acc: 0.5141 -- iter: 4/4\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 581 | loss: 0.69313 - binary_acc: 0.5127 -- iter: 4/4\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 582 | loss: 0.69314 - binary_acc: 0.5114 -- iter: 4/4\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 583 | loss: 0.69314 - binary_acc: 0.5103 -- iter: 4/4\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 584 | loss: 0.69314 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 585 | loss: 0.69314 - binary_acc: 0.5083 -- iter: 4/4\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 586 | loss: 0.69314 - binary_acc: 0.5075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 587 | loss: 0.69314 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 588 | loss: 0.69314 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 589 | loss: 0.69314 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 590 | loss: 0.69314 - binary_acc: 0.5049 -- iter: 4/4\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 591 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 592 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 593 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 594 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 595 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 596 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 597 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 598 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 599 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 600 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 601 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 602 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 603 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 604 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 605 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 606 | loss: 0.69312 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 607 | loss: 0.69312 - binary_acc: 0.4758 -- iter: 4/4\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 608 | loss: 0.69313 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 609 | loss: 0.69313 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 610 | loss: 0.69314 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 611 | loss: 0.69314 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 612 | loss: 0.69314 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 613 | loss: 0.69314 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 614 | loss: 0.69314 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 615 | loss: 0.69314 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 616 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 617 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 618 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 619 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 620 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 621 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 622 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 623 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 624 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 625 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 626 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 627 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 628 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 629 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 630 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 631 | loss: 0.69315 - binary_acc: 0.5253 -- iter: 4/4\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 632 | loss: 0.69315 - binary_acc: 0.5478 -- iter: 4/4\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 633 | loss: 0.69315 - binary_acc: 0.5680 -- iter: 4/4\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 634 | loss: 0.69315 - binary_acc: 0.5862 -- iter: 4/4\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 635 | loss: 0.69315 - binary_acc: 0.6026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 636 | loss: 0.69315 - binary_acc: 0.6173 -- iter: 4/4\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 637 | loss: 0.69315 - binary_acc: 0.6306 -- iter: 4/4\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 638 | loss: 0.69315 - binary_acc: 0.6425 -- iter: 4/4\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 639 | loss: 0.69315 - binary_acc: 0.6533 -- iter: 4/4\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 640 | loss: 0.69315 - binary_acc: 0.6379 -- iter: 4/4\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 641 | loss: 0.69315 - binary_acc: 0.6241 -- iter: 4/4\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 642 | loss: 0.69314 - binary_acc: 0.6117 -- iter: 4/4\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 643 | loss: 0.69314 - binary_acc: 0.6006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 644 | loss: 0.69314 - binary_acc: 0.5905 -- iter: 4/4\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 645 | loss: 0.69314 - binary_acc: 0.5815 -- iter: 4/4\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 646 | loss: 0.69314 - binary_acc: 0.5733 -- iter: 4/4\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 647 | loss: 0.69314 - binary_acc: 0.5660 -- iter: 4/4\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 648 | loss: 0.69314 - binary_acc: 0.5594 -- iter: 4/4\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 649 | loss: 0.69314 - binary_acc: 0.5534 -- iter: 4/4\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 650 | loss: 0.69314 - binary_acc: 0.5481 -- iter: 4/4\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 651 | loss: 0.69314 - binary_acc: 0.5433 -- iter: 4/4\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 652 | loss: 0.69314 - binary_acc: 0.5390 -- iter: 4/4\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 653 | loss: 0.69314 - binary_acc: 0.5351 -- iter: 4/4\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 654 | loss: 0.69314 - binary_acc: 0.5316 -- iter: 4/4\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 655 | loss: 0.69314 - binary_acc: 0.5284 -- iter: 4/4\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 656 | loss: 0.69314 - binary_acc: 0.5256 -- iter: 4/4\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 657 | loss: 0.69314 - binary_acc: 0.5230 -- iter: 4/4\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 658 | loss: 0.69314 - binary_acc: 0.5207 -- iter: 4/4\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 659 | loss: 0.69314 - binary_acc: 0.5186 -- iter: 4/4\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 660 | loss: 0.69313 - binary_acc: 0.5168 -- iter: 4/4\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 661 | loss: 0.69313 - binary_acc: 0.5151 -- iter: 4/4\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 662 | loss: 0.69313 - binary_acc: 0.5136 -- iter: 4/4\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 663 | loss: 0.69313 - binary_acc: 0.5122 -- iter: 4/4\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 664 | loss: 0.69313 - binary_acc: 0.5110 -- iter: 4/4\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 665 | loss: 0.69313 - binary_acc: 0.5099 -- iter: 4/4\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 666 | loss: 0.69314 - binary_acc: 0.5089 -- iter: 4/4\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 667 | loss: 0.69314 - binary_acc: 0.5080 -- iter: 4/4\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 668 | loss: 0.69313 - binary_acc: 0.5072 -- iter: 4/4\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 669 | loss: 0.69313 - binary_acc: 0.5065 -- iter: 4/4\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 670 | loss: 0.69313 - binary_acc: 0.5058 -- iter: 4/4\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 671 | loss: 0.69313 - binary_acc: 0.5053 -- iter: 4/4\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 672 | loss: 0.69313 - binary_acc: 0.5047 -- iter: 4/4\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 673 | loss: 0.69313 - binary_acc: 0.5043 -- iter: 4/4\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.69272\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 674 | loss: 0.69272 - binary_acc: 0.5735 -- iter: 4/4\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.69277\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 675 | loss: 0.69277 - binary_acc: 0.5735 -- iter: 4/4\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.69280\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 676 | loss: 0.69280 - binary_acc: 0.5661 -- iter: 4/4\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.69282\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 677 | loss: 0.69282 - binary_acc: 0.5595 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.69283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 678 | loss: 0.69283 - binary_acc: 0.5535 -- iter: 4/4\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.69283\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 679 | loss: 0.69283 - binary_acc: 0.5482 -- iter: 4/4\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.69283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 680 | loss: 0.69283 - binary_acc: 0.5434 -- iter: 4/4\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.69282\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 681 | loss: 0.69282 - binary_acc: 0.5390 -- iter: 4/4\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.69280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 682 | loss: 0.69280 - binary_acc: 0.5351 -- iter: 4/4\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.69277\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 683 | loss: 0.69277 - binary_acc: 0.5316 -- iter: 4/4\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.69273\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 684 | loss: 0.69273 - binary_acc: 0.5285 -- iter: 4/4\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.69267\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 685 | loss: 0.69267 - binary_acc: 0.5256 -- iter: 4/4\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.69259\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 686 | loss: 0.69259 - binary_acc: 0.5231 -- iter: 4/4\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.69248\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 687 | loss: 0.69248 - binary_acc: 0.5207 -- iter: 4/4\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.69233\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 688 | loss: 0.69233 - binary_acc: 0.5437 -- iter: 4/4\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.69212\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 689 | loss: 0.69212 - binary_acc: 0.5643 -- iter: 4/4\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.69183\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 690 | loss: 0.69183 - binary_acc: 0.5829 -- iter: 4/4\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.69141\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 691 | loss: 0.69141 - binary_acc: 0.5996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.69080\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 692 | loss: 0.69080 - binary_acc: 0.6146 -- iter: 4/4\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.68989\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 693 | loss: 0.68989 - binary_acc: 0.6282 -- iter: 4/4\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.68853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 694 | loss: 0.68853 - binary_acc: 0.6403 -- iter: 4/4\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.68648\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 695 | loss: 0.68648 - binary_acc: 0.6513 -- iter: 4/4\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.68347\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 696 | loss: 0.68347 - binary_acc: 0.6612 -- iter: 4/4\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.67926\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 697 | loss: 0.67926 - binary_acc: 0.6701 -- iter: 4/4\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.67382\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 698 | loss: 0.67382 - binary_acc: 0.6781 -- iter: 4/4\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.66744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 699 | loss: 0.66744 - binary_acc: 0.6853 -- iter: 4/4\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.66054\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 700 | loss: 0.66054 - binary_acc: 0.6917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.65351\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 701 | loss: 0.65351 - binary_acc: 0.6976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.64663\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 702 | loss: 0.64663 - binary_acc: 0.7028 -- iter: 4/4\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.64004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 703 | loss: 0.64004 - binary_acc: 0.7075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.63381\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 704 | loss: 0.63381 - binary_acc: 0.7118 -- iter: 4/4\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.62800\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 705 | loss: 0.62800 - binary_acc: 0.7156 -- iter: 4/4\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.62261\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 706 | loss: 0.62261 - binary_acc: 0.7190 -- iter: 4/4\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.61762\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 707 | loss: 0.61762 - binary_acc: 0.7221 -- iter: 4/4\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.61303\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 708 | loss: 0.61303 - binary_acc: 0.7249 -- iter: 4/4\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.60881\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 709 | loss: 0.60881 - binary_acc: 0.7274 -- iter: 4/4\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.60495\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 710 | loss: 0.60495 - binary_acc: 0.7297 -- iter: 4/4\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.60141\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 711 | loss: 0.60141 - binary_acc: 0.7317 -- iter: 4/4\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.59817\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 712 | loss: 0.59817 - binary_acc: 0.7335 -- iter: 4/4\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.59522\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 713 | loss: 0.59522 - binary_acc: 0.7352 -- iter: 4/4\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.59252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 714 | loss: 0.59252 - binary_acc: 0.7367 -- iter: 4/4\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.59006\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 715 | loss: 0.59006 - binary_acc: 0.7380 -- iter: 4/4\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.58781\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 716 | loss: 0.58781 - binary_acc: 0.7392 -- iter: 4/4\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.58576\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 717 | loss: 0.58576 - binary_acc: 0.7403 -- iter: 4/4\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.58390\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 718 | loss: 0.58390 - binary_acc: 0.7413 -- iter: 4/4\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.58220\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 719 | loss: 0.58220 - binary_acc: 0.7421 -- iter: 4/4\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.62830\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 720 | loss: 0.62830 - binary_acc: 0.6929 -- iter: 4/4\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.62224\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 721 | loss: 0.62224 - binary_acc: 0.6986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.61676\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 722 | loss: 0.61676 - binary_acc: 0.7038 -- iter: 4/4\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.61179\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 723 | loss: 0.61179 - binary_acc: 0.7084 -- iter: 4/4\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.60731\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 724 | loss: 0.60731 - binary_acc: 0.7125 -- iter: 4/4\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.60325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 725 | loss: 0.60325 - binary_acc: 0.7163 -- iter: 4/4\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.64761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 726 | loss: 0.64761 - binary_acc: 0.6697 -- iter: 4/4\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.63956\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 727 | loss: 0.63956 - binary_acc: 0.6777 -- iter: 4/4\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.63230\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 728 | loss: 0.63230 - binary_acc: 0.6849 -- iter: 4/4\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.62574\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 729 | loss: 0.62574 - binary_acc: 0.6914 -- iter: 4/4\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.61981\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 730 | loss: 0.61981 - binary_acc: 0.6973 -- iter: 4/4\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.61446\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 731 | loss: 0.61446 - binary_acc: 0.7026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.60963\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 732 | loss: 0.60963 - binary_acc: 0.7073 -- iter: 4/4\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.60527\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 733 | loss: 0.60527 - binary_acc: 0.7116 -- iter: 4/4\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.60133\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 734 | loss: 0.60133 - binary_acc: 0.7154 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.59777\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 735 | loss: 0.59777 - binary_acc: 0.7189 -- iter: 4/4\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.59455\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 736 | loss: 0.59455 - binary_acc: 0.7220 -- iter: 4/4\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.59164\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 737 | loss: 0.59164 - binary_acc: 0.7248 -- iter: 4/4\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.58902\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 738 | loss: 0.58902 - binary_acc: 0.7273 -- iter: 4/4\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.58665\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 739 | loss: 0.58665 - binary_acc: 0.7296 -- iter: 4/4\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.63242\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 740 | loss: 0.63242 - binary_acc: 0.6816 -- iter: 4/4\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.62571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 741 | loss: 0.62571 - binary_acc: 0.6885 -- iter: 4/4\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.61966\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 742 | loss: 0.61966 - binary_acc: 0.6946 -- iter: 4/4\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.61420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 743 | loss: 0.61420 - binary_acc: 0.7051 -- iter: 4/4\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.60926\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 744 | loss: 0.60926 - binary_acc: 0.7051 -- iter: 4/4\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.60480\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 745 | loss: 0.60480 - binary_acc: 0.7096 -- iter: 4/4\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.60077\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 746 | loss: 0.60077 - binary_acc: 0.7137 -- iter: 4/4\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.59712\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 747 | loss: 0.59712 - binary_acc: 0.7173 -- iter: 4/4\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.59382\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 748 | loss: 0.59382 - binary_acc: 0.7206 -- iter: 4/4\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.59081\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 749 | loss: 0.59081 - binary_acc: 0.7235 -- iter: 4/4\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.58808\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 750 | loss: 0.58808 - binary_acc: 0.7262 -- iter: 4/4\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m0.58558\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 751 | loss: 0.58558 - binary_acc: 0.7285 -- iter: 4/4\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m0.58328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 752 | loss: 0.58328 - binary_acc: 0.7307 -- iter: 4/4\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m0.58114\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 753 | loss: 0.58114 - binary_acc: 0.7326 -- iter: 4/4\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m0.62500\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 754 | loss: 0.62500 - binary_acc: 0.6844 -- iter: 4/4\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m0.61825\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 755 | loss: 0.61825 - binary_acc: 0.6909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m0.61116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 756 | loss: 0.61116 - binary_acc: 0.6968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m0.60325\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 757 | loss: 0.60325 - binary_acc: 0.7021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m0.59301\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 758 | loss: 0.59301 - binary_acc: 0.7069 -- iter: 4/4\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m0.57889\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 759 | loss: 0.57889 - binary_acc: 0.7362 -- iter: 4/4\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m0.56239\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 760 | loss: 0.56239 - binary_acc: 0.7626 -- iter: 4/4\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m0.55999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 761 | loss: 0.55999 - binary_acc: 0.7614 -- iter: 4/4\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m0.54878\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 762 | loss: 0.54878 - binary_acc: 0.7852 -- iter: 4/4\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m0.55206\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 763 | loss: 0.55206 - binary_acc: 0.7817 -- iter: 4/4\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m0.55337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 764 | loss: 0.55337 - binary_acc: 0.7785 -- iter: 4/4\n",
      "--\n",
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m0.55452\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 765 | loss: 0.55452 - binary_acc: 0.7757 -- iter: 4/4\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m0.55554\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 766 | loss: 0.55554 - binary_acc: 0.7731 -- iter: 4/4\n",
      "--\n",
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m0.55643\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 767 | loss: 0.55643 - binary_acc: 0.7708 -- iter: 4/4\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m0.55723\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 768 | loss: 0.55723 - binary_acc: 0.7687 -- iter: 4/4\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m0.55793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 769 | loss: 0.55793 - binary_acc: 0.7668 -- iter: 4/4\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m0.55855\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 770 | loss: 0.55855 - binary_acc: 0.7652 -- iter: 4/4\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m0.55910\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 771 | loss: 0.55910 - binary_acc: 0.7636 -- iter: 4/4\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m0.55959\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 772 | loss: 0.55959 - binary_acc: 0.7623 -- iter: 4/4\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m0.56003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 773 | loss: 0.56003 - binary_acc: 0.7611 -- iter: 4/4\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m0.56041\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 774 | loss: 0.56041 - binary_acc: 0.7599 -- iter: 4/4\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m0.56075\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 775 | loss: 0.56075 - binary_acc: 0.7590 -- iter: 4/4\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m0.56106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 776 | loss: 0.56106 - binary_acc: 0.7581 -- iter: 4/4\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m0.56132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 777 | loss: 0.56132 - binary_acc: 0.7573 -- iter: 4/4\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m0.56156\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 778 | loss: 0.56156 - binary_acc: 0.7565 -- iter: 4/4\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m0.56177\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 779 | loss: 0.56177 - binary_acc: 0.7559 -- iter: 4/4\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m0.56195\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 780 | loss: 0.56195 - binary_acc: 0.7553 -- iter: 4/4\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m0.56211\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 781 | loss: 0.56211 - binary_acc: 0.7548 -- iter: 4/4\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m0.56227\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 782 | loss: 0.56227 - binary_acc: 0.7543 -- iter: 4/4\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m0.56239\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 783 | loss: 0.56239 - binary_acc: 0.7539 -- iter: 4/4\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m0.56249\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 784 | loss: 0.56249 - binary_acc: 0.7535 -- iter: 4/4\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m0.56258\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 785 | loss: 0.56258 - binary_acc: 0.7531 -- iter: 4/4\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m0.56266\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 786 | loss: 0.56266 - binary_acc: 0.7528 -- iter: 4/4\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m0.56272\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 787 | loss: 0.56272 - binary_acc: 0.7525 -- iter: 4/4\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m0.56277\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 788 | loss: 0.56277 - binary_acc: 0.7523 -- iter: 4/4\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m0.56281\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 789 | loss: 0.56281 - binary_acc: 0.7520 -- iter: 4/4\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m0.56283\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 790 | loss: 0.56283 - binary_acc: 0.7518 -- iter: 4/4\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m0.56285\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 791 | loss: 0.56285 - binary_acc: 0.7517 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m0.56285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 792 | loss: 0.56285 - binary_acc: 0.7515 -- iter: 4/4\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m0.56283\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 793 | loss: 0.56283 - binary_acc: 0.7513 -- iter: 4/4\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m0.56280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 794 | loss: 0.56280 - binary_acc: 0.7512 -- iter: 4/4\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m0.56275\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 795 | loss: 0.56275 - binary_acc: 0.7511 -- iter: 4/4\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m0.56267\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 796 | loss: 0.56267 - binary_acc: 0.7510 -- iter: 4/4\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m0.56255\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 797 | loss: 0.56255 - binary_acc: 0.7509 -- iter: 4/4\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m0.56235\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 798 | loss: 0.56235 - binary_acc: 0.7508 -- iter: 4/4\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.56201\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 799 | loss: 0.56201 - binary_acc: 0.7507 -- iter: 4/4\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.56129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 800 | loss: 0.56129 - binary_acc: 0.7506 -- iter: 4/4\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m0.55881\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 801 | loss: 0.55881 - binary_acc: 0.7506 -- iter: 4/4\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m0.54242\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 802 | loss: 0.54242 - binary_acc: 0.7755 -- iter: 4/4\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m0.52692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 803 | loss: 0.52692 - binary_acc: 0.7980 -- iter: 4/4\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m0.56203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 804 | loss: 0.56203 - binary_acc: 0.7682 -- iter: 4/4\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m0.54543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 805 | loss: 0.54543 - binary_acc: 0.7914 -- iter: 4/4\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m0.54610\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 806 | loss: 0.54610 - binary_acc: 0.7872 -- iter: 4/4\n",
      "--\n",
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m0.52427\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 807 | loss: 0.52427 - binary_acc: 0.8085 -- iter: 4/4\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m0.50404\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 808 | loss: 0.50404 - binary_acc: 0.8276 -- iter: 4/4\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m0.48571\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 809 | loss: 0.48571 - binary_acc: 0.8449 -- iter: 4/4\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m0.46914\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 810 | loss: 0.46914 - binary_acc: 0.8604 -- iter: 4/4\n",
      "--\n",
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m0.45419\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 811 | loss: 0.45419 - binary_acc: 0.8744 -- iter: 4/4\n",
      "--\n",
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m0.44070\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 812 | loss: 0.44070 - binary_acc: 0.8869 -- iter: 4/4\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m0.42853\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 813 | loss: 0.42853 - binary_acc: 0.8982 -- iter: 4/4\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m0.41756\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 814 | loss: 0.41756 - binary_acc: 0.9084 -- iter: 4/4\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m0.40766\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 815 | loss: 0.40766 - binary_acc: 0.9176 -- iter: 4/4\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m0.39874\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 816 | loss: 0.39874 - binary_acc: 0.9258 -- iter: 4/4\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m0.39069\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 817 | loss: 0.39069 - binary_acc: 0.9332 -- iter: 4/4\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m0.38343\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 818 | loss: 0.38343 - binary_acc: 0.9399 -- iter: 4/4\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m0.37688\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 819 | loss: 0.37688 - binary_acc: 0.9459 -- iter: 4/4\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m0.37098\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 820 | loss: 0.37098 - binary_acc: 0.9513 -- iter: 4/4\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m0.36565\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 821 | loss: 0.36565 - binary_acc: 0.9562 -- iter: 4/4\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m0.36085\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 822 | loss: 0.36085 - binary_acc: 0.9606 -- iter: 4/4\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m0.35651\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 823 | loss: 0.35651 - binary_acc: 0.9645 -- iter: 4/4\n",
      "--\n",
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m0.35260\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 824 | loss: 0.35260 - binary_acc: 0.9681 -- iter: 4/4\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m0.34907\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 825 | loss: 0.34907 - binary_acc: 0.9713 -- iter: 4/4\n",
      "--\n",
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m0.34588\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 826 | loss: 0.34588 - binary_acc: 0.9741 -- iter: 4/4\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m0.34300\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 827 | loss: 0.34300 - binary_acc: 0.9767 -- iter: 4/4\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m0.34040\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 828 | loss: 0.34040 - binary_acc: 0.9790 -- iter: 4/4\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m0.33806\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 829 | loss: 0.33806 - binary_acc: 0.9811 -- iter: 4/4\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m0.33594\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 830 | loss: 0.33594 - binary_acc: 0.9830 -- iter: 4/4\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m0.33402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 831 | loss: 0.33402 - binary_acc: 0.9847 -- iter: 4/4\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m0.33229\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 832 | loss: 0.33229 - binary_acc: 0.9863 -- iter: 4/4\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m0.33072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 833 | loss: 0.33072 - binary_acc: 0.9876 -- iter: 4/4\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m0.32931\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 834 | loss: 0.32931 - binary_acc: 0.9889 -- iter: 4/4\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m0.32803\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 835 | loss: 0.32803 - binary_acc: 0.9900 -- iter: 4/4\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m0.32687\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 836 | loss: 0.32687 - binary_acc: 0.9910 -- iter: 4/4\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m0.32582\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 837 | loss: 0.32582 - binary_acc: 0.9919 -- iter: 4/4\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m0.32487\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 838 | loss: 0.32487 - binary_acc: 0.9927 -- iter: 4/4\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m0.32401\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 839 | loss: 0.32401 - binary_acc: 0.9934 -- iter: 4/4\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m0.32323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 840 | loss: 0.32323 - binary_acc: 0.9941 -- iter: 4/4\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m0.32253\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 841 | loss: 0.32253 - binary_acc: 0.9947 -- iter: 4/4\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m0.32189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 842 | loss: 0.32189 - binary_acc: 0.9952 -- iter: 4/4\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m0.32131\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 843 | loss: 0.32131 - binary_acc: 0.9957 -- iter: 4/4\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m0.32078\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 844 | loss: 0.32078 - binary_acc: 0.9961 -- iter: 4/4\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m0.32030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 845 | loss: 0.32030 - binary_acc: 0.9965 -- iter: 4/4\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m0.31986\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 846 | loss: 0.31986 - binary_acc: 0.9969 -- iter: 4/4\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m0.31947\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 847 | loss: 0.31947 - binary_acc: 0.9972 -- iter: 4/4\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m0.41814\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 848 | loss: 0.41814 - binary_acc: 0.8975 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m0.40793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 849 | loss: 0.40793 - binary_acc: 0.9077 -- iter: 4/4\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m0.39873\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 850 | loss: 0.39873 - binary_acc: 0.9169 -- iter: 4/4\n",
      "--\n",
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m0.39044\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 851 | loss: 0.39044 - binary_acc: 0.9252 -- iter: 4/4\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m0.38298\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 852 | loss: 0.38298 - binary_acc: 0.9327 -- iter: 4/4\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m0.37626\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 853 | loss: 0.37626 - binary_acc: 0.9394 -- iter: 4/4\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m0.37021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 854 | loss: 0.37021 - binary_acc: 0.9455 -- iter: 4/4\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m0.36477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 855 | loss: 0.36477 - binary_acc: 0.9510 -- iter: 4/4\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m0.35986\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 856 | loss: 0.35986 - binary_acc: 0.9559 -- iter: 4/4\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m0.35544\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 857 | loss: 0.35544 - binary_acc: 0.9603 -- iter: 4/4\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m0.35146\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 858 | loss: 0.35146 - binary_acc: 0.9642 -- iter: 4/4\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m0.34787\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 859 | loss: 0.34787 - binary_acc: 0.9678 -- iter: 4/4\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.34464\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 860 | loss: 0.34464 - binary_acc: 0.9710 -- iter: 4/4\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.34173\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 861 | loss: 0.34173 - binary_acc: 0.9739 -- iter: 4/4\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.33911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 862 | loss: 0.33911 - binary_acc: 0.9765 -- iter: 4/4\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.33674\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 863 | loss: 0.33674 - binary_acc: 0.9789 -- iter: 4/4\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m0.33461\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 864 | loss: 0.33461 - binary_acc: 0.9810 -- iter: 4/4\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m0.33269\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 865 | loss: 0.33269 - binary_acc: 0.9829 -- iter: 4/4\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m0.33096\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 866 | loss: 0.33096 - binary_acc: 0.9846 -- iter: 4/4\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.32940\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 867 | loss: 0.32940 - binary_acc: 0.9861 -- iter: 4/4\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.32799\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 868 | loss: 0.32799 - binary_acc: 0.9875 -- iter: 4/4\n",
      "--\n",
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.32673\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 869 | loss: 0.32673 - binary_acc: 0.9888 -- iter: 4/4\n",
      "--\n",
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m0.32558\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 870 | loss: 0.32558 - binary_acc: 0.9909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m0.32455\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 871 | loss: 0.32455 - binary_acc: 0.9909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m0.32362\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 872 | loss: 0.32362 - binary_acc: 0.9918 -- iter: 4/4\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m0.32278\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 873 | loss: 0.32278 - binary_acc: 0.9926 -- iter: 4/4\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m0.32202\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 874 | loss: 0.32202 - binary_acc: 0.9934 -- iter: 4/4\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m0.32133\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 875 | loss: 0.32133 - binary_acc: 0.9940 -- iter: 4/4\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m0.32072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 876 | loss: 0.32072 - binary_acc: 0.9946 -- iter: 4/4\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m0.32016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 877 | loss: 0.32016 - binary_acc: 0.9952 -- iter: 4/4\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m0.31965\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 878 | loss: 0.31965 - binary_acc: 0.9957 -- iter: 4/4\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m0.31919\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 879 | loss: 0.31919 - binary_acc: 0.9961 -- iter: 4/4\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m0.31878\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 880 | loss: 0.31878 - binary_acc: 0.9965 -- iter: 4/4\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m0.31841\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 881 | loss: 0.31841 - binary_acc: 0.9968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m0.31807\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 882 | loss: 0.31807 - binary_acc: 0.9971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m0.31776\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 883 | loss: 0.31776 - binary_acc: 0.9974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m0.31749\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 884 | loss: 0.31749 - binary_acc: 0.9977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m0.31724\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 885 | loss: 0.31724 - binary_acc: 0.9979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m0.31701\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 886 | loss: 0.31701 - binary_acc: 0.9981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m0.31680\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 887 | loss: 0.31680 - binary_acc: 0.9983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m0.31661\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 888 | loss: 0.31661 - binary_acc: 0.9985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m0.31644\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 889 | loss: 0.31644 - binary_acc: 0.9986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m0.31629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 890 | loss: 0.31629 - binary_acc: 0.9988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m0.31615\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 891 | loss: 0.31615 - binary_acc: 0.9989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m0.31602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 892 | loss: 0.31602 - binary_acc: 0.9990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m0.31590\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 893 | loss: 0.31590 - binary_acc: 0.9991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m0.31579\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 894 | loss: 0.31579 - binary_acc: 0.9992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m0.31570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 895 | loss: 0.31570 - binary_acc: 0.9993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m0.31561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 896 | loss: 0.31561 - binary_acc: 0.9993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m0.31552\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 897 | loss: 0.31552 - binary_acc: 0.9994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m0.31545\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 898 | loss: 0.31545 - binary_acc: 0.9995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m0.31538\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 899 | loss: 0.31538 - binary_acc: 0.9995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m0.31532\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 900 | loss: 0.31532 - binary_acc: 0.9996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m0.31526\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 901 | loss: 0.31526 - binary_acc: 0.9996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m0.31520\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 902 | loss: 0.31520 - binary_acc: 0.9997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m0.31515\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 903 | loss: 0.31515 - binary_acc: 0.9997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m0.31511\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 904 | loss: 0.31511 - binary_acc: 0.9997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m0.31507\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 905 | loss: 0.31507 - binary_acc: 0.9997 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m0.31503\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 906 | loss: 0.31503 - binary_acc: 0.9998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m0.31499\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 907 | loss: 0.31499 - binary_acc: 0.9998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m0.31496\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 908 | loss: 0.31496 - binary_acc: 0.9998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m0.31492\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 909 | loss: 0.31492 - binary_acc: 0.9998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m0.31489\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 910 | loss: 0.31489 - binary_acc: 0.9999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m0.31487\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 911 | loss: 0.31487 - binary_acc: 0.9999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m0.31484\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 912 | loss: 0.31484 - binary_acc: 0.9999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.31481\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 913 | loss: 0.31481 - binary_acc: 0.9999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.31479\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 914 | loss: 0.31479 - binary_acc: 0.9999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.31477\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 915 | loss: 0.31477 - binary_acc: 0.9999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m0.36453\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 916 | loss: 0.36453 - binary_acc: 0.9499 -- iter: 4/4\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m0.35953\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 917 | loss: 0.35953 - binary_acc: 0.9549 -- iter: 4/4\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m0.35504\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 918 | loss: 0.35504 - binary_acc: 0.9594 -- iter: 4/4\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m0.35099\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 919 | loss: 0.35099 - binary_acc: 0.9635 -- iter: 4/4\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m0.34734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 920 | loss: 0.34734 - binary_acc: 0.9671 -- iter: 4/4\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m0.34406\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 921 | loss: 0.34406 - binary_acc: 0.9704 -- iter: 4/4\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m0.34111\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 922 | loss: 0.34111 - binary_acc: 0.9734 -- iter: 4/4\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m0.33845\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 923 | loss: 0.33845 - binary_acc: 0.9760 -- iter: 4/4\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m0.33605\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 924 | loss: 0.33605 - binary_acc: 0.9784 -- iter: 4/4\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m0.33390\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 925 | loss: 0.33390 - binary_acc: 0.9806 -- iter: 4/4\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m0.33196\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 926 | loss: 0.33196 - binary_acc: 0.9825 -- iter: 4/4\n",
      "--\n",
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m0.33021\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 927 | loss: 0.33021 - binary_acc: 0.9843 -- iter: 4/4\n",
      "--\n",
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m0.32863\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 928 | loss: 0.32863 - binary_acc: 0.9859 -- iter: 4/4\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m0.32722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 929 | loss: 0.32722 - binary_acc: 0.9873 -- iter: 4/4\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m0.32594\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 930 | loss: 0.32594 - binary_acc: 0.9885 -- iter: 4/4\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m0.32479\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 931 | loss: 0.32479 - binary_acc: 0.9897 -- iter: 4/4\n",
      "--\n",
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m0.32375\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 932 | loss: 0.32375 - binary_acc: 0.9907 -- iter: 4/4\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m0.32282\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 933 | loss: 0.32282 - binary_acc: 0.9916 -- iter: 4/4\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m0.32198\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 934 | loss: 0.32198 - binary_acc: 0.9925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m0.32122\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 935 | loss: 0.32122 - binary_acc: 0.9932 -- iter: 4/4\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m0.32054\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 936 | loss: 0.32054 - binary_acc: 0.9939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.31992\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 937 | loss: 0.31992 - binary_acc: 0.9945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m0.31937\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 938 | loss: 0.31937 - binary_acc: 0.9951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m0.31887\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 939 | loss: 0.31887 - binary_acc: 0.9956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m0.31842\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 940 | loss: 0.31842 - binary_acc: 0.9960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m0.31801\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 941 | loss: 0.31801 - binary_acc: 0.9964 -- iter: 4/4\n",
      "--\n",
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m0.31765\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 942 | loss: 0.31765 - binary_acc: 0.9968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m0.31732\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 943 | loss: 0.31732 - binary_acc: 0.9971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m0.31702\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 944 | loss: 0.31702 - binary_acc: 0.9974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m0.31675\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 945 | loss: 0.31675 - binary_acc: 0.9976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m0.31651\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 946 | loss: 0.31651 - binary_acc: 0.9979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m0.31629\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 947 | loss: 0.31629 - binary_acc: 0.9981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m0.31609\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 948 | loss: 0.31609 - binary_acc: 0.9983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m0.31591\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 949 | loss: 0.31591 - binary_acc: 0.9985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m0.31575\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 950 | loss: 0.31575 - binary_acc: 0.9986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m0.31561\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 951 | loss: 0.31561 - binary_acc: 0.9987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m0.31547\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 952 | loss: 0.31547 - binary_acc: 0.9989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m0.31535\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 953 | loss: 0.31535 - binary_acc: 0.9990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m0.31525\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 954 | loss: 0.31525 - binary_acc: 0.9991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m0.31515\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 955 | loss: 0.31515 - binary_acc: 0.9992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m0.31506\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 956 | loss: 0.31506 - binary_acc: 0.9993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m0.31498\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 957 | loss: 0.31498 - binary_acc: 0.9993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m0.31491\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 958 | loss: 0.31491 - binary_acc: 0.9994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m0.31484\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 959 | loss: 0.31484 - binary_acc: 0.9995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.31478\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 960 | loss: 0.31478 - binary_acc: 0.9995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m0.31473\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 961 | loss: 0.31473 - binary_acc: 0.9996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m0.31468\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 962 | loss: 0.31468 - binary_acc: 0.9996 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m0.31463\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 963 | loss: 0.31463 - binary_acc: 0.9996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m0.31459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 964 | loss: 0.31459 - binary_acc: 0.9997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m0.31455\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 965 | loss: 0.31455 - binary_acc: 0.9997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m0.31452\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 966 | loss: 0.31452 - binary_acc: 0.9997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m0.31448\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 967 | loss: 0.31448 - binary_acc: 0.9998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m0.31446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 968 | loss: 0.31446 - binary_acc: 0.9998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m0.31443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 969 | loss: 0.31443 - binary_acc: 0.9998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m0.31440\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 970 | loss: 0.31440 - binary_acc: 0.9998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m0.31438\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 971 | loss: 0.31438 - binary_acc: 0.9998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m0.31436\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 972 | loss: 0.31436 - binary_acc: 0.9999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m0.31434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 973 | loss: 0.31434 - binary_acc: 0.9999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m0.31432\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 974 | loss: 0.31432 - binary_acc: 0.9999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m0.31431\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 975 | loss: 0.31431 - binary_acc: 0.9999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m0.36414\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 976 | loss: 0.36414 - binary_acc: 0.9499 -- iter: 4/4\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m0.35914\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 977 | loss: 0.35914 - binary_acc: 0.9549 -- iter: 4/4\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m0.35465\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 978 | loss: 0.35465 - binary_acc: 0.9594 -- iter: 4/4\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m0.35060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 979 | loss: 0.35060 - binary_acc: 0.9635 -- iter: 4/4\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m0.34695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 980 | loss: 0.34695 - binary_acc: 0.9671 -- iter: 4/4\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m0.34367\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 981 | loss: 0.34367 - binary_acc: 0.9704 -- iter: 4/4\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m0.34072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 982 | loss: 0.34072 - binary_acc: 0.9734 -- iter: 4/4\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m0.33806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 983 | loss: 0.33806 - binary_acc: 0.9760 -- iter: 4/4\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m0.33566\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 984 | loss: 0.33566 - binary_acc: 0.9784 -- iter: 4/4\n",
      "--\n",
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m0.33351\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 985 | loss: 0.33351 - binary_acc: 0.9806 -- iter: 4/4\n",
      "--\n",
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m0.33157\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 986 | loss: 0.33157 - binary_acc: 0.9825 -- iter: 4/4\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m0.32982\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 987 | loss: 0.32982 - binary_acc: 0.9843 -- iter: 4/4\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m0.32825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 988 | loss: 0.32825 - binary_acc: 0.9859 -- iter: 4/4\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m0.32684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 989 | loss: 0.32684 - binary_acc: 0.9873 -- iter: 4/4\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m0.32556\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 990 | loss: 0.32556 - binary_acc: 0.9885 -- iter: 4/4\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m0.32442\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 991 | loss: 0.32442 - binary_acc: 0.9897 -- iter: 4/4\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m0.32338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 992 | loss: 0.32338 - binary_acc: 0.9907 -- iter: 4/4\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m0.32245\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 993 | loss: 0.32245 - binary_acc: 0.9916 -- iter: 4/4\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m0.32162\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 994 | loss: 0.32162 - binary_acc: 0.9925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m0.32086\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 995 | loss: 0.32086 - binary_acc: 0.9932 -- iter: 4/4\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m0.32018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 996 | loss: 0.32018 - binary_acc: 0.9939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m0.31957\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 997 | loss: 0.31957 - binary_acc: 0.9945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m0.31902\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 998 | loss: 0.31902 - binary_acc: 0.9951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m0.31853\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 999 | loss: 0.31853 - binary_acc: 0.9956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.31808\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1000 | loss: 0.31808 - binary_acc: 0.9960 -- iter: 4/4\n",
      "--\n",
      "Final Updated Weights: [[ 3.6725273]\n",
      " [-3.6902966]]\n",
      "Expected:  [False, True, True, False]\n",
      "Predicted:  [False, True, True, False]\n",
      "Efficiency: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "Y = [[0], [1], [1], [0]]\n",
    "# Define the network architecture\n",
    "input_layer = input_data(shape=[None, 2])\n",
    "hidden_layer = fully_connected(input_layer, 2, activation='tanh')\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='tanh')\n",
    "# Define the regression layer using the output layer\n",
    "regression_layer = regression(output_layer, optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
    "# Create the model using the regression layer\n",
    "model = tflearn.DNN(regression_layer)\n",
    "# Train the model\n",
    "model.fit(X, Y, n_epoch=1000, show_metric=True)\n",
    "# Get the final updated weights of the model\n",
    "final_weights = model.get_weights(output_layer.W)\n",
    "print(\"Final Updated Weights:\", final_weights)\n",
    "# Predict the output\n",
    "predicted = model.predict(X)\n",
    "predicted_classes = [i[0] > 0 for i in predicted]\n",
    "# Convert Y to list of bool values\n",
    "expected_classes = [i[0] > 0 for i in Y]\n",
    "# Compare and calculate efficiency\n",
    "correct_predictions = sum(1 for expected, predicted in zip(expected_classes, predicted_classes) if expected == predicted)\n",
    "total_predictions = len(expected_classes)\n",
    "efficiency = (correct_predictions / total_predictions) * 100\n",
    "print(\"Expected: \", expected_classes)\n",
    "print(\"Predicted: \", predicted_classes)\n",
    "print(\"Efficiency: {:.2f}%\".format(efficiency))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cba76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\91960\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: AQ0F4R\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.122s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.62383\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 002 | loss: 0.62383 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.68054\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 003 | loss: 0.68054 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.69000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 004 | loss: 0.69000 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.69218\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 005 | loss: 0.69218 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.69280\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 006 | loss: 0.69280 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.69301\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 007 | loss: 0.69301 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 008 | loss: 0.69309 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 009 | loss: 0.69312 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 010 | loss: 0.69313 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 011 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 012 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 013 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 014 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 015 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 016 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 017 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 018 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 019 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 020 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 021 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 022 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 023 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 024 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 025 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 026 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 027 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 028 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 029 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 030 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 031 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 032 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 033 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 034 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 035 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 036 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 037 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 038 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 039 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 040 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 041 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 042 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 043 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 044 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 045 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 046 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 047 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 048 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 049 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 050 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 051 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 052 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 053 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 054 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 055 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 056 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 057 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 058 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 059 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 060 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 061 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 062 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 063 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 064 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 065 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 066 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 067 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 068 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 069 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 070 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 071 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 072 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 073 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 074 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 075 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 076 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 077 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 078 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 079 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 080 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 081 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 082 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 083 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 084 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 085 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 086 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 087 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 088 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 089 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 090 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 091 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 092 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 093 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 094 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 095 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 096 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 097 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 098 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 099 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 100 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 101 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 102 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 103 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 104 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 105 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 106 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 107 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 108 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 109 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 110 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 111 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 112 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 113 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 114 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 115 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 116 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 117 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 118 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 119 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 120 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 121 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 122 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 123 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 124 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 125 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 126 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 127 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 128 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 129 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 130 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 131 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 132 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 133 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 134 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 135 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 136 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 137 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 138 | loss: 0.69313 - binary_acc: 0.5500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 139 | loss: 0.69313 - binary_acc: 0.5450 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 140 | loss: 0.69313 - binary_acc: 0.5405 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 141 | loss: 0.69314 - binary_acc: 0.5364 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 142 | loss: 0.69314 - binary_acc: 0.5328 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 143 | loss: 0.69314 - binary_acc: 0.5295 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 144 | loss: 0.69314 - binary_acc: 0.5266 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 145 | loss: 0.69314 - binary_acc: 0.5239 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 146 | loss: 0.69314 - binary_acc: 0.5215 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 147 | loss: 0.69314 - binary_acc: 0.5194 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 148 | loss: 0.69314 - binary_acc: 0.5174 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 149 | loss: 0.69314 - binary_acc: 0.5157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 150 | loss: 0.69314 - binary_acc: 0.5141 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 151 | loss: 0.69314 - binary_acc: 0.5127 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 152 | loss: 0.69314 - binary_acc: 0.5114 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 153 | loss: 0.69314 - binary_acc: 0.5103 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 154 | loss: 0.69314 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 155 | loss: 0.69314 - binary_acc: 0.5083 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 156 | loss: 0.69315 - binary_acc: 0.5075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 157 | loss: 0.69315 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 158 | loss: 0.69315 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 159 | loss: 0.69315 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 160 | loss: 0.69315 - binary_acc: 0.5049 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 161 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 162 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 163 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 164 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 165 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 166 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 167 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 168 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 169 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 170 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 171 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 172 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 173 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 174 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 175 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 176 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 177 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 178 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 179 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 180 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 181 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 182 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 183 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 184 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.69307\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 185 | loss: 0.69307 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.69307\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 186 | loss: 0.69307 - binary_acc: 0.5503 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.69308\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 187 | loss: 0.69308 - binary_acc: 0.5453 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 188 | loss: 0.69309 - binary_acc: 0.5408 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 189 | loss: 0.69309 - binary_acc: 0.5367 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 190 | loss: 0.69310 - binary_acc: 0.5330 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 191 | loss: 0.69311 - binary_acc: 0.5297 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 192 | loss: 0.69311 - binary_acc: 0.5267 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 193 | loss: 0.69312 - binary_acc: 0.5241 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 194 | loss: 0.69312 - binary_acc: 0.5217 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 195 | loss: 0.69312 - binary_acc: 0.5195 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 196 | loss: 0.69313 - binary_acc: 0.5175 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 197 | loss: 0.69313 - binary_acc: 0.5158 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 198 | loss: 0.69313 - binary_acc: 0.5142 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 199 | loss: 0.69313 - binary_acc: 0.5128 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 200 | loss: 0.69314 - binary_acc: 0.5115 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 201 | loss: 0.69314 - binary_acc: 0.5104 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 202 | loss: 0.69314 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 203 | loss: 0.69314 - binary_acc: 0.5084 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 204 | loss: 0.69314 - binary_acc: 0.5076 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 205 | loss: 0.69314 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 206 | loss: 0.69314 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 207 | loss: 0.69314 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 208 | loss: 0.69315 - binary_acc: 0.5050 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 209 | loss: 0.69315 - binary_acc: 0.5045 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 210 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 211 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 212 | loss: 0.69315 - binary_acc: 0.5033 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 213 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 214 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 215 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 216 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 217 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 218 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 219 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 220 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 221 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 222 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 223 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 224 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 225 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 226 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 227 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 228 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 229 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 230 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 231 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 232 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 233 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 234 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 235 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 236 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 237 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 238 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 239 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 240 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 241 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 242 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 243 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 244 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 245 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 246 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 247 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 248 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 249 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 250 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 251 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 252 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 253 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 254 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 255 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 256 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 257 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 258 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 259 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 260 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 261 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 262 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 263 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 264 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 265 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 266 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 267 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 268 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 269 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 270 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 271 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 272 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 273 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 274 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 275 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 276 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 277 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 278 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 279 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 280 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 281 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 282 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 283 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 284 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 285 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 286 | loss: 0.69336 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 287 | loss: 0.69334 - binary_acc: 0.4550 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 288 | loss: 0.69332 - binary_acc: 0.4595 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 289 | loss: 0.69331 - binary_acc: 0.4886 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 290 | loss: 0.69329 - binary_acc: 0.4897 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 291 | loss: 0.69328 - binary_acc: 0.4907 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 292 | loss: 0.69326 - binary_acc: 0.4917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 293 | loss: 0.69325 - binary_acc: 0.4925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 294 | loss: 0.69324 - binary_acc: 0.4932 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 295 | loss: 0.69323 - binary_acc: 0.4939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 296 | loss: 0.69322 - binary_acc: 0.4945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 297 | loss: 0.69322 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 298 | loss: 0.69321 - binary_acc: 0.4956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 299 | loss: 0.69320 - binary_acc: 0.4960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 300 | loss: 0.69320 - binary_acc: 0.4964 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 301 | loss: 0.69319 - binary_acc: 0.4968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 302 | loss: 0.69319 - binary_acc: 0.4971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 303 | loss: 0.69318 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 304 | loss: 0.69318 - binary_acc: 0.4976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 305 | loss: 0.69318 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 306 | loss: 0.69317 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 307 | loss: 0.69317 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 308 | loss: 0.69317 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 309 | loss: 0.69317 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 310 | loss: 0.69316 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 311 | loss: 0.69316 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 312 | loss: 0.69316 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 313 | loss: 0.69316 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 314 | loss: 0.69316 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 315 | loss: 0.69316 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 316 | loss: 0.69316 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 317 | loss: 0.69316 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 318 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 319 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 320 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 321 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 322 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 323 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 324 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 325 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 326 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 327 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 328 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 329 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 330 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 331 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 332 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 333 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 334 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 335 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 336 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 337 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 338 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 339 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 340 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 341 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 342 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 343 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 344 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 345 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 346 | loss: 0.69312 - binary_acc: 0.5500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 347 | loss: 0.69313 - binary_acc: 0.5700 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 348 | loss: 0.69313 - binary_acc: 0.5630 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 349 | loss: 0.69313 - binary_acc: 0.5567 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 350 | loss: 0.69313 - binary_acc: 0.5510 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 351 | loss: 0.69313 - binary_acc: 0.5459 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 352 | loss: 0.69314 - binary_acc: 0.5413 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 353 | loss: 0.69314 - binary_acc: 0.5372 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 354 | loss: 0.69314 - binary_acc: 0.5335 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 355 | loss: 0.69314 - binary_acc: 0.5301 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 356 | loss: 0.69314 - binary_acc: 0.5271 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 357 | loss: 0.69314 - binary_acc: 0.5244 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 358 | loss: 0.69314 - binary_acc: 0.5220 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 359 | loss: 0.69314 - binary_acc: 0.5198 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 360 | loss: 0.69314 - binary_acc: 0.5178 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 361 | loss: 0.69314 - binary_acc: 0.5160 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 362 | loss: 0.69314 - binary_acc: 0.5144 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 363 | loss: 0.69314 - binary_acc: 0.5130 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 364 | loss: 0.69314 - binary_acc: 0.5117 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 365 | loss: 0.69314 - binary_acc: 0.5105 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 366 | loss: 0.69314 - binary_acc: 0.5095 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 367 | loss: 0.69314 - binary_acc: 0.5085 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 368 | loss: 0.69315 - binary_acc: 0.5077 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 369 | loss: 0.69315 - binary_acc: 0.5069 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 370 | loss: 0.69315 - binary_acc: 0.5062 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 371 | loss: 0.69315 - binary_acc: 0.5056 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 372 | loss: 0.69315 - binary_acc: 0.5050 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 373 | loss: 0.69315 - binary_acc: 0.5045 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 374 | loss: 0.69315 - binary_acc: 0.5041 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 375 | loss: 0.69315 - binary_acc: 0.5037 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 376 | loss: 0.69315 - binary_acc: 0.5033 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 377 | loss: 0.69315 - binary_acc: 0.5030 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 378 | loss: 0.69315 - binary_acc: 0.5027 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 379 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 380 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 381 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 382 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 383 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 384 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 385 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 386 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 387 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 388 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 389 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 390 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 391 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 392 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 393 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 394 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 395 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 396 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 397 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 398 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 399 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 400 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 401 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 402 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 403 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 404 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 405 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 406 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 407 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 408 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 409 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 410 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 411 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 412 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 413 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 414 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 415 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 416 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 417 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 418 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 419 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 420 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 421 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 422 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 423 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 424 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 425 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 426 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 427 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 428 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 429 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 430 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 431 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 432 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 433 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 434 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 435 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 436 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 437 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 438 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 439 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 440 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 441 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 442 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 443 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 444 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 445 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 446 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 447 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 448 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 449 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 450 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 451 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 452 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 453 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 454 | loss: 0.69327 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 455 | loss: 0.69326 - binary_acc: 0.4550 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 456 | loss: 0.69325 - binary_acc: 0.4595 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 457 | loss: 0.69324 - binary_acc: 0.4636 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 458 | loss: 0.69323 - binary_acc: 0.4672 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 459 | loss: 0.69322 - binary_acc: 0.4705 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 460 | loss: 0.69321 - binary_acc: 0.4734 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 461 | loss: 0.69321 - binary_acc: 0.4761 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 462 | loss: 0.69320 - binary_acc: 0.4785 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 463 | loss: 0.69320 - binary_acc: 0.4806 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 464 | loss: 0.69319 - binary_acc: 0.4826 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 465 | loss: 0.69319 - binary_acc: 0.4843 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 466 | loss: 0.69318 - binary_acc: 0.4859 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 467 | loss: 0.69318 - binary_acc: 0.4873 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 468 | loss: 0.69318 - binary_acc: 0.4886 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 469 | loss: 0.69317 - binary_acc: 0.4897 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 470 | loss: 0.69317 - binary_acc: 0.4907 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 471 | loss: 0.69317 - binary_acc: 0.4917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 472 | loss: 0.69317 - binary_acc: 0.4925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 473 | loss: 0.69316 - binary_acc: 0.4932 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 474 | loss: 0.69316 - binary_acc: 0.4939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 475 | loss: 0.69316 - binary_acc: 0.4945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 476 | loss: 0.69316 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 477 | loss: 0.69316 - binary_acc: 0.4956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 478 | loss: 0.69315 - binary_acc: 0.4960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 479 | loss: 0.69315 - binary_acc: 0.4714 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 480 | loss: 0.69315 - binary_acc: 0.4743 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 481 | loss: 0.69315 - binary_acc: 0.4768 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 482 | loss: 0.69315 - binary_acc: 0.4792 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 483 | loss: 0.69315 - binary_acc: 0.4812 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 484 | loss: 0.69315 - binary_acc: 0.4831 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 485 | loss: 0.69315 - binary_acc: 0.4848 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 486 | loss: 0.69315 - binary_acc: 0.4863 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 487 | loss: 0.69315 - binary_acc: 0.4877 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 488 | loss: 0.69315 - binary_acc: 0.4889 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 489 | loss: 0.69315 - binary_acc: 0.4900 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 490 | loss: 0.69315 - binary_acc: 0.4910 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 491 | loss: 0.69315 - binary_acc: 0.4919 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 492 | loss: 0.69315 - binary_acc: 0.4927 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 493 | loss: 0.69315 - binary_acc: 0.4935 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 494 | loss: 0.69315 - binary_acc: 0.4941 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 495 | loss: 0.69315 - binary_acc: 0.4947 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 496 | loss: 0.69315 - binary_acc: 0.4952 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 497 | loss: 0.69315 - binary_acc: 0.4957 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 498 | loss: 0.69315 - binary_acc: 0.4961 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 499 | loss: 0.69315 - binary_acc: 0.4965 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 500 | loss: 0.69315 - binary_acc: 0.4969 -- iter: 4/4\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 501 | loss: 0.69315 - binary_acc: 0.4972 -- iter: 4/4\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 502 | loss: 0.69315 - binary_acc: 0.4975 -- iter: 4/4\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 503 | loss: 0.69315 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 504 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 505 | loss: 0.69315 - binary_acc: 0.4982 -- iter: 4/4\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 506 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 507 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 508 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 509 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 510 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 511 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 512 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 513 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 514 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 515 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 516 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 517 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 518 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 519 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 520 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 521 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 522 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 523 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 524 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 525 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 526 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 527 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 528 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 529 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 530 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 531 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 532 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 533 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 534 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 535 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 536 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 537 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 538 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 539 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 540 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 541 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 542 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 543 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 544 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 545 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 546 | loss: 0.69311 - binary_acc: 0.5500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 547 | loss: 0.69312 - binary_acc: 0.5450 -- iter: 4/4\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 548 | loss: 0.69312 - binary_acc: 0.5405 -- iter: 4/4\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 549 | loss: 0.69312 - binary_acc: 0.5364 -- iter: 4/4\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 550 | loss: 0.69313 - binary_acc: 0.5328 -- iter: 4/4\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 551 | loss: 0.69313 - binary_acc: 0.5295 -- iter: 4/4\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 552 | loss: 0.69313 - binary_acc: 0.5266 -- iter: 4/4\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 553 | loss: 0.69313 - binary_acc: 0.5239 -- iter: 4/4\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 554 | loss: 0.69313 - binary_acc: 0.5215 -- iter: 4/4\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 555 | loss: 0.69314 - binary_acc: 0.5194 -- iter: 4/4\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 556 | loss: 0.69314 - binary_acc: 0.5174 -- iter: 4/4\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 557 | loss: 0.69314 - binary_acc: 0.5157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 558 | loss: 0.69314 - binary_acc: 0.5141 -- iter: 4/4\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 559 | loss: 0.69314 - binary_acc: 0.5127 -- iter: 4/4\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 560 | loss: 0.69314 - binary_acc: 0.5114 -- iter: 4/4\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 561 | loss: 0.69314 - binary_acc: 0.5103 -- iter: 4/4\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.69299\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 562 | loss: 0.69299 - binary_acc: 0.5593 -- iter: 4/4\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.69301\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 563 | loss: 0.69301 - binary_acc: 0.5533 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.69303\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 564 | loss: 0.69303 - binary_acc: 0.5480 -- iter: 4/4\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.69304\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 565 | loss: 0.69304 - binary_acc: 0.5432 -- iter: 4/4\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.69306\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 566 | loss: 0.69306 - binary_acc: 0.5389 -- iter: 4/4\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.69307\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 567 | loss: 0.69307 - binary_acc: 0.5350 -- iter: 4/4\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.69308\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 568 | loss: 0.69308 - binary_acc: 0.5315 -- iter: 4/4\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 569 | loss: 0.69309 - binary_acc: 0.5283 -- iter: 4/4\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 570 | loss: 0.69310 - binary_acc: 0.5255 -- iter: 4/4\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 571 | loss: 0.69310 - binary_acc: 0.5230 -- iter: 4/4\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 572 | loss: 0.69311 - binary_acc: 0.5207 -- iter: 4/4\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 573 | loss: 0.69312 - binary_acc: 0.5186 -- iter: 4/4\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 574 | loss: 0.69312 - binary_acc: 0.5167 -- iter: 4/4\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 575 | loss: 0.69313 - binary_acc: 0.5151 -- iter: 4/4\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 576 | loss: 0.69313 - binary_acc: 0.5136 -- iter: 4/4\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 577 | loss: 0.69313 - binary_acc: 0.5122 -- iter: 4/4\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.69255\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 578 | loss: 0.69255 - binary_acc: 0.5610 -- iter: 4/4\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.69267\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 579 | loss: 0.69267 - binary_acc: 0.5549 -- iter: 4/4\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.69275\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 580 | loss: 0.69275 - binary_acc: 0.5494 -- iter: 4/4\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.69281\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 581 | loss: 0.69281 - binary_acc: 0.5445 -- iter: 4/4\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.69286\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 582 | loss: 0.69286 - binary_acc: 0.5400 -- iter: 4/4\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.69291\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 583 | loss: 0.69291 - binary_acc: 0.5360 -- iter: 4/4\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.69294\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 584 | loss: 0.69294 - binary_acc: 0.5324 -- iter: 4/4\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.69298\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 585 | loss: 0.69298 - binary_acc: 0.5292 -- iter: 4/4\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.69300\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 586 | loss: 0.69300 - binary_acc: 0.5263 -- iter: 4/4\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.69302\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 587 | loss: 0.69302 - binary_acc: 0.5236 -- iter: 4/4\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.69304\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 588 | loss: 0.69304 - binary_acc: 0.5213 -- iter: 4/4\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.69305\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 589 | loss: 0.69305 - binary_acc: 0.5191 -- iter: 4/4\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.69306\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 590 | loss: 0.69306 - binary_acc: 0.5172 -- iter: 4/4\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.69306\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 591 | loss: 0.69306 - binary_acc: 0.5155 -- iter: 4/4\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.69307\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 592 | loss: 0.69307 - binary_acc: 0.5140 -- iter: 4/4\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.69306\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 593 | loss: 0.69306 - binary_acc: 0.5126 -- iter: 4/4\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.69306\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 594 | loss: 0.69306 - binary_acc: 0.5113 -- iter: 4/4\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.69305\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 595 | loss: 0.69305 - binary_acc: 0.5102 -- iter: 4/4\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.69304\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 596 | loss: 0.69304 - binary_acc: 0.5092 -- iter: 4/4\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.69303\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 597 | loss: 0.69303 - binary_acc: 0.5082 -- iter: 4/4\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.69301\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 598 | loss: 0.69301 - binary_acc: 0.5074 -- iter: 4/4\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.69299\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 599 | loss: 0.69299 - binary_acc: 0.5067 -- iter: 4/4\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.69296\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 600 | loss: 0.69296 - binary_acc: 0.5060 -- iter: 4/4\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.69292\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 601 | loss: 0.69292 - binary_acc: 0.5054 -- iter: 4/4\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.69287\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 602 | loss: 0.69287 - binary_acc: 0.5049 -- iter: 4/4\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.69281\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 603 | loss: 0.69281 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.69274\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 604 | loss: 0.69274 - binary_acc: 0.5039 -- iter: 4/4\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.69264\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 605 | loss: 0.69264 - binary_acc: 0.5035 -- iter: 4/4\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.69252\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 606 | loss: 0.69252 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.69235\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 607 | loss: 0.69235 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.69212\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 608 | loss: 0.69212 - binary_acc: 0.5276 -- iter: 4/4\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.69180\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 609 | loss: 0.69180 - binary_acc: 0.5498 -- iter: 4/4\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.69135\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 610 | loss: 0.69135 - binary_acc: 0.5698 -- iter: 4/4\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.69068\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 611 | loss: 0.69068 - binary_acc: 0.5879 -- iter: 4/4\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.68969\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 612 | loss: 0.68969 - binary_acc: 0.6041 -- iter: 4/4\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.68821\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 613 | loss: 0.68821 - binary_acc: 0.6187 -- iter: 4/4\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.68598\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 614 | loss: 0.68598 - binary_acc: 0.6318 -- iter: 4/4\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.68274\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 615 | loss: 0.68274 - binary_acc: 0.6436 -- iter: 4/4\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.67827\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 616 | loss: 0.67827 - binary_acc: 0.6543 -- iter: 4/4\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.67262\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 617 | loss: 0.67262 - binary_acc: 0.6638 -- iter: 4/4\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.66609\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 618 | loss: 0.66609 - binary_acc: 0.6724 -- iter: 4/4\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.65914\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 619 | loss: 0.65914 - binary_acc: 0.6802 -- iter: 4/4\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.68827\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 620 | loss: 0.68827 - binary_acc: 0.6372 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.68268\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 621 | loss: 0.68268 - binary_acc: 0.6485 -- iter: 4/4\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.67749\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 622 | loss: 0.67749 - binary_acc: 0.6586 -- iter: 4/4\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.67783\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 623 | loss: 0.67783 - binary_acc: 0.6428 -- iter: 4/4\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.68411\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 624 | loss: 0.68411 - binary_acc: 0.6285 -- iter: 4/4\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.67464\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 625 | loss: 0.67464 - binary_acc: 0.6406 -- iter: 4/4\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.66509\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 626 | loss: 0.66509 - binary_acc: 0.6516 -- iter: 4/4\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.65612\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 627 | loss: 0.65612 - binary_acc: 0.6614 -- iter: 4/4\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.64782\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 628 | loss: 0.64782 - binary_acc: 0.6703 -- iter: 4/4\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.64019\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 629 | loss: 0.64019 - binary_acc: 0.6782 -- iter: 4/4\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.63321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 630 | loss: 0.63321 - binary_acc: 0.6854 -- iter: 4/4\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.62681\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 631 | loss: 0.62681 - binary_acc: 0.6919 -- iter: 4/4\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.62098\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 632 | loss: 0.62098 - binary_acc: 0.6977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.61565\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 633 | loss: 0.61565 - binary_acc: 0.7029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.61078\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 634 | loss: 0.61078 - binary_acc: 0.7076 -- iter: 4/4\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.60633\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 635 | loss: 0.60633 - binary_acc: 0.7119 -- iter: 4/4\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.60226\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 636 | loss: 0.60226 - binary_acc: 0.7157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.59851\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 637 | loss: 0.59851 - binary_acc: 0.7191 -- iter: 4/4\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.59504\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 638 | loss: 0.59504 - binary_acc: 0.7222 -- iter: 4/4\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.59178\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 639 | loss: 0.59178 - binary_acc: 0.7250 -- iter: 4/4\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.58865\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 640 | loss: 0.58865 - binary_acc: 0.7275 -- iter: 4/4\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.58551\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 641 | loss: 0.58551 - binary_acc: 0.7297 -- iter: 4/4\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.58208\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 642 | loss: 0.58208 - binary_acc: 0.7318 -- iter: 4/4\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.57774\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 643 | loss: 0.57774 - binary_acc: 0.7336 -- iter: 4/4\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.60802\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 644 | loss: 0.60802 - binary_acc: 0.6852 -- iter: 4/4\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.62621\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 645 | loss: 0.62621 - binary_acc: 0.6667 -- iter: 4/4\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.62954\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 646 | loss: 0.62954 - binary_acc: 0.6500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.62700\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 647 | loss: 0.62700 - binary_acc: 0.6600 -- iter: 4/4\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.62111\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 648 | loss: 0.62111 - binary_acc: 0.6690 -- iter: 4/4\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.61558\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 649 | loss: 0.61558 - binary_acc: 0.6771 -- iter: 4/4\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.61049\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 650 | loss: 0.61049 - binary_acc: 0.6844 -- iter: 4/4\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.60581\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 651 | loss: 0.60581 - binary_acc: 0.6910 -- iter: 4/4\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.60147\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 652 | loss: 0.60147 - binary_acc: 0.6969 -- iter: 4/4\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.59736\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 653 | loss: 0.59736 - binary_acc: 0.7022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.59320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 654 | loss: 0.59320 - binary_acc: 0.7070 -- iter: 4/4\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.58801\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 655 | loss: 0.58801 - binary_acc: 0.7113 -- iter: 4/4\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.57679\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 656 | loss: 0.57679 - binary_acc: 0.7151 -- iter: 4/4\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.56507\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 657 | loss: 0.56507 - binary_acc: 0.7186 -- iter: 4/4\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.56493\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 658 | loss: 0.56493 - binary_acc: 0.7218 -- iter: 4/4\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.55988\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 659 | loss: 0.55988 - binary_acc: 0.7246 -- iter: 4/4\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.54130\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 660 | loss: 0.54130 - binary_acc: 0.7521 -- iter: 4/4\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.52425\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 661 | loss: 0.52425 - binary_acc: 0.7769 -- iter: 4/4\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.50754\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 662 | loss: 0.50754 - binary_acc: 0.7992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.49106\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 663 | loss: 0.49106 - binary_acc: 0.8193 -- iter: 4/4\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.47500\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 664 | loss: 0.47500 - binary_acc: 0.8374 -- iter: 4/4\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.46037\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 665 | loss: 0.46037 - binary_acc: 0.8536 -- iter: 4/4\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.44707\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 666 | loss: 0.44707 - binary_acc: 0.8683 -- iter: 4/4\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.43500\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 667 | loss: 0.43500 - binary_acc: 0.8814 -- iter: 4/4\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.42404\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 668 | loss: 0.42404 - binary_acc: 0.8933 -- iter: 4/4\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.41411\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 669 | loss: 0.41411 - binary_acc: 0.9136 -- iter: 4/4\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.40509\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 670 | loss: 0.40509 - binary_acc: 0.9136 -- iter: 4/4\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.39692\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 671 | loss: 0.39692 - binary_acc: 0.9222 -- iter: 4/4\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.38951\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 672 | loss: 0.38951 - binary_acc: 0.9300 -- iter: 4/4\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.38280\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 673 | loss: 0.38280 - binary_acc: 0.9370 -- iter: 4/4\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.37671\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 674 | loss: 0.37671 - binary_acc: 0.9433 -- iter: 4/4\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.37119\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 675 | loss: 0.37119 - binary_acc: 0.9490 -- iter: 4/4\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.36618\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 676 | loss: 0.36618 - binary_acc: 0.9541 -- iter: 4/4\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.36164\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 677 | loss: 0.36164 - binary_acc: 0.9587 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.35753\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 678 | loss: 0.35753 - binary_acc: 0.9628 -- iter: 4/4\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.35380\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 679 | loss: 0.35380 - binary_acc: 0.9665 -- iter: 4/4\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.35041\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 680 | loss: 0.35041 - binary_acc: 0.9699 -- iter: 4/4\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.34734\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 681 | loss: 0.34734 - binary_acc: 0.9729 -- iter: 4/4\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.34456\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 682 | loss: 0.34456 - binary_acc: 0.9756 -- iter: 4/4\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.34203\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 683 | loss: 0.34203 - binary_acc: 0.9780 -- iter: 4/4\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.33973\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 684 | loss: 0.33973 - binary_acc: 0.9802 -- iter: 4/4\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.33765\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 685 | loss: 0.33765 - binary_acc: 0.9822 -- iter: 4/4\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.33575\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 686 | loss: 0.33575 - binary_acc: 0.9840 -- iter: 4/4\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.33403\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 687 | loss: 0.33403 - binary_acc: 0.9856 -- iter: 4/4\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.33247\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 688 | loss: 0.33247 - binary_acc: 0.9870 -- iter: 4/4\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.33105\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 689 | loss: 0.33105 - binary_acc: 0.9883 -- iter: 4/4\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.32975\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 690 | loss: 0.32975 - binary_acc: 0.9895 -- iter: 4/4\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.32857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 691 | loss: 0.32857 - binary_acc: 0.9905 -- iter: 4/4\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.32750\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 692 | loss: 0.32750 - binary_acc: 0.9915 -- iter: 4/4\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.32652\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 693 | loss: 0.32652 - binary_acc: 0.9923 -- iter: 4/4\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.32563\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 694 | loss: 0.32563 - binary_acc: 0.9931 -- iter: 4/4\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.32482\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 695 | loss: 0.32482 - binary_acc: 0.9938 -- iter: 4/4\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.32408\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 696 | loss: 0.32408 - binary_acc: 0.9944 -- iter: 4/4\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.32341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 697 | loss: 0.32341 - binary_acc: 0.9950 -- iter: 4/4\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.42132\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 698 | loss: 0.42132 - binary_acc: 0.8955 -- iter: 4/4\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.41094\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 699 | loss: 0.41094 - binary_acc: 0.9059 -- iter: 4/4\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.40158\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 700 | loss: 0.40158 - binary_acc: 0.9153 -- iter: 4/4\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.39315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 701 | loss: 0.39315 - binary_acc: 0.9238 -- iter: 4/4\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.38555\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 702 | loss: 0.38555 - binary_acc: 0.9314 -- iter: 4/4\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.37871\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 703 | loss: 0.37871 - binary_acc: 0.9383 -- iter: 4/4\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.37254\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 704 | loss: 0.37254 - binary_acc: 0.9445 -- iter: 4/4\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.36698\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 705 | loss: 0.36698 - binary_acc: 0.9500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.41132\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 706 | loss: 0.41132 - binary_acc: 0.9050 -- iter: 4/4\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.40188\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 707 | loss: 0.40188 - binary_acc: 0.9145 -- iter: 4/4\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.39338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 708 | loss: 0.39338 - binary_acc: 0.9231 -- iter: 4/4\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.38573\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 709 | loss: 0.38573 - binary_acc: 0.9307 -- iter: 4/4\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.37882\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 710 | loss: 0.37882 - binary_acc: 0.9377 -- iter: 4/4\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.37261\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 711 | loss: 0.37261 - binary_acc: 0.9439 -- iter: 4/4\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.36700\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 712 | loss: 0.36700 - binary_acc: 0.9495 -- iter: 4/4\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.36195\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 713 | loss: 0.36195 - binary_acc: 0.9546 -- iter: 4/4\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.35740\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 714 | loss: 0.35740 - binary_acc: 0.9632 -- iter: 4/4\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.35330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 715 | loss: 0.35330 - binary_acc: 0.9632 -- iter: 4/4\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.34961\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 716 | loss: 0.34961 - binary_acc: 0.9669 -- iter: 4/4\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.34627\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 717 | loss: 0.34627 - binary_acc: 0.9702 -- iter: 4/4\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.34327\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 718 | loss: 0.34327 - binary_acc: 0.9732 -- iter: 4/4\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.34056\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 719 | loss: 0.34056 - binary_acc: 0.9759 -- iter: 4/4\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.33812\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 720 | loss: 0.33812 - binary_acc: 0.9783 -- iter: 4/4\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.33591\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 721 | loss: 0.33591 - binary_acc: 0.9804 -- iter: 4/4\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.33392\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 722 | loss: 0.33392 - binary_acc: 0.9824 -- iter: 4/4\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.33213\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 723 | loss: 0.33213 - binary_acc: 0.9842 -- iter: 4/4\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.33051\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 724 | loss: 0.33051 - binary_acc: 0.9857 -- iter: 4/4\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.32905\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 725 | loss: 0.32905 - binary_acc: 0.9872 -- iter: 4/4\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.32773\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 726 | loss: 0.32773 - binary_acc: 0.9885 -- iter: 4/4\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.32654\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 727 | loss: 0.32654 - binary_acc: 0.9896 -- iter: 4/4\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.32547\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 728 | loss: 0.32547 - binary_acc: 0.9906 -- iter: 4/4\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.32450\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 729 | loss: 0.32450 - binary_acc: 0.9916 -- iter: 4/4\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.32362\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 730 | loss: 0.32362 - binary_acc: 0.9924 -- iter: 4/4\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.32282\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 731 | loss: 0.32282 - binary_acc: 0.9932 -- iter: 4/4\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.32211\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 732 | loss: 0.32211 - binary_acc: 0.9939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.32146\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 733 | loss: 0.32146 - binary_acc: 0.9945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.32087\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 734 | loss: 0.32087 - binary_acc: 0.9950 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.32034\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 735 | loss: 0.32034 - binary_acc: 0.9955 -- iter: 4/4\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.31986\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 736 | loss: 0.31986 - binary_acc: 0.9960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.31942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 737 | loss: 0.31942 - binary_acc: 0.9964 -- iter: 4/4\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.31902\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 738 | loss: 0.31902 - binary_acc: 0.9967 -- iter: 4/4\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.31866\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 739 | loss: 0.31866 - binary_acc: 0.9971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.31834\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 740 | loss: 0.31834 - binary_acc: 0.9974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.31804\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 741 | loss: 0.31804 - binary_acc: 0.9976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.31777\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 742 | loss: 0.31777 - binary_acc: 0.9979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.31753\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 743 | loss: 0.31753 - binary_acc: 0.9981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.31731\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 744 | loss: 0.31731 - binary_acc: 0.9983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.31710\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 745 | loss: 0.31710 - binary_acc: 0.9984 -- iter: 4/4\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.31692\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 746 | loss: 0.31692 - binary_acc: 0.9986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.31675\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 747 | loss: 0.31675 - binary_acc: 0.9987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.31660\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 748 | loss: 0.31660 - binary_acc: 0.9989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.31645\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 749 | loss: 0.31645 - binary_acc: 0.9990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.31633\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 750 | loss: 0.31633 - binary_acc: 0.9991 -- iter: 4/4\n",
      "--\n",
      "Final Updated Weights: [[-3.3867304]\n",
      " [-3.3246727]]\n",
      "Expected:  [False, True, True, False]\n",
      "Predicted:  [False, True, True, False]\n",
      "Efficiency: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "Y = [[0], [1], [1], [0]]\n",
    "# Define the network architecture\n",
    "input_layer = input_data(shape=[None, 2])\n",
    "hidden_layer = fully_connected(input_layer, 2, activation='tanh')\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='tanh')\n",
    "# Define the regression layer using the output layer\n",
    "regression_layer = regression(output_layer, optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
    "# Create the model using the regression layer\n",
    "model = tflearn.DNN(regression_layer)\n",
    "# Train the model\n",
    "model.fit(X, Y, n_epoch=750, show_metric=True)\n",
    "# Get the final updated weights of the model\n",
    "final_weights = model.get_weights(output_layer.W)\n",
    "print(\"Final Updated Weights:\", final_weights)\n",
    "# Predict the output\n",
    "predicted = model.predict(X)\n",
    "predicted_classes = [i[0] > 0 for i in predicted]\n",
    "# Convert Y to list of bool values\n",
    "expected_classes = [i[0] > 0 for i in Y]\n",
    "# Compare and calculate efficiency\n",
    "correct_predictions = sum(1 for expected, predicted in zip(expected_classes, predicted_classes) if expected == predicted)\n",
    "total_predictions = len(expected_classes)\n",
    "efficiency = (correct_predictions / total_predictions) * 100\n",
    "print(\"Expected: \", expected_classes)\n",
    "print(\"Predicted: \", predicted_classes)\n",
    "print(\"Efficiency: {:.2f}%\".format(efficiency))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd2fe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\91960\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: 3ZAQXF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.157s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.65118\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 002 | loss: 0.65118 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.70504\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 003 | loss: 0.70504 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.71029\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 004 | loss: 0.71029 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.70894\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 005 | loss: 0.70894 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.70666\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 006 | loss: 0.70666 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.70476\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 007 | loss: 0.70476 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.70307\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 008 | loss: 0.70307 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.70181\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 009 | loss: 0.70181 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.70077\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 010 | loss: 0.70077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.69992\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 011 | loss: 0.69992 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.69921\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 012 | loss: 0.69921 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.69862\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 013 | loss: 0.69862 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.69812\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 014 | loss: 0.69812 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69769\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 015 | loss: 0.69769 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69732\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 016 | loss: 0.69732 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69700\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 017 | loss: 0.69700 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69672\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 018 | loss: 0.69672 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69648\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 019 | loss: 0.69648 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69626\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 020 | loss: 0.69626 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69607\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 021 | loss: 0.69607 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69590\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 022 | loss: 0.69590 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69575\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 023 | loss: 0.69575 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69561\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 024 | loss: 0.69561 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69548\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 025 | loss: 0.69548 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69537\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 026 | loss: 0.69537 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69526\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 027 | loss: 0.69526 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69516\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 028 | loss: 0.69516 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69508\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 029 | loss: 0.69508 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69499\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 030 | loss: 0.69499 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69492\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 031 | loss: 0.69492 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69485\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 032 | loss: 0.69485 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69478\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 033 | loss: 0.69478 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69472\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 034 | loss: 0.69472 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69467\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 035 | loss: 0.69467 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69462\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 036 | loss: 0.69462 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69457\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 037 | loss: 0.69457 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69452\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 038 | loss: 0.69452 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69448\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 039 | loss: 0.69448 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69444\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 040 | loss: 0.69444 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69440\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 041 | loss: 0.69440 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69436\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 042 | loss: 0.69436 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69433\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 043 | loss: 0.69433 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69429\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 044 | loss: 0.69429 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69426\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 045 | loss: 0.69426 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69423\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 046 | loss: 0.69423 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69420\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 047 | loss: 0.69420 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69418\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 048 | loss: 0.69418 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69415\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 049 | loss: 0.69415 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69413\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 050 | loss: 0.69413 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69410\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 051 | loss: 0.69410 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69408\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 052 | loss: 0.69408 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69406\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 053 | loss: 0.69406 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69404\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 054 | loss: 0.69404 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69402\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 055 | loss: 0.69402 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69400\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 056 | loss: 0.69400 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69398\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 057 | loss: 0.69398 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69397\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 058 | loss: 0.69397 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69395\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 059 | loss: 0.69395 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69403\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 060 | loss: 0.69403 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69400\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 061 | loss: 0.69400 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69398\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 062 | loss: 0.69398 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69395\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 063 | loss: 0.69395 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69393\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 064 | loss: 0.69393 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69391\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 065 | loss: 0.69391 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69389\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 066 | loss: 0.69389 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69387\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 067 | loss: 0.69387 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69386\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 068 | loss: 0.69386 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69384\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 069 | loss: 0.69384 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69383\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 070 | loss: 0.69383 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69381\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 071 | loss: 0.69381 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69380\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 072 | loss: 0.69380 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69379\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 073 | loss: 0.69379 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69378\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 074 | loss: 0.69378 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69377\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 075 | loss: 0.69377 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.69376\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 076 | loss: 0.69376 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.69374\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 077 | loss: 0.69374 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.69373\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 078 | loss: 0.69373 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.69373\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 079 | loss: 0.69373 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.69372\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 080 | loss: 0.69372 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.69371\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 081 | loss: 0.69371 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.69370\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 082 | loss: 0.69370 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.69369\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 083 | loss: 0.69369 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.69368\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 084 | loss: 0.69368 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.69367\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 085 | loss: 0.69367 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.69361\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 086 | loss: 0.69361 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.69360\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 087 | loss: 0.69360 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.69360\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 088 | loss: 0.69360 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.69360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 089 | loss: 0.69360 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.69360\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 090 | loss: 0.69360 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.69360\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 091 | loss: 0.69360 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.69359\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 092 | loss: 0.69359 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.69359\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 093 | loss: 0.69359 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.69359\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 094 | loss: 0.69359 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.69358\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 095 | loss: 0.69358 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.69358\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 096 | loss: 0.69358 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.69358\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 097 | loss: 0.69358 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.69357\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 098 | loss: 0.69357 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.69357\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 099 | loss: 0.69357 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.69356\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 100 | loss: 0.69356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.69356\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 101 | loss: 0.69356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.69356\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 102 | loss: 0.69356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.69355\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 103 | loss: 0.69355 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.69355\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 104 | loss: 0.69355 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.69354\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 105 | loss: 0.69354 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.69354\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 106 | loss: 0.69354 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.69354\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 107 | loss: 0.69354 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.69353\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 108 | loss: 0.69353 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.69353\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 109 | loss: 0.69353 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 110 | loss: 0.69352 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 111 | loss: 0.69352 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 112 | loss: 0.69352 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.69351\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 113 | loss: 0.69351 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.69351\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 114 | loss: 0.69351 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.69351\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 115 | loss: 0.69351 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 116 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 117 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 118 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 119 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 120 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 121 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 122 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 123 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 124 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 125 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 126 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 127 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 128 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 129 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 130 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 131 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 132 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 133 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 134 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 135 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 136 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 137 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 138 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 139 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 140 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 141 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 142 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 143 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 144 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 145 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 146 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 147 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 148 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 149 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 150 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 151 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 152 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 153 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 154 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 155 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 156 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 157 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 158 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 159 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 160 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 161 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 162 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 163 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 164 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 165 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 166 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 167 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 168 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 169 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 170 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 171 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 172 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 173 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 174 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 175 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 176 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 177 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 178 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 179 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 180 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 181 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 182 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 183 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 184 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 185 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 186 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 187 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 188 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 189 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 190 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 191 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 192 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 193 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 194 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 195 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 196 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 197 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 198 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 199 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 200 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 201 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 202 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 203 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 204 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 205 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 206 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 207 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 208 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 209 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 210 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 211 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 212 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 213 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 214 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 215 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 216 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 217 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 218 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 219 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 220 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 221 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 222 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 223 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 224 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 225 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 226 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 227 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 228 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 229 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 230 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 231 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 232 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 233 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 234 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 235 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 236 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 237 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 238 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 239 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 240 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 241 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 242 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 243 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 244 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 245 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 246 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 247 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 248 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 249 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 250 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 251 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 252 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 253 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 254 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 255 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 256 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 257 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 258 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 259 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 260 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 261 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 262 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 263 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 264 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 265 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 266 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 267 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 268 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 269 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 270 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 271 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 272 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 273 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 274 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 275 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 276 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 277 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 278 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 279 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 280 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 281 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 282 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 283 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 284 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 285 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 286 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 287 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 288 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 289 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 290 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 291 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 292 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 293 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 294 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 295 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 296 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 297 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 298 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 299 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 300 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 301 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 302 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 303 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 304 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 305 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 306 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 307 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 308 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 309 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 310 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 311 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 312 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 313 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 314 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 315 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 316 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 317 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 318 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 319 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 320 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 321 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 322 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 323 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 324 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 325 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 326 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 327 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 328 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 329 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 330 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 331 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 332 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 333 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 334 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 335 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 336 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 337 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 338 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 339 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 340 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 341 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 342 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 343 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 344 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 345 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 346 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 347 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 348 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 349 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 350 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 351 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 352 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 353 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 354 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 355 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 356 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 357 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 358 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 359 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 360 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 361 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 362 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 363 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 364 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 365 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 366 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 367 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 368 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 369 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 370 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 371 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 372 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 373 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 374 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 375 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 376 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 377 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 378 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 379 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 380 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 381 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 382 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 383 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 384 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 385 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 386 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 387 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 388 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 389 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 390 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 391 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 392 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 393 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 394 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 395 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 396 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 397 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 398 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 399 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 400 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 401 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 402 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 403 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 404 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 405 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 406 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 407 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 408 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 409 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 410 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 411 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 412 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 413 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 414 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 415 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 416 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 417 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 418 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 419 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 420 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 421 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 422 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 423 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 424 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 425 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 426 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 427 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 428 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 429 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 430 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 431 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 432 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 433 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 434 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 435 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 436 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 437 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 438 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 439 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 440 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 441 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 442 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 443 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 444 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 445 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 446 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 447 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 448 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 449 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 450 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 451 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 452 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 453 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 454 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 455 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 456 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 457 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 458 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 459 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 460 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 461 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 462 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 463 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 464 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 465 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 466 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 467 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 468 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 469 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 470 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 471 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 472 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 473 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 474 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 475 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 476 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 477 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 478 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 479 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 480 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 481 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 482 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 483 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 484 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 485 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 486 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 487 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 488 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 489 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 490 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 491 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 492 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 493 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 494 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 495 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 496 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 497 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 498 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 499 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 500 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Final Updated Weights: [[-1.2457565]\n",
      " [-1.2512188]]\n",
      "Expected:  [False, True, True, False]\n",
      "Predicted:  [False, False, False, False]\n",
      "Efficiency: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "Y = [[0], [1], [1], [0]]\n",
    "# Define the network architecture\n",
    "input_layer = input_data(shape=[None, 2])\n",
    "hidden_layer = fully_connected(input_layer, 2, activation='sigmoid')  # Changed activation function to sigmoid\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='sigmoid')  # Changed activation function to sigmoid\n",
    "# Define the regression layer using the output layer\n",
    "regression_layer = regression(output_layer, optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
    "# Create the model using the regression layer\n",
    "model = tflearn.DNN(regression_layer)\n",
    "# Train the model\n",
    "model.fit(X, Y, n_epoch=500, show_metric=True)\n",
    "# Get the final updated weights of the model\n",
    "final_weights = model.get_weights(output_layer.W)\n",
    "print(\"Final Updated Weights:\", final_weights)\n",
    "# Predict the output\n",
    "predicted = model.predict(X)\n",
    "predicted_classes = [i[0] > 0.5 for i in predicted]  # Use 0.5 as the threshold for sigmoid\n",
    "# Convert Y to list of bool values\n",
    "expected_classes = [i[0] > 0.5 for i in Y]  # Use 0.5 as the threshold for sigmoid\n",
    "# Compare and calculate efficiency\n",
    "correct_predictions = sum(1 for expected, predicted in zip(expected_classes, predicted_classes) if expected == predicted)\n",
    "total_predictions = len(expected_classes)\n",
    "efficiency = (correct_predictions / total_predictions) * 100\n",
    "print(\"Expected: \", expected_classes)\n",
    "print(\"Predicted: \", predicted_classes)\n",
    "print(\"Efficiency: {:.2f}%\".format(efficiency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84096dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\91960\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: M7G6JB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.107s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.65191\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 002 | loss: 0.65191 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.70573\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 003 | loss: 0.70573 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.71088\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 004 | loss: 0.71088 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.70943\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 005 | loss: 0.70943 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.70720\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 006 | loss: 0.70720 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.70518\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 007 | loss: 0.70518 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.70351\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 008 | loss: 0.70351 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.70216\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 009 | loss: 0.70216 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.70106\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 010 | loss: 0.70106 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.70016\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 011 | loss: 0.70016 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.69942\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 012 | loss: 0.69942 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.69880\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 013 | loss: 0.69880 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.69828\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 014 | loss: 0.69828 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69783\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 015 | loss: 0.69783 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69745\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 016 | loss: 0.69745 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69712\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 017 | loss: 0.69712 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69683\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 018 | loss: 0.69683 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69658\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 019 | loss: 0.69658 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69635\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 020 | loss: 0.69635 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69615\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 021 | loss: 0.69615 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69597\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 022 | loss: 0.69597 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69581\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 023 | loss: 0.69581 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69567\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 024 | loss: 0.69567 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69554\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 025 | loss: 0.69554 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69542\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 026 | loss: 0.69542 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69531\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 027 | loss: 0.69531 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69521\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 028 | loss: 0.69521 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69512\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 029 | loss: 0.69512 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69504\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 030 | loss: 0.69504 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69496\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 031 | loss: 0.69496 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69488\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 032 | loss: 0.69488 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69482\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 033 | loss: 0.69482 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69476\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 034 | loss: 0.69476 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69470\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 035 | loss: 0.69470 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69464\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 036 | loss: 0.69464 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69459\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 037 | loss: 0.69459 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69454\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 038 | loss: 0.69454 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69450\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 039 | loss: 0.69450 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69446\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 040 | loss: 0.69446 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69442\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 041 | loss: 0.69442 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69438\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 042 | loss: 0.69438 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69434\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 043 | loss: 0.69434 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69431\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 044 | loss: 0.69431 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69428\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 045 | loss: 0.69428 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69425\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 046 | loss: 0.69425 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69422\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 047 | loss: 0.69422 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69419\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 048 | loss: 0.69419 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69416\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 049 | loss: 0.69416 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69414\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 050 | loss: 0.69414 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69411\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 051 | loss: 0.69411 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69409\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 052 | loss: 0.69409 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69407\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 053 | loss: 0.69407 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69405\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 054 | loss: 0.69405 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69403\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 055 | loss: 0.69403 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69401\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 056 | loss: 0.69401 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69399\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 057 | loss: 0.69399 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69397\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 058 | loss: 0.69397 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69396\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 059 | loss: 0.69396 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69394\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 060 | loss: 0.69394 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69392\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 061 | loss: 0.69392 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69391\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 062 | loss: 0.69391 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69389\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 063 | loss: 0.69389 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69388\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 064 | loss: 0.69388 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69387\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 065 | loss: 0.69387 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69385\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 066 | loss: 0.69385 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69384\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 067 | loss: 0.69384 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69383\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 068 | loss: 0.69383 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69382\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 069 | loss: 0.69382 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69381\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 070 | loss: 0.69381 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69379\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 071 | loss: 0.69379 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69378\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 072 | loss: 0.69378 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69377\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 073 | loss: 0.69377 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69376\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 074 | loss: 0.69376 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69375\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 075 | loss: 0.69375 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.69370\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 076 | loss: 0.69370 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.69369\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 077 | loss: 0.69369 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.69369\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 078 | loss: 0.69369 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.69368\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 079 | loss: 0.69368 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.69368\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 080 | loss: 0.69368 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.69367\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 081 | loss: 0.69367 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.69367\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 082 | loss: 0.69367 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.69366\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 083 | loss: 0.69366 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.69366\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 084 | loss: 0.69366 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.69365\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 085 | loss: 0.69365 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.69365\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 086 | loss: 0.69365 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.69364\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 087 | loss: 0.69364 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.69363\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 088 | loss: 0.69363 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.69363\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 089 | loss: 0.69363 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.69362\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 090 | loss: 0.69362 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.69362\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 091 | loss: 0.69362 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.69361\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 092 | loss: 0.69361 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.69361\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 093 | loss: 0.69361 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.69360\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 094 | loss: 0.69360 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.69360\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 095 | loss: 0.69360 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.69359\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 096 | loss: 0.69359 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.69359\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 097 | loss: 0.69359 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.69358\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 098 | loss: 0.69358 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.69358\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 099 | loss: 0.69358 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.69357\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 100 | loss: 0.69357 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.69357\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 101 | loss: 0.69357 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.69356\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 102 | loss: 0.69356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.69356\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 103 | loss: 0.69356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.69355\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 104 | loss: 0.69355 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.69355\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 105 | loss: 0.69355 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.69354\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 106 | loss: 0.69354 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.69354\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 107 | loss: 0.69354 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.69353\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 108 | loss: 0.69353 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.69353\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 109 | loss: 0.69353 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 110 | loss: 0.69352 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 111 | loss: 0.69352 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 112 | loss: 0.69352 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.69351\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 113 | loss: 0.69351 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.69351\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 114 | loss: 0.69351 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.69350\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 115 | loss: 0.69350 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.69350\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 116 | loss: 0.69350 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.69350\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 117 | loss: 0.69350 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.69349\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 118 | loss: 0.69349 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.69349\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 119 | loss: 0.69349 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.69349\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 120 | loss: 0.69349 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.69348\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 121 | loss: 0.69348 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.69348\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 122 | loss: 0.69348 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.69348\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 123 | loss: 0.69348 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.69347\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 124 | loss: 0.69347 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.69347\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 125 | loss: 0.69347 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.69347\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 126 | loss: 0.69347 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.69346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 127 | loss: 0.69346 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.69346\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 128 | loss: 0.69346 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.69346\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 129 | loss: 0.69346 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 130 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 131 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 132 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 133 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 134 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 135 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 136 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 137 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 138 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 139 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 140 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 141 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 142 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 143 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 144 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 145 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 146 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 147 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 148 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 149 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 150 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 151 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 152 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 153 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 154 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 155 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 156 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 157 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 158 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 159 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 160 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 161 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 162 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 163 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 164 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 165 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 166 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 167 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 168 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 169 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 170 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 171 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 172 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 173 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 174 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 175 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 176 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 177 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 178 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 179 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 180 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 181 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 182 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 183 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 184 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 185 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 186 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 187 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 188 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 189 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 190 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 191 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 192 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 193 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 194 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 195 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 196 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 197 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 198 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 199 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 200 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 201 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 202 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 203 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 204 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 205 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 206 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 207 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 208 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 209 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 210 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 211 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 212 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 213 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 214 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 215 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 216 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 217 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 218 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 219 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 220 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 221 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 222 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 223 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 224 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 225 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 226 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 227 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 228 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 229 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 230 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 231 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 232 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 233 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 234 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 235 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 236 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 237 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 238 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 239 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 240 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 241 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 242 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 243 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 244 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 245 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 246 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 247 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 248 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 249 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 250 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 251 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 252 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 253 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 254 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 255 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 256 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 257 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 258 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 259 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 260 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 261 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 262 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 263 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 264 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 265 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 266 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 267 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 268 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 269 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 270 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 271 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 272 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 273 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 274 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 275 | loss: 0.69328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 276 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 277 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 278 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 279 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 280 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 281 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 282 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 283 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 284 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 285 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 286 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 287 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 288 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 289 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 290 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 291 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 292 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 293 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 294 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 295 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 296 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 297 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 298 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 299 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 300 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 301 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 302 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 303 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 304 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 305 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 306 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 307 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 308 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 309 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 310 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 311 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 312 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 313 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 314 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 315 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 316 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 317 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 318 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 319 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 320 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 321 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 322 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 323 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 324 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 325 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 326 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 327 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 328 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 329 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 330 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 331 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 332 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 333 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 334 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 335 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 336 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 337 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 338 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 339 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 340 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 341 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 342 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 343 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 344 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 345 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 346 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 347 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 348 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 349 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 350 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 351 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 352 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 353 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 354 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 355 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 356 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 357 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 358 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 359 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 360 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 361 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 362 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 363 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 364 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 365 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 366 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 367 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 368 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 369 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 370 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 371 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 372 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 373 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 374 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 375 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 376 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 377 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 378 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 379 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 380 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 381 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 382 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 383 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 384 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 385 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 386 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 387 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 388 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 389 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 390 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 391 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 392 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 393 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 394 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 395 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 396 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 397 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 398 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 399 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 400 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 401 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 402 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 403 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 404 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 405 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 406 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 407 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 408 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 409 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 410 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 411 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 412 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 413 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 414 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 415 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 416 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 417 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 418 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 419 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 420 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 421 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 422 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 423 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 424 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 425 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 426 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 427 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 428 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 429 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 430 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 431 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 432 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 433 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 434 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 435 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 436 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 437 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 438 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 439 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 440 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 441 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 442 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 443 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 444 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 445 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 446 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 447 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 448 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 449 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 450 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 451 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 452 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 453 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 454 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 455 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 456 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 457 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 458 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 459 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 460 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 461 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 462 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 463 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 464 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 465 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 466 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 467 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 468 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 469 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 470 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 471 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 472 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 473 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 474 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 475 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 476 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 477 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 478 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 479 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 480 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 481 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 482 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 483 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 484 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 485 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 486 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 487 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 488 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 489 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 490 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 491 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 492 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 493 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 494 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 495 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 496 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 497 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 498 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 499 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 500 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 501 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 502 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 503 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 504 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 505 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 506 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 507 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 508 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 509 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 510 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 511 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 512 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 513 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 514 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 515 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 516 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 517 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 518 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 519 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 520 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 521 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 522 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 523 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 524 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 525 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 526 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 527 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 528 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 529 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 530 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 531 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 532 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 533 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 534 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 535 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 536 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 537 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 538 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 539 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 540 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 541 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 542 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 543 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 544 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 545 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 546 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 547 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 548 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 549 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 550 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 551 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 552 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 553 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 554 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 555 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 556 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 557 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 558 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 559 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 560 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 561 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 562 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 563 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 564 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 565 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 566 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 567 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 568 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 569 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 570 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 571 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 572 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 573 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 574 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 575 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 576 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 577 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 578 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 579 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 580 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 581 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 582 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 583 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 584 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 585 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 586 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 587 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 588 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 589 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 590 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 591 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 592 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 593 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 594 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 595 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 596 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 597 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 598 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 599 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 600 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 601 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 602 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 603 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 604 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 605 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 606 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 607 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 608 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 609 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 610 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 611 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 612 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 613 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 614 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 615 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 616 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 617 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 618 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 619 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 620 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 621 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 622 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 623 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 624 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 625 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 626 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 627 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 628 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 629 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 630 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 631 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 632 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 633 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 634 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 635 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 636 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 637 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 638 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 639 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 640 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 641 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 642 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 643 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 644 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 645 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 646 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 647 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 648 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 649 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 650 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 651 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 652 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 653 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 654 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 655 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 656 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 657 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 658 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 659 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 660 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 661 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 662 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 663 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 664 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 665 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 666 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 667 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 668 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 669 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 670 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 671 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 672 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 673 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 674 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 675 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 676 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 677 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 678 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 679 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 680 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 681 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 682 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 683 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 684 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 685 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 686 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 687 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 688 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 689 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 690 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 691 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 692 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 693 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 694 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 695 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 696 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 697 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 698 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 699 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 700 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 701 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 702 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 703 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 704 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 705 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 706 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 707 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 708 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 709 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 710 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 711 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 712 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 713 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 714 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 715 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 716 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 717 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 718 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 719 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 720 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 721 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 722 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 723 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 724 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 725 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 726 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 727 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 728 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 729 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 730 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 731 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 732 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 733 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 734 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 735 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 736 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 737 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 738 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 739 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 740 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 741 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 742 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 743 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 744 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 745 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 746 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 747 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 748 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 749 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 750 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Final Updated Weights: [[-1.2848324]\n",
      " [-1.3134302]]\n",
      "Expected:  [False, True, True, False]\n",
      "Predicted:  [False, False, False, False]\n",
      "Efficiency: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "Y = [[0], [1], [1], [0]]\n",
    "# Define the network architecture\n",
    "input_layer = input_data(shape=[None, 2])\n",
    "hidden_layer = fully_connected(input_layer, 2, activation='sigmoid')  # Changed activation function to sigmoid\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='sigmoid')  # Changed activation function to sigmoid\n",
    "# Define the regression layer using the output layer\n",
    "regression_layer = regression(output_layer, optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
    "# Create the model using the regression layer\n",
    "model = tflearn.DNN(regression_layer)\n",
    "# Train the model\n",
    "model.fit(X, Y, n_epoch=750, show_metric=True)\n",
    "# Get the final updated weights of the model\n",
    "final_weights = model.get_weights(output_layer.W)\n",
    "print(\"Final Updated Weights:\", final_weights)\n",
    "# Predict the output\n",
    "predicted = model.predict(X)\n",
    "predicted_classes = [i[0] > 0.5 for i in predicted]  # Use 0.5 as the threshold for sigmoid\n",
    "# Convert Y to list of bool values\n",
    "expected_classes = [i[0] > 0.5 for i in Y]  # Use 0.5 as the threshold for sigmoid\n",
    "# Compare and calculate efficiency\n",
    "correct_predictions = sum(1 for expected, predicted in zip(expected_classes, predicted_classes) if expected == predicted)\n",
    "total_predictions = len(expected_classes)\n",
    "efficiency = (correct_predictions / total_predictions) * 100\n",
    "print(\"Expected: \", expected_classes)\n",
    "print(\"Predicted: \", predicted_classes)\n",
    "print(\"Efficiency: {:.2f}%\".format(efficiency))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7c77bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\91960\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: I8XYWK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.135s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.65152\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 002 | loss: 0.65152 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.70536\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 003 | loss: 0.70536 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.71056\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 004 | loss: 0.71056 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.70916\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 005 | loss: 0.70916 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.70697\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 006 | loss: 0.70697 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.70499\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 007 | loss: 0.70499 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.70335\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 008 | loss: 0.70335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.70202\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 009 | loss: 0.70202 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.70094\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 010 | loss: 0.70094 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.70006\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 011 | loss: 0.70006 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.69933\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 012 | loss: 0.69933 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.69872\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 013 | loss: 0.69872 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.69821\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 014 | loss: 0.69821 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69777\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 015 | loss: 0.69777 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69739\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 016 | loss: 0.69739 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69707\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 017 | loss: 0.69707 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69678\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 018 | loss: 0.69678 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69653\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 019 | loss: 0.69653 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69631\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 020 | loss: 0.69631 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69612\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 021 | loss: 0.69612 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69594\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 022 | loss: 0.69594 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69578\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 023 | loss: 0.69578 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69564\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 024 | loss: 0.69564 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69551\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 025 | loss: 0.69551 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69540\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 026 | loss: 0.69540 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69529\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 027 | loss: 0.69529 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69519\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 028 | loss: 0.69519 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69510\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 029 | loss: 0.69510 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69502\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 030 | loss: 0.69502 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69494\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 031 | loss: 0.69494 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69487\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 032 | loss: 0.69487 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69480\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 033 | loss: 0.69480 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69474\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 034 | loss: 0.69474 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69468\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 035 | loss: 0.69468 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69463\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 036 | loss: 0.69463 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69458\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 037 | loss: 0.69458 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69453\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 038 | loss: 0.69453 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69449\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 039 | loss: 0.69449 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69445\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 040 | loss: 0.69445 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69441\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 041 | loss: 0.69441 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69437\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 042 | loss: 0.69437 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69433\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 043 | loss: 0.69433 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69421\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 044 | loss: 0.69421 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69419\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 045 | loss: 0.69419 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69417\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 046 | loss: 0.69417 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69416\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 047 | loss: 0.69416 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69414\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 048 | loss: 0.69414 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69412\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 049 | loss: 0.69412 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69410\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 050 | loss: 0.69410 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69408\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 051 | loss: 0.69408 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69406\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 052 | loss: 0.69406 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69404\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 053 | loss: 0.69404 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69403\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 054 | loss: 0.69403 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69401\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 055 | loss: 0.69401 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69399\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 056 | loss: 0.69399 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69398\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 057 | loss: 0.69398 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69396\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 058 | loss: 0.69396 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69394\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 059 | loss: 0.69394 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69393\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 060 | loss: 0.69393 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69392\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 061 | loss: 0.69392 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69390\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 062 | loss: 0.69390 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69389\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 063 | loss: 0.69389 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69387\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 064 | loss: 0.69387 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69386\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 065 | loss: 0.69386 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69385\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 066 | loss: 0.69385 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69384\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 067 | loss: 0.69384 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69382\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 068 | loss: 0.69382 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69381\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 069 | loss: 0.69381 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69375\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 070 | loss: 0.69375 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69374\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 071 | loss: 0.69374 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69374\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 072 | loss: 0.69374 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69373\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 073 | loss: 0.69373 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69379\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 074 | loss: 0.69379 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69378\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 075 | loss: 0.69378 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.69377\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 076 | loss: 0.69377 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.69376\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 077 | loss: 0.69376 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.69375\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 078 | loss: 0.69375 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.69374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 079 | loss: 0.69374 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.69373\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 080 | loss: 0.69373 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.69372\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 081 | loss: 0.69372 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.69371\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 082 | loss: 0.69371 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.69370\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 083 | loss: 0.69370 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.69369\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 084 | loss: 0.69369 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.69368\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 085 | loss: 0.69368 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.69367\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 086 | loss: 0.69367 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.69366\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 087 | loss: 0.69366 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.69366\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 088 | loss: 0.69366 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.69365\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 089 | loss: 0.69365 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.69364\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 090 | loss: 0.69364 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.69363\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 091 | loss: 0.69363 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.69363\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 092 | loss: 0.69363 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.69362\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 093 | loss: 0.69362 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.69361\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 094 | loss: 0.69361 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.69361\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 095 | loss: 0.69361 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.69360\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 096 | loss: 0.69360 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.69359\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 097 | loss: 0.69359 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.69359\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 098 | loss: 0.69359 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.69358\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 099 | loss: 0.69358 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.69358\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 100 | loss: 0.69358 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.69357\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 101 | loss: 0.69357 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.69357\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 102 | loss: 0.69357 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.69356\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 103 | loss: 0.69356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.69356\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 104 | loss: 0.69356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.69355\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 105 | loss: 0.69355 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.69355\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 106 | loss: 0.69355 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.69354\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 107 | loss: 0.69354 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.69354\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 108 | loss: 0.69354 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.69353\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 109 | loss: 0.69353 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.69353\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 110 | loss: 0.69353 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 111 | loss: 0.69352 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 112 | loss: 0.69352 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 113 | loss: 0.69352 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.69351\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 114 | loss: 0.69351 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.69351\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 115 | loss: 0.69351 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.69350\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 116 | loss: 0.69350 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.69350\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 117 | loss: 0.69350 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.69350\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 118 | loss: 0.69350 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.69349\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 119 | loss: 0.69349 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 120 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 121 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 122 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 123 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 124 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 125 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 126 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 127 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 128 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 129 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 130 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 131 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 132 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 133 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 134 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 135 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 136 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 137 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 138 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 139 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 140 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 141 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 142 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 143 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 144 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 145 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 146 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 147 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 148 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 149 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 150 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 151 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 152 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 153 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 154 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 155 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 156 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 157 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 158 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.69344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 159 | loss: 0.69344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.69343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 160 | loss: 0.69343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 161 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 162 | loss: 0.69342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 163 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 164 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 165 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 166 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.69340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 167 | loss: 0.69340 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 168 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 169 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 170 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 171 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 172 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 173 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.69338\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 174 | loss: 0.69338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 175 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 176 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 177 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 178 | loss: 0.69337 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 179 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 180 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 181 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 182 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 183 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.69336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 184 | loss: 0.69336 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 185 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 186 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 187 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 188 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 189 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 190 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.69335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 191 | loss: 0.69335 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 192 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 193 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 194 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 195 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 196 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 197 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 198 | loss: 0.69334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 199 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 200 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 201 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 202 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 203 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 204 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 205 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 206 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 207 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 208 | loss: 0.69333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 209 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 210 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 211 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 212 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 213 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 214 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 215 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 216 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 217 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 218 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 219 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 220 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 221 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 222 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 223 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 224 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 225 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 226 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 227 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 228 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 229 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 230 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 231 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 232 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 233 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 234 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 235 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 236 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 237 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 238 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 239 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 240 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 241 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 242 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 243 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 244 | loss: 0.69330 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 245 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 246 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 247 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 248 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 249 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 250 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 251 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 252 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 253 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 254 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 255 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 256 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 257 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 258 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 259 | loss: 0.69329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 260 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 261 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 262 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 263 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 264 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 265 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 266 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 267 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 268 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 269 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 270 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 271 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 272 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 273 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 274 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 275 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 276 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 277 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 278 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 279 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 280 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 281 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 282 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 283 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 284 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 285 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 286 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 287 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 288 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 289 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 290 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 291 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 292 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 293 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 294 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 295 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 296 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 297 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 298 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.69327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 299 | loss: 0.69327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 300 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 301 | loss: 0.69326 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 302 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 303 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 304 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 305 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 306 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 307 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 308 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 309 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 310 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 311 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 312 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 313 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 314 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 315 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 316 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 317 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 318 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 319 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 320 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 321 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 322 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 323 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 324 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 325 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 326 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 327 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 328 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 329 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 330 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 331 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 332 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 333 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 334 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 335 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 336 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 337 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 338 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 339 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 340 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 341 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 342 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 343 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 344 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 345 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 346 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 347 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 348 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 349 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 350 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 351 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 352 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 353 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 354 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 355 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 356 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 357 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 358 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 359 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 360 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 361 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 362 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 363 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 364 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 365 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 366 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 367 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 368 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 369 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 370 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 371 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 372 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 373 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 374 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 375 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 376 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 377 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 378 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 379 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 380 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 381 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 382 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 383 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 384 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 385 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 386 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 387 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 388 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 389 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 390 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 391 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 392 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 393 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 394 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 395 | loss: 0.69324 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 396 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 397 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 398 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 399 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 400 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 401 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 402 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 403 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 404 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 405 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 406 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 407 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 408 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 409 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 410 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 411 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 412 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 413 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 414 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 415 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 416 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 417 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 418 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 419 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 420 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 421 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 422 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 423 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 424 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 425 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 426 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 427 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 428 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 429 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 430 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 431 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 432 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 433 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 434 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 435 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 436 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 437 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 438 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 439 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 440 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 441 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 442 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 443 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 444 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 445 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 446 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 447 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 448 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 449 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 450 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 451 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 452 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 453 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 454 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 455 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 456 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 457 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 458 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 459 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 460 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 461 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 462 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 463 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 464 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 465 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 466 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 467 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 468 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 469 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 470 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 471 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 472 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 473 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 474 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 475 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 476 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 477 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 478 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 479 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 480 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 481 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 482 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 483 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 484 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 485 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 486 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 487 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 488 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 489 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 490 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 491 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 492 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 493 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 494 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 495 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 496 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 497 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 498 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 499 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 500 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 501 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 502 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 503 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 504 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 505 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 506 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 507 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 508 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 509 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 510 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 511 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 512 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 513 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 514 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 515 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 516 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 517 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 518 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 519 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 520 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 521 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 522 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 523 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 524 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 525 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 526 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 527 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 528 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 529 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 530 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 531 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 532 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 533 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 534 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 535 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 536 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 537 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 538 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 539 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 540 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 541 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 542 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 543 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 544 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 545 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 546 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 547 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 548 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 549 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 550 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 551 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 552 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 553 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 554 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 555 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 556 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 557 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 558 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 559 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 560 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 561 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 562 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 563 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 564 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 565 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 566 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 567 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 568 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 569 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 570 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 571 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 572 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 573 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 574 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 575 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 576 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 577 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 578 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 579 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 580 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 581 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 582 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 583 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 584 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 585 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 586 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 587 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 588 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 589 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 590 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 591 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 592 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 593 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 594 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 595 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 596 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 597 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 598 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 599 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 600 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 601 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 602 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 603 | loss: 0.69322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 604 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 605 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 606 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 607 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 608 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 609 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 610 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 611 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 612 | loss: 0.69321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 613 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 614 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 615 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 616 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 617 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 618 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 619 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 620 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 621 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 622 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 623 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 624 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 625 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 626 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 627 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 628 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 629 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 630 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 631 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 632 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 633 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 634 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 635 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 636 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 637 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 638 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 639 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 640 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 641 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 642 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 643 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 644 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 645 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 646 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 647 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 648 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 649 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 650 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 651 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 652 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 653 | loss: 0.69320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 654 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 655 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 656 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 657 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 658 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 659 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 660 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 661 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 662 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 663 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 664 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 665 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 666 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 667 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 668 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 669 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 670 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 671 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 672 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 673 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 674 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 675 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 676 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 677 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 678 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 679 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 680 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 681 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 682 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 683 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 684 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 685 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 686 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 687 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 688 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 689 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 690 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 691 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 692 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 693 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 694 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 695 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 696 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 697 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 698 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 699 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 700 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 701 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 702 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 703 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 704 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 705 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 706 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 707 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 708 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 709 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 710 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 711 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 712 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 713 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 714 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 715 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 716 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 717 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 718 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 719 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 720 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 721 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 722 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 723 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 724 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 725 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 726 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 727 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 728 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 729 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 730 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 731 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 732 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 733 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 734 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 735 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 736 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 737 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 738 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 739 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 740 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 741 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 742 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 743 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 744 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 745 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 746 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 747 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 748 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 749 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 750 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 751 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 752 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 753 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 754 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 755 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 756 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 757 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 758 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 759 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 760 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 761 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 762 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 763 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 764 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 765 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 766 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 767 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 768 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 769 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 770 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 771 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 772 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 773 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 774 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 775 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 776 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 777 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 778 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 779 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 780 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 781 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 782 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 783 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 784 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 785 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 786 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 787 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 788 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 789 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 790 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 791 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 792 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 793 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 794 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 795 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 796 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 797 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 798 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 799 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 800 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 801 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 802 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 803 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 804 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 805 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 806 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 807 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 808 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 809 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 810 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 811 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 812 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 813 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 814 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 815 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 816 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 817 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 818 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 819 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 820 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 821 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 822 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 823 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 824 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 825 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 826 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 827 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 828 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 829 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 830 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 831 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 832 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 833 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 834 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 835 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 836 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 837 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 838 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 839 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 840 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 841 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 842 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 843 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 844 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 845 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 846 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 847 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 848 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 849 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 850 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 851 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 852 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 853 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 854 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 855 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 856 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 857 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 858 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 859 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 860 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 861 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 862 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 863 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 864 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 865 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 866 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 867 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 868 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 869 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 870 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 871 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 872 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 873 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 874 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 875 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 876 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 877 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 878 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 879 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 880 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 881 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 882 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 883 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 884 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 885 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 886 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 887 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 888 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 889 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 890 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 891 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 892 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 893 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 894 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 895 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 896 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 897 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 898 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 899 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 900 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 901 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 902 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 903 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 904 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 905 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 906 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 907 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 908 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 909 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 910 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 911 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 912 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 913 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 914 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 915 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 916 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 917 | loss: 0.69318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 918 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 919 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 920 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 921 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 922 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 923 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 924 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 925 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 926 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 927 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 928 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 929 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 930 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 931 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 932 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 933 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 934 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 935 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 936 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 937 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 938 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 939 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 940 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 941 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 942 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 943 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 944 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 945 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 946 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 947 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 948 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 949 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 950 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 951 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 952 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 953 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 954 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 955 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 956 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 957 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 958 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 959 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 960 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 961 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 962 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 963 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 964 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 965 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 966 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 967 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 968 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 969 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 970 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 971 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 972 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 973 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 974 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 975 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 976 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 977 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 978 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 979 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 980 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 981 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 982 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 983 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 984 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 985 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 986 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 987 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 988 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 989 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 990 | loss: 0.69317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 991 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 992 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 993 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 994 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 995 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 996 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 997 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 998 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 999 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1000 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Final Updated Weights: [[-1.3525987]\n",
      " [-1.36563  ]]\n",
      "Expected:  [False, True, True, False]\n",
      "Predicted:  [False, False, False, False]\n",
      "Efficiency: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "Y = [[0], [1], [1], [0]]\n",
    "# Define the network architecture\n",
    "input_layer = input_data(shape=[None, 2])\n",
    "hidden_layer = fully_connected(input_layer, 2, activation='sigmoid')  # Changed activation function to sigmoid\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='sigmoid')  # Changed activation function to sigmoid\n",
    "# Define the regression layer using the output layer\n",
    "regression_layer = regression(output_layer, optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
    "# Create the model using the regression layer\n",
    "model = tflearn.DNN(regression_layer)\n",
    "# Train the model\n",
    "model.fit(X, Y, n_epoch=1000, show_metric=True)\n",
    "# Get the final updated weights of the model\n",
    "final_weights = model.get_weights(output_layer.W)\n",
    "print(\"Final Updated Weights:\", final_weights)\n",
    "# Predict the output\n",
    "predicted = model.predict(X)\n",
    "predicted_classes = [i[0] > 0.5 for i in predicted]  # Use 0.5 as the threshold for sigmoid\n",
    "# Convert Y to list of bool values\n",
    "expected_classes = [i[0] > 0.5 for i in Y]  # Use 0.5 as the threshold for sigmoid\n",
    "# Compare and calculate efficiency\n",
    "correct_predictions = sum(1 for expected, predicted in zip(expected_classes, predicted_classes) if expected == predicted)\n",
    "total_predictions = len(expected_classes)\n",
    "efficiency = (correct_predictions / total_predictions) * 100\n",
    "print(\"Expected: \", expected_classes)\n",
    "print(\"Predicted: \", predicted_classes)\n",
    "print(\"Efficiency: {:.2f}%\".format(efficiency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60dd398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\91960\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: 4V6TPL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.118s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.65166\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 002 | loss: 0.65166 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.70722\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 003 | loss: 0.70722 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.71362\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 004 | loss: 0.71362 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.71291\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 005 | loss: 0.71291 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.71103\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 006 | loss: 0.71103 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.70912\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 007 | loss: 0.70912 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.70741\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 008 | loss: 0.70741 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.70593\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 009 | loss: 0.70593 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.70467\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 010 | loss: 0.70467 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.70358\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 011 | loss: 0.70358 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.70264\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 012 | loss: 0.70264 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.70183\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 013 | loss: 0.70183 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.70113\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 014 | loss: 0.70113 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69997\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 015 | loss: 0.69997 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69997\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 016 | loss: 0.69997 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69950\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 017 | loss: 0.69950 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69907\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 018 | loss: 0.69907 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69869\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 019 | loss: 0.69869 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69835\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 020 | loss: 0.69835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69804\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 021 | loss: 0.69804 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69776\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 022 | loss: 0.69776 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69751\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 023 | loss: 0.69751 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69728\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 024 | loss: 0.69728 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69706\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 025 | loss: 0.69706 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69686\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 026 | loss: 0.69686 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69668\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 027 | loss: 0.69668 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69651\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 028 | loss: 0.69651 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69635\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 029 | loss: 0.69635 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69620\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 030 | loss: 0.69620 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69607\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 031 | loss: 0.69607 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69593\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 032 | loss: 0.69593 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69581\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 033 | loss: 0.69581 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69569\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 034 | loss: 0.69569 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69557\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 035 | loss: 0.69557 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69547\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 036 | loss: 0.69547 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69536\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 037 | loss: 0.69536 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69527\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 038 | loss: 0.69527 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69516\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 039 | loss: 0.69516 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69507\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 040 | loss: 0.69507 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69498\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 041 | loss: 0.69498 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69489\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 042 | loss: 0.69489 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69480\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 043 | loss: 0.69480 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69471\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 044 | loss: 0.69471 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69462\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 045 | loss: 0.69462 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69453\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 046 | loss: 0.69453 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69445\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 047 | loss: 0.69445 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69435\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 048 | loss: 0.69435 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69427\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 049 | loss: 0.69427 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69417\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 050 | loss: 0.69417 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69409\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 051 | loss: 0.69409 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69398\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 052 | loss: 0.69398 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69389\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 053 | loss: 0.69389 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69378\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 054 | loss: 0.69378 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69368\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 055 | loss: 0.69368 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69356\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 056 | loss: 0.69356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 057 | loss: 0.69345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 058 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 059 | loss: 0.69319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69303\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 060 | loss: 0.69303 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69289\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 061 | loss: 0.69289 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69271\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 062 | loss: 0.69271 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69255\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 063 | loss: 0.69255 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69232\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 064 | loss: 0.69232 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69213\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 065 | loss: 0.69213 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69185\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 066 | loss: 0.69185 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69160\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 067 | loss: 0.69160 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69129\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 068 | loss: 0.69129 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69093\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 069 | loss: 0.69093 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69054\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 070 | loss: 0.69054 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69002\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 071 | loss: 0.69002 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69174\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 072 | loss: 0.69174 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69146\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 073 | loss: 0.69146 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69097\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 074 | loss: 0.69097 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69024\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 075 | loss: 0.69024 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.68949\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 076 | loss: 0.68949 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.68859\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 077 | loss: 0.68859 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.68743\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 078 | loss: 0.68743 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.68602\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 079 | loss: 0.68602 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.68445\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 080 | loss: 0.68445 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.68231\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 081 | loss: 0.68231 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.67963\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 082 | loss: 0.67963 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.67685\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 083 | loss: 0.67685 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.67366\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 084 | loss: 0.67366 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.67067\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 085 | loss: 0.67067 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.66763\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 086 | loss: 0.66763 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.66374\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 087 | loss: 0.66374 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.66056\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 088 | loss: 0.66056 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.65667\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 089 | loss: 0.65667 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.65343\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 090 | loss: 0.65343 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 091 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.64751\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 092 | loss: 0.64751 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.64433\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 093 | loss: 0.64433 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.64142\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 094 | loss: 0.64142 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.63914\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 095 | loss: 0.63914 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.63670\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 096 | loss: 0.63670 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.63432\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 097 | loss: 0.63432 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.63207\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 098 | loss: 0.63207 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.62995\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 099 | loss: 0.62995 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.62802\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 100 | loss: 0.62802 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.62648\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 101 | loss: 0.62648 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.62492\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 102 | loss: 0.62492 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.62341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 103 | loss: 0.62341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.62197\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 104 | loss: 0.62197 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.62061\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 105 | loss: 0.62061 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.61934\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 106 | loss: 0.61934 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.61815\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 107 | loss: 0.61815 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.61705\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 108 | loss: 0.61705 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.61606\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 109 | loss: 0.61606 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.61512\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 110 | loss: 0.61512 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.61424\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 111 | loss: 0.61424 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.61346\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 112 | loss: 0.61346 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.61277\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 113 | loss: 0.61277 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.61210\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 114 | loss: 0.61210 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.61146\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 115 | loss: 0.61146 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.61085\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 116 | loss: 0.61085 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.61028\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 117 | loss: 0.61028 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.60974\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 118 | loss: 0.60974 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.60922\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 119 | loss: 0.60922 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.60876\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 120 | loss: 0.60876 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.60839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 121 | loss: 0.60839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.60802\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 122 | loss: 0.60802 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.60766\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 123 | loss: 0.60766 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.60731\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 124 | loss: 0.60731 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.60697\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 125 | loss: 0.60697 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.60665\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 126 | loss: 0.60665 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.60634\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 127 | loss: 0.60634 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.60605\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 128 | loss: 0.60605 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.60577\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 129 | loss: 0.60577 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.60550\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 130 | loss: 0.60550 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.60526\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 131 | loss: 0.60526 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.60506\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 132 | loss: 0.60506 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.60487\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 133 | loss: 0.60487 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.60468\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 134 | loss: 0.60468 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.60450\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 135 | loss: 0.60450 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.60431\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 136 | loss: 0.60431 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.60413\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 137 | loss: 0.60413 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.60396\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 138 | loss: 0.60396 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.60380\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 139 | loss: 0.60380 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.60363\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 140 | loss: 0.60363 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.60348\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 141 | loss: 0.60348 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.60333\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 142 | loss: 0.60333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.60320\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 143 | loss: 0.60320 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.60310\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 144 | loss: 0.60310 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.60299\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 145 | loss: 0.60299 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.60288\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 146 | loss: 0.60288 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.60277\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 147 | loss: 0.60277 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.60267\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 148 | loss: 0.60267 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.60256\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 149 | loss: 0.60256 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.60246\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 150 | loss: 0.60246 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.60235\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 151 | loss: 0.60235 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.60226\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 152 | loss: 0.60226 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.60216\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 153 | loss: 0.60216 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.60207\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 154 | loss: 0.60207 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.60199\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 155 | loss: 0.60199 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.60192\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 156 | loss: 0.60192 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.60185\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 157 | loss: 0.60185 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.60178\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 158 | loss: 0.60178 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.60171\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 159 | loss: 0.60171 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.60164\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 160 | loss: 0.60164 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.60157\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 161 | loss: 0.60157 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.60150\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 162 | loss: 0.60150 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.60143\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 163 | loss: 0.60143 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.60137\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 164 | loss: 0.60137 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.60130\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 165 | loss: 0.60130 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.60124\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 166 | loss: 0.60124 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.60119\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 167 | loss: 0.60119 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.60113\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 168 | loss: 0.60113 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.60108\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 169 | loss: 0.60108 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.60102\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 170 | loss: 0.60102 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.60097\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 171 | loss: 0.60097 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.60092\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 172 | loss: 0.60092 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.60087\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 173 | loss: 0.60087 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.60083\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 174 | loss: 0.60083 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.60078\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 175 | loss: 0.60078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.60073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 176 | loss: 0.60073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.60069\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 177 | loss: 0.60069 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.60065\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 178 | loss: 0.60065 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.60061\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 179 | loss: 0.60061 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.60057\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 180 | loss: 0.60057 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.60053\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 181 | loss: 0.60053 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.60049\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 182 | loss: 0.60049 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.60045\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 183 | loss: 0.60045 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.60042\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 184 | loss: 0.60042 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.60038\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 185 | loss: 0.60038 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.60035\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 186 | loss: 0.60035 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.60031\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 187 | loss: 0.60031 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.60028\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 188 | loss: 0.60028 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.60025\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 189 | loss: 0.60025 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.60022\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 190 | loss: 0.60022 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.60019\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 191 | loss: 0.60019 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.60016\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 192 | loss: 0.60016 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.60013\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 193 | loss: 0.60013 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.60010\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 194 | loss: 0.60010 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.60007\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 195 | loss: 0.60007 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.60004\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 196 | loss: 0.60004 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.60001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 197 | loss: 0.60001 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.59999\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 198 | loss: 0.59999 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.59996\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 199 | loss: 0.59996 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.59994\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 200 | loss: 0.59994 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.59992\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 201 | loss: 0.59992 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.59989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 202 | loss: 0.59989 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.59987\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 203 | loss: 0.59987 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.59984\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 204 | loss: 0.59984 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.59983\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 205 | loss: 0.59983 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.59981\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 206 | loss: 0.59981 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.59979\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 207 | loss: 0.59979 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.59977\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 208 | loss: 0.59977 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.59975\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 209 | loss: 0.59975 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.59973\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 210 | loss: 0.59973 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.59970\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 211 | loss: 0.59970 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.59968\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 212 | loss: 0.59968 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.59966\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 213 | loss: 0.59966 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.59964\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 214 | loss: 0.59964 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.59962\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 215 | loss: 0.59962 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.59961\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 216 | loss: 0.59961 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.59959\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 217 | loss: 0.59959 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.59957\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 218 | loss: 0.59957 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.59955\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 219 | loss: 0.59955 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.59953\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 220 | loss: 0.59953 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.59951\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 221 | loss: 0.59951 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.59950\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 222 | loss: 0.59950 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.59948\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 223 | loss: 0.59948 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.59947\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 224 | loss: 0.59947 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.59945\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 225 | loss: 0.59945 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.59943\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 226 | loss: 0.59943 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.59942\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 227 | loss: 0.59942 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.59940\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 228 | loss: 0.59940 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.59939\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 229 | loss: 0.59939 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.59938\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 230 | loss: 0.59938 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.59937\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 231 | loss: 0.59937 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.59935\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 232 | loss: 0.59935 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.59934\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 233 | loss: 0.59934 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.59932\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 234 | loss: 0.59932 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.59931\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 235 | loss: 0.59931 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.59929\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 236 | loss: 0.59929 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.59928\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 237 | loss: 0.59928 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.59927\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 238 | loss: 0.59927 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.59926\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 239 | loss: 0.59926 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.59924\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 240 | loss: 0.59924 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.59923\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 241 | loss: 0.59923 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.59922\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 242 | loss: 0.59922 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.59920\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 243 | loss: 0.59920 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.59919\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 244 | loss: 0.59919 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.59918\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 245 | loss: 0.59918 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.59917\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 246 | loss: 0.59917 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.59916\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 247 | loss: 0.59916 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.59915\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 248 | loss: 0.59915 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.59914\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 249 | loss: 0.59914 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.59912\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 250 | loss: 0.59912 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.59912\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 251 | loss: 0.59912 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.59911\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 252 | loss: 0.59911 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.59910\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 253 | loss: 0.59910 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.59909\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 254 | loss: 0.59909 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.59908\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 255 | loss: 0.59908 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.59907\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 256 | loss: 0.59907 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.59906\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 257 | loss: 0.59906 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.59904\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 258 | loss: 0.59904 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.59904\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 259 | loss: 0.59904 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.59903\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 260 | loss: 0.59903 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.59902\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 261 | loss: 0.59902 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.59901\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 262 | loss: 0.59901 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.59900\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 263 | loss: 0.59900 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.59899\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 264 | loss: 0.59899 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.59898\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 265 | loss: 0.59898 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.59897\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 266 | loss: 0.59897 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.59896\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 267 | loss: 0.59896 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.59895\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 268 | loss: 0.59895 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.59894\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 269 | loss: 0.59894 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.62377\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 270 | loss: 0.62377 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.62128\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 271 | loss: 0.62128 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.61904\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 272 | loss: 0.61904 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.61702\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 273 | loss: 0.61702 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.61520\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 274 | loss: 0.61520 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.61356\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 275 | loss: 0.61356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.61209\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 276 | loss: 0.61209 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.61076\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 277 | loss: 0.61076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.60957\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 278 | loss: 0.60957 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.60849\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 279 | loss: 0.60849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.60753\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 280 | loss: 0.60753 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.60665\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 281 | loss: 0.60665 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.60586\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 282 | loss: 0.60586 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.60516\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 283 | loss: 0.60516 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.60452\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 284 | loss: 0.60452 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.60394\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 285 | loss: 0.60394 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.60342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 286 | loss: 0.60342 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.60295\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 287 | loss: 0.60295 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.60253\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 288 | loss: 0.60253 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.60215\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 289 | loss: 0.60215 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.60181\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 290 | loss: 0.60181 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.60150\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 291 | loss: 0.60150 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.60123\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 292 | loss: 0.60123 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.60097\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 293 | loss: 0.60097 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.60075\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 294 | loss: 0.60075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.60054\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 295 | loss: 0.60054 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.60036\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 296 | loss: 0.60036 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.60019\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 297 | loss: 0.60019 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.60004\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 298 | loss: 0.60004 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.59990\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 299 | loss: 0.59990 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.59978\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 300 | loss: 0.59978 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.59966\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 301 | loss: 0.59966 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.59956\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 302 | loss: 0.59956 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.59947\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 303 | loss: 0.59947 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.59939\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 304 | loss: 0.59939 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.59931\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 305 | loss: 0.59931 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.59924\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 306 | loss: 0.59924 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.59918\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 307 | loss: 0.59918 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.59912\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 308 | loss: 0.59912 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.59907\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 309 | loss: 0.59907 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.59902\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 310 | loss: 0.59902 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.59898\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 311 | loss: 0.59898 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.59894\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 312 | loss: 0.59894 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.59890\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 313 | loss: 0.59890 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.59887\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 314 | loss: 0.59887 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.59884\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 315 | loss: 0.59884 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.59881\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 316 | loss: 0.59881 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.59878\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 317 | loss: 0.59878 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.59876\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 318 | loss: 0.59876 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.59874\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 319 | loss: 0.59874 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.59872\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 320 | loss: 0.59872 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.59870\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 321 | loss: 0.59870 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.59868\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 322 | loss: 0.59868 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.59866\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 323 | loss: 0.59866 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.59865\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 324 | loss: 0.59865 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.59863\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 325 | loss: 0.59863 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.59862\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 326 | loss: 0.59862 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.59861\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 327 | loss: 0.59861 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.59860\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 328 | loss: 0.59860 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.59858\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 329 | loss: 0.59858 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 330 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.59856\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 331 | loss: 0.59856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.59855\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 332 | loss: 0.59855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.59854\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 333 | loss: 0.59854 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.59853\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 334 | loss: 0.59853 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.59852\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 335 | loss: 0.59852 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.59851\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 336 | loss: 0.59851 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.59850\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 337 | loss: 0.59850 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.59849\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 338 | loss: 0.59849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.59848\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 339 | loss: 0.59848 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 340 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 341 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.59846\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 342 | loss: 0.59846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 343 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 344 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 345 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 346 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 347 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.59841\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 348 | loss: 0.59841 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.59840\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 349 | loss: 0.59840 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 350 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 351 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 352 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 353 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.62322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 354 | loss: 0.62322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.62072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 355 | loss: 0.62072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.61848\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 356 | loss: 0.61848 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.61646\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 357 | loss: 0.61646 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.61464\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 358 | loss: 0.61464 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.61300\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 359 | loss: 0.61300 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.61152\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 360 | loss: 0.61152 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.61019\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 361 | loss: 0.61019 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.60899\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 362 | loss: 0.60899 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.60791\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 363 | loss: 0.60791 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.60694\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 364 | loss: 0.60694 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.60607\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 365 | loss: 0.60607 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.60528\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 366 | loss: 0.60528 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.60456\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 367 | loss: 0.60456 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.60392\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 368 | loss: 0.60392 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.60334\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 369 | loss: 0.60334 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.60282\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 370 | loss: 0.60282 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.60235\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 371 | loss: 0.60235 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.60192\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 372 | loss: 0.60192 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.60154\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 373 | loss: 0.60154 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.60119\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 374 | loss: 0.60119 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.60088\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 375 | loss: 0.60088 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.60060\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 376 | loss: 0.60060 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.60034\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 377 | loss: 0.60034 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.60010\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 378 | loss: 0.60010 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.59989\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 379 | loss: 0.59989 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.59970\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 380 | loss: 0.59970 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.59953\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 381 | loss: 0.59953 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.59937\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 382 | loss: 0.59937 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.59922\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 383 | loss: 0.59922 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.59909\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 384 | loss: 0.59909 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.59897\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 385 | loss: 0.59897 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.59886\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 386 | loss: 0.59886 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.59876\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 387 | loss: 0.59876 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.59866\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 388 | loss: 0.59866 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 389 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.59849\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 390 | loss: 0.59849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 391 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 392 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.59829\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 393 | loss: 0.59829 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.59823\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 394 | loss: 0.59823 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.59818\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 395 | loss: 0.59818 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.59813\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 396 | loss: 0.59813 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.59808\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 397 | loss: 0.59808 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.59804\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 398 | loss: 0.59804 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.59800\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 399 | loss: 0.59800 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.59797\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 400 | loss: 0.59797 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.59793\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 401 | loss: 0.59793 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.59790\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 402 | loss: 0.59790 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.59787\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 403 | loss: 0.59787 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.59784\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 404 | loss: 0.59784 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.59782\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 405 | loss: 0.59782 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.59779\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 406 | loss: 0.59779 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.59777\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 407 | loss: 0.59777 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.59775\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 408 | loss: 0.59775 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.59772\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 409 | loss: 0.59772 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.59770\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 410 | loss: 0.59770 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.59768\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 411 | loss: 0.59768 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.59799\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 412 | loss: 0.59799 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.59794\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 413 | loss: 0.59794 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.59790\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 414 | loss: 0.59790 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.59786\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 415 | loss: 0.59786 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.59782\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 416 | loss: 0.59782 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.59778\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 417 | loss: 0.59778 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.59775\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 418 | loss: 0.59775 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.59772\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 419 | loss: 0.59772 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.59768\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 420 | loss: 0.59768 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.59765\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 421 | loss: 0.59765 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.59763\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 422 | loss: 0.59763 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.59760\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 423 | loss: 0.59760 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.59758\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 424 | loss: 0.59758 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.59755\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 425 | loss: 0.59755 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.59753\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 426 | loss: 0.59753 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.59751\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 427 | loss: 0.59751 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.59749\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 428 | loss: 0.59749 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.59746\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 429 | loss: 0.59746 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.59744\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 430 | loss: 0.59744 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.59743\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 431 | loss: 0.59743 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.59740\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 432 | loss: 0.59740 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.59739\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 433 | loss: 0.59739 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.59737\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 434 | loss: 0.59737 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.59735\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 435 | loss: 0.59735 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.59733\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 436 | loss: 0.59733 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.59731\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 437 | loss: 0.59731 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.59730\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 438 | loss: 0.59730 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.59728\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 439 | loss: 0.59728 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.59726\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 440 | loss: 0.59726 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.59724\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 441 | loss: 0.59724 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.59723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 442 | loss: 0.59723 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.59721\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 443 | loss: 0.59721 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.59719\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 444 | loss: 0.59719 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.59718\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 445 | loss: 0.59718 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.59716\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 446 | loss: 0.59716 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.59714\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 447 | loss: 0.59714 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.59712\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 448 | loss: 0.59712 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.59710\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 449 | loss: 0.59710 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.59708\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 450 | loss: 0.59708 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.59707\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 451 | loss: 0.59707 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.59705\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 452 | loss: 0.59705 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.59703\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 453 | loss: 0.59703 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.59701\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 454 | loss: 0.59701 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.59699\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 455 | loss: 0.59699 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.59697\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 456 | loss: 0.59697 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.59696\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 457 | loss: 0.59696 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.59694\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 458 | loss: 0.59694 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.59691\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 459 | loss: 0.59691 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.59690\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 460 | loss: 0.59690 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.59688\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 461 | loss: 0.59688 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.59686\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 462 | loss: 0.59686 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.59683\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 463 | loss: 0.59683 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.59681\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 464 | loss: 0.59681 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.59679\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 465 | loss: 0.59679 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.59677\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 466 | loss: 0.59677 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.59675\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 467 | loss: 0.59675 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.59673\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 468 | loss: 0.59673 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.59670\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 469 | loss: 0.59670 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.59668\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 470 | loss: 0.59668 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.59666\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 471 | loss: 0.59666 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.59663\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 472 | loss: 0.59663 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.59661\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 473 | loss: 0.59661 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.59658\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 474 | loss: 0.59658 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.59656\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 475 | loss: 0.59656 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.59653\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 476 | loss: 0.59653 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.59651\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 477 | loss: 0.59651 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.59648\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 478 | loss: 0.59648 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.59645\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 479 | loss: 0.59645 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.59643\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 480 | loss: 0.59643 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.59640\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 481 | loss: 0.59640 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.62177\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 482 | loss: 0.62177 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.61922\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 483 | loss: 0.61922 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.61692\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 484 | loss: 0.61692 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.61483\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 485 | loss: 0.61483 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.61295\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 486 | loss: 0.61295 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.61126\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 487 | loss: 0.61126 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.61035\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 488 | loss: 0.61035 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.60892\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 489 | loss: 0.60892 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.63243\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 490 | loss: 0.63243 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.62879\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 491 | loss: 0.62879 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.62608\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 492 | loss: 0.62608 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.62306\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 493 | loss: 0.62306 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.62034\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 494 | loss: 0.62034 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.61790\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 495 | loss: 0.61790 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.64049\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 496 | loss: 0.64049 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.63602\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 497 | loss: 0.63602 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.63199\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 498 | loss: 0.63199 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.62836\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 499 | loss: 0.62836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.62509\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 500 | loss: 0.62509 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Final Updated Weights: [[-1.7978529]\n",
      " [ 4.333626 ]]\n",
      "Expected:  [False, True, True, False]\n",
      "Predicted:  [False, True, False, False]\n",
      "Efficiency: 75.00%\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "Y = [[0], [1], [1], [0]]\n",
    "\n",
    "# Define the network architecture\n",
    "input_layer = input_data(shape=[None, 2])\n",
    "hidden_layer = fully_connected(input_layer, 2, activation='relu')  # Changed activation function to ReLU\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='sigmoid')  # Output layer remains sigmoid\n",
    "\n",
    "# Define the regression layer using the output layer\n",
    "regression_layer = regression(output_layer, optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
    "\n",
    "# Create the model using the regression layer\n",
    "model = tflearn.DNN(regression_layer)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, n_epoch=500, show_metric=True)\n",
    "# Get the final updated weights of the model\n",
    "final_weights = model.get_weights(output_layer.W)\n",
    "print(\"Final Updated Weights:\", final_weights)\n",
    "# Predict the output\n",
    "predicted = model.predict(X)\n",
    "predicted_classes = [i[0] > 0.5 for i in predicted]  # Use 0.5 as the threshold for sigmoid\n",
    "\n",
    "# Convert Y to list of bool values\n",
    "expected_classes = [i[0] > 0.5 for i in Y]  # Use 0.5 as the threshold for sigmoid\n",
    "\n",
    "# Compare and calculate efficiency\n",
    "correct_predictions = sum(1 for expected, predicted in zip(expected_classes, predicted_classes) if expected == predicted)\n",
    "total_predictions = len(expected_classes)\n",
    "efficiency = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "print(\"Expected: \", expected_classes)\n",
    "print(\"Predicted: \", predicted_classes)\n",
    "print(\"Efficiency: {:.2f}%\".format(efficiency))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45919dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\91960\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: EV5K0K\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.134s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.65166\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 002 | loss: 0.65166 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.70721\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 003 | loss: 0.70721 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.71362\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 004 | loss: 0.71362 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.71291\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 005 | loss: 0.71291 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.71103\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 006 | loss: 0.71103 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.70912\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 007 | loss: 0.70912 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.70741\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 008 | loss: 0.70741 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.70593\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 009 | loss: 0.70593 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.70466\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 010 | loss: 0.70466 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.70358\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 011 | loss: 0.70358 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.70264\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 012 | loss: 0.70264 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.70183\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 013 | loss: 0.70183 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.70113\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 014 | loss: 0.70113 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.70051\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 015 | loss: 0.70051 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69997\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 016 | loss: 0.69997 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69949\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 017 | loss: 0.69949 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69906\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 018 | loss: 0.69906 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69868\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 019 | loss: 0.69868 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 020 | loss: 0.69833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69802\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 021 | loss: 0.69802 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69774\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 022 | loss: 0.69774 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69748\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 023 | loss: 0.69748 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69725\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 024 | loss: 0.69725 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69703\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 025 | loss: 0.69703 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69683\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 026 | loss: 0.69683 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69665\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 027 | loss: 0.69665 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69647\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 028 | loss: 0.69647 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69631\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 029 | loss: 0.69631 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69616\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 030 | loss: 0.69616 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69602\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 031 | loss: 0.69602 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69589\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 032 | loss: 0.69589 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69577\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 033 | loss: 0.69577 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69564\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 034 | loss: 0.69564 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69553\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 035 | loss: 0.69553 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69542\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 036 | loss: 0.69542 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69532\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 037 | loss: 0.69532 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69521\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 038 | loss: 0.69521 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69512\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 039 | loss: 0.69512 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69503\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 040 | loss: 0.69503 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69493\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 041 | loss: 0.69493 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69506\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 042 | loss: 0.69506 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69496\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 043 | loss: 0.69496 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69485\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 044 | loss: 0.69485 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69475\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 045 | loss: 0.69475 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69466\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 046 | loss: 0.69466 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69456\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 047 | loss: 0.69456 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69447\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 048 | loss: 0.69447 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69439\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 049 | loss: 0.69439 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69430\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 050 | loss: 0.69430 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69423\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 051 | loss: 0.69423 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69415\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 052 | loss: 0.69415 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69406\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 053 | loss: 0.69406 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69430\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 054 | loss: 0.69430 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69421\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 055 | loss: 0.69421 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69411\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 056 | loss: 0.69411 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69402\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 057 | loss: 0.69402 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69392\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 058 | loss: 0.69392 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69382\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 059 | loss: 0.69382 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69374\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 060 | loss: 0.69374 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69365\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 061 | loss: 0.69365 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69356\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 062 | loss: 0.69356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69349\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 063 | loss: 0.69349 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 064 | loss: 0.69339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 065 | loss: 0.69331 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 066 | loss: 0.69323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 067 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69305\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 068 | loss: 0.69305 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69296\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 069 | loss: 0.69296 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69288\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 070 | loss: 0.69288 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69278\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 071 | loss: 0.69278 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69268\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 072 | loss: 0.69268 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69260\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 073 | loss: 0.69260 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69251\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 074 | loss: 0.69251 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69240\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 075 | loss: 0.69240 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.69231\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 076 | loss: 0.69231 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.69220\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 077 | loss: 0.69220 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.69212\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 078 | loss: 0.69212 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.69201\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 079 | loss: 0.69201 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.69191\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 080 | loss: 0.69191 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.69181\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 081 | loss: 0.69181 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.69168\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 082 | loss: 0.69168 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.69159\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 083 | loss: 0.69159 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.69145\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 084 | loss: 0.69145 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.69135\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 085 | loss: 0.69135 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.69121\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 086 | loss: 0.69121 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.69110\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 087 | loss: 0.69110 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.69095\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 088 | loss: 0.69095 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.69084\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 089 | loss: 0.69084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.69068\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 090 | loss: 0.69068 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.69056\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 091 | loss: 0.69056 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.69040\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 092 | loss: 0.69040 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.69025\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 093 | loss: 0.69025 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.69011\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 094 | loss: 0.69011 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.68992\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 095 | loss: 0.68992 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.68979\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 096 | loss: 0.68979 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.68956\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 097 | loss: 0.68956 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.68937\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 098 | loss: 0.68937 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.68917\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 099 | loss: 0.68917 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.68899\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 100 | loss: 0.68899 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.68883\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 101 | loss: 0.68883 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.68856\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 102 | loss: 0.68856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.68834\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 103 | loss: 0.68834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.68814\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 104 | loss: 0.68814 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.68795\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 105 | loss: 0.68795 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.68769\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 106 | loss: 0.68769 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.68742\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 107 | loss: 0.68742 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.68716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 108 | loss: 0.68716 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.68701\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 109 | loss: 0.68701 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.68669\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 110 | loss: 0.68669 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.68641\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 111 | loss: 0.68641 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.68625\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 112 | loss: 0.68625 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.68591\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 113 | loss: 0.68591 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.68553\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 114 | loss: 0.68553 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.68541\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 115 | loss: 0.68541 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.68505\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 116 | loss: 0.68505 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.68457\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 117 | loss: 0.68457 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.68420\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 118 | loss: 0.68420 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.68378\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 119 | loss: 0.68378 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.68339\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 120 | loss: 0.68339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.68284\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 121 | loss: 0.68284 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.68246\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 122 | loss: 0.68246 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.68196\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 123 | loss: 0.68196 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.68158\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 124 | loss: 0.68158 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.68100\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 125 | loss: 0.68100 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.68055\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 126 | loss: 0.68055 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.68058\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 127 | loss: 0.68058 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.68010\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 128 | loss: 0.68010 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.67941\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 129 | loss: 0.67941 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.67879\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 130 | loss: 0.67879 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.67839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 131 | loss: 0.67839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.67776\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 132 | loss: 0.67776 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.67728\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 133 | loss: 0.67728 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.67655\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 134 | loss: 0.67655 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.67578\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 135 | loss: 0.67578 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.67531\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 136 | loss: 0.67531 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.67456\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 137 | loss: 0.67456 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.67394\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 138 | loss: 0.67394 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.67350\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 139 | loss: 0.67350 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.67274\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 140 | loss: 0.67274 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.67186\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 141 | loss: 0.67186 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.67130\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 142 | loss: 0.67130 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.67103\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 143 | loss: 0.67103 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.67030\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 144 | loss: 0.67030 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.66981\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 145 | loss: 0.66981 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.66931\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 146 | loss: 0.66931 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.66854\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 147 | loss: 0.66854 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.66769\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 148 | loss: 0.66769 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.66701\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 149 | loss: 0.66701 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.66670\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 150 | loss: 0.66670 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.66602\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 151 | loss: 0.66602 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.66528\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 152 | loss: 0.66528 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.66476\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 153 | loss: 0.66476 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.66451\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 154 | loss: 0.66451 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.66391\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 155 | loss: 0.66391 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.66322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 156 | loss: 0.66322 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.66252\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 157 | loss: 0.66252 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.66192\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 158 | loss: 0.66192 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.66180\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 159 | loss: 0.66180 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.66132\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 160 | loss: 0.66132 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.66077\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 161 | loss: 0.66077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.66022\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 162 | loss: 0.66022 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.65978\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 163 | loss: 0.65978 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.65974\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 164 | loss: 0.65974 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.65936\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 165 | loss: 0.65936 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.65891\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 166 | loss: 0.65891 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.65845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 167 | loss: 0.65845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.65798\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 168 | loss: 0.65798 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.65753\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 169 | loss: 0.65753 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.65711\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 170 | loss: 0.65711 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.65686\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 171 | loss: 0.65686 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.65684\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 172 | loss: 0.65684 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.65661\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 173 | loss: 0.65661 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.67034\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 174 | loss: 0.67034 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.66885\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 175 | loss: 0.66885 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.66745\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 176 | loss: 0.66745 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.66614\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 177 | loss: 0.66614 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.66492\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 178 | loss: 0.66492 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.66380\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 179 | loss: 0.66380 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.66279\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 180 | loss: 0.66279 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.66187\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 181 | loss: 0.66187 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.66118\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 182 | loss: 0.66118 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.66070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 183 | loss: 0.66070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.66008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 184 | loss: 0.66008 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.65944\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 185 | loss: 0.65944 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.65883\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 186 | loss: 0.65883 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.65824\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 187 | loss: 0.65824 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.65768\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 188 | loss: 0.65768 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.65716\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 189 | loss: 0.65716 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.65668\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 190 | loss: 0.65668 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.65623\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 191 | loss: 0.65623 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.65581\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 192 | loss: 0.65581 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.65542\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 193 | loss: 0.65542 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.65508\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 194 | loss: 0.65508 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.65477\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 195 | loss: 0.65477 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.65460\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 196 | loss: 0.65460 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.65457\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 197 | loss: 0.65457 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.65442\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 198 | loss: 0.65442 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.65424\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 199 | loss: 0.65424 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.65404\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 200 | loss: 0.65404 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.65384\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 201 | loss: 0.65384 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.65365\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 202 | loss: 0.65365 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.65346\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 203 | loss: 0.65346 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.65329\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 204 | loss: 0.65329 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.65312\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 205 | loss: 0.65312 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.65296\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 206 | loss: 0.65296 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.65283\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 207 | loss: 0.65283 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.65271\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 208 | loss: 0.65271 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.65260\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 209 | loss: 0.65260 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.65256\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 210 | loss: 0.65256 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.65266\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 211 | loss: 0.65266 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.65265\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 212 | loss: 0.65265 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.65261\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 213 | loss: 0.65261 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.65254\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 214 | loss: 0.65254 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.65246\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 215 | loss: 0.65246 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.65238\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 216 | loss: 0.65238 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.65229\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 217 | loss: 0.65229 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.65221\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 218 | loss: 0.65221 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.65213\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 219 | loss: 0.65213 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.65205\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 220 | loss: 0.65205 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.65197\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 221 | loss: 0.65197 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.65189\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 222 | loss: 0.65189 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.65182\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 223 | loss: 0.65182 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.65176\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 224 | loss: 0.65176 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.65169\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 225 | loss: 0.65169 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.65164\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 226 | loss: 0.65164 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.65158\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 227 | loss: 0.65158 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.65153\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 228 | loss: 0.65153 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.65148\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 229 | loss: 0.65148 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.65143\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 230 | loss: 0.65143 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.65140\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 231 | loss: 0.65140 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.65137\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 232 | loss: 0.65137 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.65135\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 233 | loss: 0.65135 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.65135\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 234 | loss: 0.65135 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.65146\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 235 | loss: 0.65146 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.65151\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 236 | loss: 0.65151 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.65153\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 237 | loss: 0.65153 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.65153\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 238 | loss: 0.65153 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.65153\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 239 | loss: 0.65153 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.65151\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 240 | loss: 0.65151 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.65149\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 241 | loss: 0.65149 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.65146\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 242 | loss: 0.65146 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.65143\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 243 | loss: 0.65143 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.65140\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 244 | loss: 0.65140 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.65138\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 245 | loss: 0.65138 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.65135\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 246 | loss: 0.65135 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.65132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 247 | loss: 0.65132 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.65129\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 248 | loss: 0.65129 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.65126\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 249 | loss: 0.65126 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.65123\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 250 | loss: 0.65123 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.65121\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 251 | loss: 0.65121 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.65118\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 252 | loss: 0.65118 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.65116\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 253 | loss: 0.65116 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.65114\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 254 | loss: 0.65114 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.65113\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 255 | loss: 0.65113 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.65112\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 256 | loss: 0.65112 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.65111\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 257 | loss: 0.65111 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.65110\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 258 | loss: 0.65110 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.65109\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 259 | loss: 0.65109 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.65108\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 260 | loss: 0.65108 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.65110\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 261 | loss: 0.65110 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.65119\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 262 | loss: 0.65119 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.65125\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 263 | loss: 0.65125 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.65128\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 264 | loss: 0.65128 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.65129\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 265 | loss: 0.65129 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.65130\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 266 | loss: 0.65130 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.65129\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 267 | loss: 0.65129 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.65128\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 268 | loss: 0.65128 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.65127\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 269 | loss: 0.65127 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.65125\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 270 | loss: 0.65125 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.65123\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 271 | loss: 0.65123 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.65122\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 272 | loss: 0.65122 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.65120\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 273 | loss: 0.65120 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.65118\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 274 | loss: 0.65118 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.65116\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 275 | loss: 0.65116 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.65114\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 276 | loss: 0.65114 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.65112\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 277 | loss: 0.65112 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.65110\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 278 | loss: 0.65110 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.65108\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 279 | loss: 0.65108 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.65107\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 280 | loss: 0.65107 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.65105\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 281 | loss: 0.65105 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.65103\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 282 | loss: 0.65103 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.65102\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 283 | loss: 0.65102 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.65100\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 284 | loss: 0.65100 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.65099\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 285 | loss: 0.65099 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.65098\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 286 | loss: 0.65098 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.65096\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 287 | loss: 0.65096 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.65095\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 288 | loss: 0.65095 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.65094\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 289 | loss: 0.65094 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.65093\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 290 | loss: 0.65093 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.65092\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 291 | loss: 0.65092 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.65091\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 292 | loss: 0.65091 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.65090\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 293 | loss: 0.65090 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.65089\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 294 | loss: 0.65089 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.65089\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 295 | loss: 0.65089 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.65088\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 296 | loss: 0.65088 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.65087\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 297 | loss: 0.65087 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.65086\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 298 | loss: 0.65086 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.65086\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 299 | loss: 0.65086 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.66794\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 300 | loss: 0.66794 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.66626\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 301 | loss: 0.66626 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.66475\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 302 | loss: 0.66475 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.66338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 303 | loss: 0.66338 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.66215\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 304 | loss: 0.66215 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.66104\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 305 | loss: 0.66104 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.66004\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 306 | loss: 0.66004 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.65913\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 307 | loss: 0.65913 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.65832\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 308 | loss: 0.65832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.65758\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 309 | loss: 0.65758 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.65692\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 310 | loss: 0.65692 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.65633\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 311 | loss: 0.65633 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.65579\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 312 | loss: 0.65579 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.65531\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 313 | loss: 0.65531 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.65487\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 314 | loss: 0.65487 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.65448\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 315 | loss: 0.65448 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.65412\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 316 | loss: 0.65412 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.65380\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 317 | loss: 0.65380 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.65351\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 318 | loss: 0.65351 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.65332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 319 | loss: 0.65332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.66952\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 320 | loss: 0.66952 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.66777\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 321 | loss: 0.66777 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.66619\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 322 | loss: 0.66619 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.66475\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 323 | loss: 0.66475 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.66345\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 324 | loss: 0.66345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.66227\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 325 | loss: 0.66227 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.66120\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 326 | loss: 0.66120 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.66023\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 327 | loss: 0.66023 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.65935\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 328 | loss: 0.65935 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.65855\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 329 | loss: 0.65855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.65783\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 330 | loss: 0.65783 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.65718\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 331 | loss: 0.65718 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.65658\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 332 | loss: 0.65658 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.65605\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 333 | loss: 0.65605 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.65556\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 334 | loss: 0.65556 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.65512\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 335 | loss: 0.65512 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.65472\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 336 | loss: 0.65472 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.65436\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 337 | loss: 0.65436 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.65403\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 338 | loss: 0.65403 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.65373\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 339 | loss: 0.65373 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.65346\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 340 | loss: 0.65346 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.65321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 341 | loss: 0.65321 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.65299\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 342 | loss: 0.65299 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.65279\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 343 | loss: 0.65279 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.65261\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 344 | loss: 0.65261 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.65244\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 345 | loss: 0.65244 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.65229\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 346 | loss: 0.65229 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.65215\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 347 | loss: 0.65215 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.65203\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 348 | loss: 0.65203 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.65192\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 349 | loss: 0.65192 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.65181\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 350 | loss: 0.65181 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.65172\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 351 | loss: 0.65172 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.65164\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 352 | loss: 0.65164 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.65156\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 353 | loss: 0.65156 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.65149\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 354 | loss: 0.65149 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.65142\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 355 | loss: 0.65142 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.65137\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 356 | loss: 0.65137 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.65131\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 357 | loss: 0.65131 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.65126\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 358 | loss: 0.65126 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.65122\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 359 | loss: 0.65122 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.66797\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 360 | loss: 0.66797 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.66631\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 361 | loss: 0.66631 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.66480\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 362 | loss: 0.66480 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.66345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 363 | loss: 0.66345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.66222\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 364 | loss: 0.66222 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.66112\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 365 | loss: 0.66112 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.66012\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 366 | loss: 0.66012 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.65921\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 367 | loss: 0.65921 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.65840\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 368 | loss: 0.65840 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.65766\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 369 | loss: 0.65766 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.65700\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 370 | loss: 0.65700 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.65639\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 371 | loss: 0.65639 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.65585\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 372 | loss: 0.65585 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.65536\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 373 | loss: 0.65536 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.65492\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 374 | loss: 0.65492 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.65452\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 375 | loss: 0.65452 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.65416\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 376 | loss: 0.65416 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.65383\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 377 | loss: 0.65383 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.65353\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 378 | loss: 0.65353 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.65327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 379 | loss: 0.65327 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.65303\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 380 | loss: 0.65303 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.65281\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 381 | loss: 0.65281 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.65261\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 382 | loss: 0.65261 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.65244\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 383 | loss: 0.65244 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.65228\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 384 | loss: 0.65228 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.65214\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 385 | loss: 0.65214 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.65201\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 386 | loss: 0.65201 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.65190\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 387 | loss: 0.65190 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.65179\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 388 | loss: 0.65179 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.65170\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 389 | loss: 0.65170 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.65161\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 390 | loss: 0.65161 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.65153\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 391 | loss: 0.65153 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.65146\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 392 | loss: 0.65146 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.65140\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 393 | loss: 0.65140 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.65134\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 394 | loss: 0.65134 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.65129\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 395 | loss: 0.65129 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.65124\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 396 | loss: 0.65124 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.65119\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 397 | loss: 0.65119 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.65116\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 398 | loss: 0.65116 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.65118\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 399 | loss: 0.65118 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.65119\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 400 | loss: 0.65119 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.65120\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 401 | loss: 0.65120 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.65119\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 402 | loss: 0.65119 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.65119\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 403 | loss: 0.65119 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.65117\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 404 | loss: 0.65117 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.65116\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 405 | loss: 0.65116 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.65115\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 406 | loss: 0.65115 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.65113\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 407 | loss: 0.65113 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.65112\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 408 | loss: 0.65112 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.65110\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 409 | loss: 0.65110 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.65108\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 410 | loss: 0.65108 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.65107\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 411 | loss: 0.65107 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.65105\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 412 | loss: 0.65105 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.65104\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 413 | loss: 0.65104 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.65102\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 414 | loss: 0.65102 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.65101\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 415 | loss: 0.65101 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.65100\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 416 | loss: 0.65100 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.65098\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 417 | loss: 0.65098 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.65097\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 418 | loss: 0.65097 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.65096\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 419 | loss: 0.65096 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.65095\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 420 | loss: 0.65095 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.65094\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 421 | loss: 0.65094 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.65092\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 422 | loss: 0.65092 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.65091\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 423 | loss: 0.65091 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.65091\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 424 | loss: 0.65091 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.65090\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 425 | loss: 0.65090 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.65089\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 426 | loss: 0.65089 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.65088\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 427 | loss: 0.65088 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.65087\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 428 | loss: 0.65087 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.65086\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 429 | loss: 0.65086 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.65086\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 430 | loss: 0.65086 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.65085\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 431 | loss: 0.65085 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.65085\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 432 | loss: 0.65085 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 433 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.65083\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 434 | loss: 0.65083 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.65083\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 435 | loss: 0.65083 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.65082\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 436 | loss: 0.65082 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.65082\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 437 | loss: 0.65082 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.65081\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 438 | loss: 0.65081 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.65081\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 439 | loss: 0.65081 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.65081\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 440 | loss: 0.65081 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.65080\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 441 | loss: 0.65080 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.65080\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 442 | loss: 0.65080 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.65079\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 443 | loss: 0.65079 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.65079\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 444 | loss: 0.65079 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.65079\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 445 | loss: 0.65079 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.65078\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 446 | loss: 0.65078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.65078\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 447 | loss: 0.65078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.65078\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 448 | loss: 0.65078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.65078\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 449 | loss: 0.65078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.65077\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 450 | loss: 0.65077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.65077\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 451 | loss: 0.65077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.65077\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 452 | loss: 0.65077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.65077\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 453 | loss: 0.65077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 454 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 455 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 456 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 457 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 458 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 459 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 460 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 461 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 462 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 463 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 464 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 465 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 466 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 467 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 468 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 469 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 470 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 471 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 472 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 473 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 474 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 475 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 476 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 477 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 478 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 479 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 480 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 481 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 482 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 483 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 484 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 485 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 486 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 487 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 488 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 489 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 490 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 491 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 492 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 493 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 494 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 495 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 496 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 497 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 498 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 499 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 500 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 501 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 502 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 503 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 504 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 505 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 506 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 507 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 508 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 509 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 510 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 511 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 512 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 513 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 514 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 515 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 516 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 517 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 518 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 519 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 520 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 521 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 522 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 523 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 524 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 525 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 526 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 527 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 528 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 529 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 530 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 531 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 532 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 533 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 534 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 535 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 536 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 537 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 538 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 539 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 540 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 541 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 542 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 543 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 544 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 545 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 546 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 547 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 548 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 549 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 550 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 551 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 552 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 553 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 554 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 555 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 556 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 557 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 558 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 559 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 560 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 561 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 562 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 563 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.65077\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 564 | loss: 0.65077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.65079\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 565 | loss: 0.65079 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.65080\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 566 | loss: 0.65080 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.65081\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 567 | loss: 0.65081 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.65082\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 568 | loss: 0.65082 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.65083\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 569 | loss: 0.65083 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 570 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 571 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 572 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 573 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 574 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 575 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 576 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 577 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 578 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.65084\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 579 | loss: 0.65084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.65083\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 580 | loss: 0.65083 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.65083\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 581 | loss: 0.65083 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.65083\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 582 | loss: 0.65083 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.65082\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 583 | loss: 0.65082 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.65082\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 584 | loss: 0.65082 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.65082\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 585 | loss: 0.65082 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.65082\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 586 | loss: 0.65082 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.65081\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 587 | loss: 0.65081 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.65081\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 588 | loss: 0.65081 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.65081\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 589 | loss: 0.65081 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.65080\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 590 | loss: 0.65080 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.65080\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 591 | loss: 0.65080 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.65080\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 592 | loss: 0.65080 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.65079\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 593 | loss: 0.65079 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.65079\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 594 | loss: 0.65079 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.65079\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 595 | loss: 0.65079 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.65079\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 596 | loss: 0.65079 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.65078\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 597 | loss: 0.65078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.65078\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 598 | loss: 0.65078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.65078\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 599 | loss: 0.65078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.65078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 600 | loss: 0.65078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.65077\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 601 | loss: 0.65077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.65077\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 602 | loss: 0.65077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.65077\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 603 | loss: 0.65077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.65077\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 604 | loss: 0.65077 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 605 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 606 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 607 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 608 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 609 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.65076\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 610 | loss: 0.65076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 611 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 612 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 613 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 614 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 615 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 616 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.65075\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 617 | loss: 0.65075 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 618 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 619 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 620 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 621 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 622 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 623 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 624 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.65074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 625 | loss: 0.65074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 626 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 627 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 628 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 629 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 630 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 631 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 632 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 633 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 634 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 635 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 636 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.65073\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 637 | loss: 0.65073 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 638 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 639 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 640 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 641 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 642 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 643 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 644 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 645 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 646 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 647 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 648 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 649 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 650 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 651 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 652 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 653 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.65072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 654 | loss: 0.65072 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 655 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 656 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 657 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 658 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 659 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 660 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 661 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 662 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 663 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 664 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 665 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 666 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 667 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 668 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 669 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 670 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 671 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 672 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 673 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 674 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 675 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 676 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 677 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 678 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 679 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 680 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 681 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 682 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 683 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 684 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 685 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 686 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 687 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 688 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 689 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 690 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 691 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 692 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 693 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 694 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 695 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 696 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 697 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 698 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 699 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 700 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 701 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 702 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 703 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 704 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 705 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 706 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 707 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 708 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 709 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 710 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 711 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 712 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 713 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 714 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 715 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 716 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 717 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 718 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 719 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 720 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 721 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 722 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 723 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 724 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 725 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 726 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 727 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 728 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 729 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 730 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 731 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 732 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 733 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 734 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 735 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 736 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 737 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 738 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 739 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 740 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 741 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.65070\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 742 | loss: 0.65070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 743 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 744 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 745 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 746 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 747 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 748 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 749 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 750 | loss: 0.65071 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Final Updated Weights: [[-1.8958325]\n",
      " [-3.5121155]]\n",
      "Expected:  [False, True, True, False]\n",
      "Predicted:  [True, True, True, False]\n",
      "Efficiency: 75.00%\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "Y = [[0], [1], [1], [0]]\n",
    "\n",
    "# Define the network architecture\n",
    "input_layer = input_data(shape=[None, 2])\n",
    "hidden_layer = fully_connected(input_layer, 2, activation='relu')  # Changed activation function to ReLU\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='sigmoid')  # Output layer remains sigmoid\n",
    "\n",
    "# Define the regression layer using the output layer\n",
    "regression_layer = regression(output_layer, optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
    "\n",
    "# Create the model using the regression layer\n",
    "model = tflearn.DNN(regression_layer)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, n_epoch=750, show_metric=True)\n",
    "# Get the final updated weights of the model\n",
    "final_weights = model.get_weights(output_layer.W)\n",
    "print(\"Final Updated Weights:\", final_weights)\n",
    "# Predict the output\n",
    "predicted = model.predict(X)\n",
    "predicted_classes = [i[0] > 0.5 for i in predicted]  # Use 0.5 as the threshold for sigmoid\n",
    "\n",
    "# Convert Y to list of bool values\n",
    "expected_classes = [i[0] > 0.5 for i in Y]  # Use 0.5 as the threshold for sigmoid\n",
    "\n",
    "# Compare and calculate efficiency\n",
    "correct_predictions = sum(1 for expected, predicted in zip(expected_classes, predicted_classes) if expected == predicted)\n",
    "total_predictions = len(expected_classes)\n",
    "efficiency = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "print(\"Expected: \", expected_classes)\n",
    "print(\"Predicted: \", predicted_classes)\n",
    "print(\"Efficiency: {:.2f}%\".format(efficiency))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc26be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91960\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\91960\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: 8W2EB7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.133s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.65166\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 002 | loss: 0.65166 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.70722\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 003 | loss: 0.70722 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.71362\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 004 | loss: 0.71362 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.71292\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 005 | loss: 0.71292 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.71104\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 006 | loss: 0.71104 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.70913\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 007 | loss: 0.70913 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.70742\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 008 | loss: 0.70742 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.70594\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 009 | loss: 0.70594 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.70468\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 010 | loss: 0.70468 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.70359\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 011 | loss: 0.70359 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.70266\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 012 | loss: 0.70266 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.70185\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 013 | loss: 0.70185 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.70115\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 014 | loss: 0.70115 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.70053\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 015 | loss: 0.70053 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69999\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 016 | loss: 0.69999 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69952\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 017 | loss: 0.69952 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69909\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 018 | loss: 0.69909 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69871\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 019 | loss: 0.69871 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69837\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 020 | loss: 0.69837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69807\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 021 | loss: 0.69807 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69779\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 022 | loss: 0.69779 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69753\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 023 | loss: 0.69753 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69731\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 024 | loss: 0.69731 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69709\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 025 | loss: 0.69709 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69690\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 026 | loss: 0.69690 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69672\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 027 | loss: 0.69672 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69655\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 028 | loss: 0.69655 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69640\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 029 | loss: 0.69640 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69626\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 030 | loss: 0.69626 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69612\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 031 | loss: 0.69612 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69599\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 032 | loss: 0.69599 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69587\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 033 | loss: 0.69587 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69576\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 034 | loss: 0.69576 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69565\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 035 | loss: 0.69565 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69555\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 036 | loss: 0.69555 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69546\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 037 | loss: 0.69546 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69536\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 038 | loss: 0.69536 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69527\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 039 | loss: 0.69527 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69519\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 040 | loss: 0.69519 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69511\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 041 | loss: 0.69511 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69503\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 042 | loss: 0.69503 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69495\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 043 | loss: 0.69495 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69488\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 044 | loss: 0.69488 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69481\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 045 | loss: 0.69481 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69474\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 046 | loss: 0.69474 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69466\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 047 | loss: 0.69466 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69460\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 048 | loss: 0.69460 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69453\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 049 | loss: 0.69453 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69446\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 050 | loss: 0.69446 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69439\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 051 | loss: 0.69439 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69433\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 052 | loss: 0.69433 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69426\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 053 | loss: 0.69426 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69420\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 054 | loss: 0.69420 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69413\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 055 | loss: 0.69413 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69407\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 056 | loss: 0.69407 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69400\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 057 | loss: 0.69400 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69419\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 058 | loss: 0.69419 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69414\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 059 | loss: 0.69414 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69405\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 060 | loss: 0.69405 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69397\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 061 | loss: 0.69397 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69388\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 062 | loss: 0.69388 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69380\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 063 | loss: 0.69380 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69373\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 064 | loss: 0.69373 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69365\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 065 | loss: 0.69365 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69356\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 066 | loss: 0.69356 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69349\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 067 | loss: 0.69349 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69341\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 068 | loss: 0.69341 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 069 | loss: 0.69332 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 070 | loss: 0.69325 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 071 | loss: 0.69316 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69307\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 072 | loss: 0.69307 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69299\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 073 | loss: 0.69299 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69289\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 074 | loss: 0.69289 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69280\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 075 | loss: 0.69280 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.69271\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 076 | loss: 0.69271 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.69260\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 077 | loss: 0.69260 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.69249\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 078 | loss: 0.69249 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.69238\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 079 | loss: 0.69238 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.69228\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 080 | loss: 0.69228 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.69214\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 081 | loss: 0.69214 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.69203\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 082 | loss: 0.69203 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.69189\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 083 | loss: 0.69189 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.69176\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 084 | loss: 0.69176 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.69160\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 085 | loss: 0.69160 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.69143\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 086 | loss: 0.69143 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.69127\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 087 | loss: 0.69127 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.69106\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 088 | loss: 0.69106 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.69087\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 089 | loss: 0.69087 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.69063\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 090 | loss: 0.69063 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.69042\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 091 | loss: 0.69042 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.69013\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 092 | loss: 0.69013 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.68981\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 093 | loss: 0.68981 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.68948\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 094 | loss: 0.68948 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.68910\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 095 | loss: 0.68910 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.68874\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 096 | loss: 0.68874 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.68828\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 097 | loss: 0.68828 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.68780\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 098 | loss: 0.68780 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.68721\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 099 | loss: 0.68721 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.68650\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 100 | loss: 0.68650 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.68572\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 101 | loss: 0.68572 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.68466\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 102 | loss: 0.68466 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.68339\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 103 | loss: 0.68339 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.68207\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 104 | loss: 0.68207 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.68013\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 105 | loss: 0.68013 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.67792\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 106 | loss: 0.67792 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.67540\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 107 | loss: 0.67540 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.67215\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 108 | loss: 0.67215 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.66871\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 109 | loss: 0.66871 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.66513\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 110 | loss: 0.66513 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.66173\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 111 | loss: 0.66173 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.65827\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 112 | loss: 0.65827 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.65452\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 113 | loss: 0.65452 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.65143\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 114 | loss: 0.65143 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.64792\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 115 | loss: 0.64792 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.64454\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 116 | loss: 0.64454 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.64142\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 117 | loss: 0.64142 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.63838\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 118 | loss: 0.63838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.63545\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 119 | loss: 0.63545 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.63288\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 120 | loss: 0.63288 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.63045\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 121 | loss: 0.63045 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.62839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 122 | loss: 0.62839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.62629\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 123 | loss: 0.62629 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.62441\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 124 | loss: 0.62441 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.62255\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 125 | loss: 0.62255 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.62084\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 126 | loss: 0.62084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.61924\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 127 | loss: 0.61924 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.61783\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 128 | loss: 0.61783 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.61652\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 129 | loss: 0.61652 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.61527\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 130 | loss: 0.61527 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.61409\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 131 | loss: 0.61409 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.61302\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 132 | loss: 0.61302 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.61203\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 133 | loss: 0.61203 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.61124\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 134 | loss: 0.61124 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.61048\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 135 | loss: 0.61048 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.60974\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 136 | loss: 0.60974 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.60903\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 137 | loss: 0.60903 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.60837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 138 | loss: 0.60837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.60776\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 139 | loss: 0.60776 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.60718\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 140 | loss: 0.60718 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.60665\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 141 | loss: 0.60665 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.60620\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 142 | loss: 0.60620 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.60579\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 143 | loss: 0.60579 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.60540\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 144 | loss: 0.60540 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.60502\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 145 | loss: 0.60502 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.60467\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 146 | loss: 0.60467 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.60433\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 147 | loss: 0.60433 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.60402\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 148 | loss: 0.60402 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.60373\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 149 | loss: 0.60373 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.60345\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 150 | loss: 0.60345 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.60319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 151 | loss: 0.60319 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.60300\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 152 | loss: 0.60300 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.60280\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 153 | loss: 0.60280 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.60262\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 154 | loss: 0.60262 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.60244\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 155 | loss: 0.60244 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.60226\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 156 | loss: 0.60226 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.60210\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 157 | loss: 0.60210 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.60194\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 158 | loss: 0.60194 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.60179\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 159 | loss: 0.60179 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.60169\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 160 | loss: 0.60169 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.60160\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 161 | loss: 0.60160 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.60151\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 162 | loss: 0.60151 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.60141\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 163 | loss: 0.60141 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.60131\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 164 | loss: 0.60131 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.60121\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 165 | loss: 0.60121 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.60114\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 166 | loss: 0.60114 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.60107\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 167 | loss: 0.60107 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.60099\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 168 | loss: 0.60099 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.60091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 169 | loss: 0.60091 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.60084\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 170 | loss: 0.60084 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.60076\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 171 | loss: 0.60076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.60069\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 172 | loss: 0.60069 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.60062\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 173 | loss: 0.60062 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.60055\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 174 | loss: 0.60055 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.60049\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 175 | loss: 0.60049 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.60043\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 176 | loss: 0.60043 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.60037\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 177 | loss: 0.60037 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.60031\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 178 | loss: 0.60031 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.60025\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 179 | loss: 0.60025 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.60020\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 180 | loss: 0.60020 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.60015\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 181 | loss: 0.60015 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.60010\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 182 | loss: 0.60010 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.60008\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 183 | loss: 0.60008 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.60005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 184 | loss: 0.60005 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.60002\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 185 | loss: 0.60002 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.59999\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 186 | loss: 0.59999 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.59996\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 187 | loss: 0.59996 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.59993\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 188 | loss: 0.59993 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.59990\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 189 | loss: 0.59990 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.59986\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 190 | loss: 0.59986 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.59983\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 191 | loss: 0.59983 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.62263\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 192 | loss: 0.62263 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.62033\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 193 | loss: 0.62033 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.61825\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 194 | loss: 0.61825 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.61638\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 195 | loss: 0.61638 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.61470\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 196 | loss: 0.61470 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.61318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 197 | loss: 0.61318 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.61181\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 198 | loss: 0.61181 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.61057\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 199 | loss: 0.61057 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.60946\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 200 | loss: 0.60946 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.60846\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 201 | loss: 0.60846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.60755\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 202 | loss: 0.60755 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.60675\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 203 | loss: 0.60675 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.60603\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 204 | loss: 0.60603 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.60538\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 205 | loss: 0.60538 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.60479\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 206 | loss: 0.60479 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.60425\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 207 | loss: 0.60425 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.60377\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 208 | loss: 0.60377 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.60333\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 209 | loss: 0.60333 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.60293\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 210 | loss: 0.60293 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.60257\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 211 | loss: 0.60257 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.60225\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 212 | loss: 0.60225 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.60195\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 213 | loss: 0.60195 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.60169\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 214 | loss: 0.60169 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.60145\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 215 | loss: 0.60145 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.60125\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 216 | loss: 0.60125 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.60107\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 217 | loss: 0.60107 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.60090\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 218 | loss: 0.60090 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.60074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 219 | loss: 0.60074 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.60060\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 220 | loss: 0.60060 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.60047\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 221 | loss: 0.60047 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.60035\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 222 | loss: 0.60035 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.60024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 223 | loss: 0.60024 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.60014\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 224 | loss: 0.60014 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.60004\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 225 | loss: 0.60004 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.59996\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 226 | loss: 0.59996 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.59988\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 227 | loss: 0.59988 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.59980\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 228 | loss: 0.59980 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.59974\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 229 | loss: 0.59974 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.59967\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 230 | loss: 0.59967 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.59962\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 231 | loss: 0.59962 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.59956\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 232 | loss: 0.59956 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.59951\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 233 | loss: 0.59951 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.59947\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 234 | loss: 0.59947 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.59944\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 235 | loss: 0.59944 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.59941\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 236 | loss: 0.59941 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.59939\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 237 | loss: 0.59939 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.59936\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 238 | loss: 0.59936 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.59933\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 239 | loss: 0.59933 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.59931\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 240 | loss: 0.59931 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.59929\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 241 | loss: 0.59929 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.59926\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 242 | loss: 0.59926 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.59924\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 243 | loss: 0.59924 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.59922\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 244 | loss: 0.59922 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.59920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 245 | loss: 0.59920 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.62405\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 246 | loss: 0.62405 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.62155\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 247 | loss: 0.62155 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.61929\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 248 | loss: 0.61929 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.61726\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 249 | loss: 0.61726 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.61544\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 250 | loss: 0.61544 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.61379\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 251 | loss: 0.61379 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.61231\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 252 | loss: 0.61231 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.61098\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 253 | loss: 0.61098 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.60978\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 254 | loss: 0.60978 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.60869\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 255 | loss: 0.60869 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.60772\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 256 | loss: 0.60772 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.60684\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 257 | loss: 0.60684 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.60605\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 258 | loss: 0.60605 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.60534\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 259 | loss: 0.60534 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.60469\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 260 | loss: 0.60469 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.60412\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 261 | loss: 0.60412 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.60359\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 262 | loss: 0.60359 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.60312\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 263 | loss: 0.60312 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.60270\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 264 | loss: 0.60270 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.60232\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 265 | loss: 0.60232 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.60197\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 266 | loss: 0.60197 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.60166\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 267 | loss: 0.60166 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.60138\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 268 | loss: 0.60138 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.60113\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 269 | loss: 0.60113 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.60090\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 270 | loss: 0.60090 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.60070\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 271 | loss: 0.60070 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.60051\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 272 | loss: 0.60051 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.60034\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 273 | loss: 0.60034 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.60019\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 274 | loss: 0.60019 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.60005\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 275 | loss: 0.60005 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.59993\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 276 | loss: 0.59993 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.59983\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 277 | loss: 0.59983 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.59973\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 278 | loss: 0.59973 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.59965\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 279 | loss: 0.59965 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.59957\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 280 | loss: 0.59957 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.59950\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 281 | loss: 0.59950 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.59943\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 282 | loss: 0.59943 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.59937\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 283 | loss: 0.59937 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.62267\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 284 | loss: 0.62267 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.62029\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 285 | loss: 0.62029 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.61815\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 286 | loss: 0.61815 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.61622\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 287 | loss: 0.61622 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.61448\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 288 | loss: 0.61448 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.61292\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 289 | loss: 0.61292 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.61151\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 290 | loss: 0.61151 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.61024\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 291 | loss: 0.61024 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.60910\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 292 | loss: 0.60910 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.60807\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 293 | loss: 0.60807 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.60715\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 294 | loss: 0.60715 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.60631\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 295 | loss: 0.60631 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.60556\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 296 | loss: 0.60556 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.60488\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 297 | loss: 0.60488 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.60427\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 298 | loss: 0.60427 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.60373\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 299 | loss: 0.60373 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.60323\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 300 | loss: 0.60323 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.60278\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 301 | loss: 0.60278 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.60238\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 302 | loss: 0.60238 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.60202\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 303 | loss: 0.60202 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.60170\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 304 | loss: 0.60170 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.60140\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 305 | loss: 0.60140 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.60114\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 306 | loss: 0.60114 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.60090\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 307 | loss: 0.60090 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.60068\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 308 | loss: 0.60068 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.60049\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 309 | loss: 0.60049 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.60031\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 310 | loss: 0.60031 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.60015\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 311 | loss: 0.60015 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.60001\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 312 | loss: 0.60001 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.59988\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 313 | loss: 0.59988 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.59977\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 314 | loss: 0.59977 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.59966\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 315 | loss: 0.59966 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.59957\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 316 | loss: 0.59957 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.59948\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 317 | loss: 0.59948 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.59941\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 318 | loss: 0.59941 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.59935\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 319 | loss: 0.59935 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.59929\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 320 | loss: 0.59929 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.59924\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 321 | loss: 0.59924 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.59919\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 322 | loss: 0.59919 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.59914\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 323 | loss: 0.59914 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.59910\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 324 | loss: 0.59910 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.59907\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 325 | loss: 0.59907 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.59903\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 326 | loss: 0.59903 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.59901\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 327 | loss: 0.59901 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.59898\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 328 | loss: 0.59898 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.59896\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 329 | loss: 0.59896 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.59894\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 330 | loss: 0.59894 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.59892\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 331 | loss: 0.59892 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.59890\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 332 | loss: 0.59890 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.59888\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 333 | loss: 0.59888 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.59887\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 334 | loss: 0.59887 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.59885\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 335 | loss: 0.59885 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.59884\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 336 | loss: 0.59884 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.59883\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 337 | loss: 0.59883 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.59881\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 338 | loss: 0.59881 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.59880\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 339 | loss: 0.59880 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.59879\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 340 | loss: 0.59879 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.59878\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 341 | loss: 0.59878 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.59877\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 342 | loss: 0.59877 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.59876\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 343 | loss: 0.59876 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.59875\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 344 | loss: 0.59875 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.59874\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 345 | loss: 0.59874 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.59874\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 346 | loss: 0.59874 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.59873\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 347 | loss: 0.59873 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.59872\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 348 | loss: 0.59872 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.59871\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 349 | loss: 0.59871 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.59871\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 350 | loss: 0.59871 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.59870\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 351 | loss: 0.59870 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.59870\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 352 | loss: 0.59870 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.59869\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 353 | loss: 0.59869 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.59869\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 354 | loss: 0.59869 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.59868\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 355 | loss: 0.59868 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.59868\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 356 | loss: 0.59868 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.59867\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 357 | loss: 0.59867 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.59867\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 358 | loss: 0.59867 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.59866\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 359 | loss: 0.59866 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.59866\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 360 | loss: 0.59866 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.59865\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 361 | loss: 0.59865 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.59865\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 362 | loss: 0.59865 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.59865\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 363 | loss: 0.59865 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.59864\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 364 | loss: 0.59864 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.59864\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 365 | loss: 0.59864 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.59864\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 366 | loss: 0.59864 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.59863\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 367 | loss: 0.59863 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.59863\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 368 | loss: 0.59863 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.59863\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 369 | loss: 0.59863 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.59862\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 370 | loss: 0.59862 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.59862\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 371 | loss: 0.59862 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.59862\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 372 | loss: 0.59862 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.59861\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 373 | loss: 0.59861 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.59861\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 374 | loss: 0.59861 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.59861\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 375 | loss: 0.59861 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.59861\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 376 | loss: 0.59861 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.59860\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 377 | loss: 0.59860 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.59860\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 378 | loss: 0.59860 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.59860\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 379 | loss: 0.59860 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.59860\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 380 | loss: 0.59860 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.59859\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 381 | loss: 0.59859 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.59859\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 382 | loss: 0.59859 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.59859\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 383 | loss: 0.59859 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.59859\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 384 | loss: 0.59859 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.59858\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 385 | loss: 0.59858 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.59858\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 386 | loss: 0.59858 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.59858\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 387 | loss: 0.59858 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.59858\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 388 | loss: 0.59858 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.59858\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 389 | loss: 0.59858 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 390 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 391 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 392 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 393 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 394 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.59856\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 395 | loss: 0.59856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 396 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 397 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 398 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 399 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 400 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 401 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 402 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 403 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 404 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.59856\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 405 | loss: 0.59856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.59856\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 406 | loss: 0.59856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.59856\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 407 | loss: 0.59856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.59856\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 408 | loss: 0.59856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.59856\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 409 | loss: 0.59856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.59856\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 410 | loss: 0.59856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.59856\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 411 | loss: 0.59856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.59855\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 412 | loss: 0.59855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.59855\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 413 | loss: 0.59855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.59855\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 414 | loss: 0.59855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.59855\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 415 | loss: 0.59855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.59855\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 416 | loss: 0.59855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.59855\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 417 | loss: 0.59855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.59854\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 418 | loss: 0.59854 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.59854\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 419 | loss: 0.59854 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.59979\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 420 | loss: 0.59979 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.59966\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 421 | loss: 0.59966 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.59955\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 422 | loss: 0.59955 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.59944\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 423 | loss: 0.59944 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.59935\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 424 | loss: 0.59935 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.59926\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 425 | loss: 0.59926 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.59919\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 426 | loss: 0.59919 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.59912\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 427 | loss: 0.59912 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.59906\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 428 | loss: 0.59906 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.59900\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 429 | loss: 0.59900 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.59895\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 430 | loss: 0.59895 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.59890\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 431 | loss: 0.59890 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.59886\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 432 | loss: 0.59886 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.59882\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 433 | loss: 0.59882 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.59879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 434 | loss: 0.59879 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.59876\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 435 | loss: 0.59876 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.59873\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 436 | loss: 0.59873 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.59871\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 437 | loss: 0.59871 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.59869\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 438 | loss: 0.59869 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.59866\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 439 | loss: 0.59866 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.59865\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 440 | loss: 0.59865 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.59863\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 441 | loss: 0.59863 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.59861\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 442 | loss: 0.59861 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.59860\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 443 | loss: 0.59860 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.59859\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 444 | loss: 0.59859 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.59858\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 445 | loss: 0.59858 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 446 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.59856\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 447 | loss: 0.59856 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.59855\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 448 | loss: 0.59855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.59854\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 449 | loss: 0.59854 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.59853\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 450 | loss: 0.59853 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.59853\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 451 | loss: 0.59853 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.59852\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 452 | loss: 0.59852 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.59851\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 453 | loss: 0.59851 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.59851\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 454 | loss: 0.59851 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.59850\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 455 | loss: 0.59850 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.59850\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 456 | loss: 0.59850 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.59850\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 457 | loss: 0.59850 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.59849\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 458 | loss: 0.59849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.59849\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 459 | loss: 0.59849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.59849\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 460 | loss: 0.59849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.59848\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 461 | loss: 0.59848 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.59848\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 462 | loss: 0.59848 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.59848\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 463 | loss: 0.59848 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 464 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 465 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 466 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 467 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 468 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.59846\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 469 | loss: 0.59846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.59846\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 470 | loss: 0.59846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.59846\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 471 | loss: 0.59846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.59846\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 472 | loss: 0.59846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.59846\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 473 | loss: 0.59846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.59846\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 474 | loss: 0.59846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 475 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 476 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 477 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 478 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 479 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 480 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 481 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 482 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 483 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 484 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 485 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 486 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 487 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 488 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 489 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 490 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 491 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 492 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 493 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 494 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 495 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 496 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 497 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 498 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 499 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 500 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 501 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 502 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 503 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 504 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 505 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 506 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 507 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 508 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 509 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 510 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 511 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 512 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 513 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 514 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 515 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 516 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 517 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 518 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 519 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 520 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 521 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 522 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 523 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 524 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 525 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 526 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 527 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 528 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 529 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 530 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 531 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 532 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 533 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 534 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 535 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 536 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 537 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.59944\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 538 | loss: 0.59944 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.59934\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 539 | loss: 0.59934 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.59924\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 540 | loss: 0.59924 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.59916\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 541 | loss: 0.59916 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.59908\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 542 | loss: 0.59908 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.59901\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 543 | loss: 0.59901 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.59895\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 544 | loss: 0.59895 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.59890\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 545 | loss: 0.59890 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.59885\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 546 | loss: 0.59885 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.59880\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 547 | loss: 0.59880 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.59876\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 548 | loss: 0.59876 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.59872\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 549 | loss: 0.59872 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.59869\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 550 | loss: 0.59869 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.59866\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 551 | loss: 0.59866 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.59863\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 552 | loss: 0.59863 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.59861\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 553 | loss: 0.59861 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.59859\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 554 | loss: 0.59859 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 555 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.59855\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 556 | loss: 0.59855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.59853\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 557 | loss: 0.59853 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.59852\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 558 | loss: 0.59852 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.59850\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 559 | loss: 0.59850 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.59849\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 560 | loss: 0.59849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.59848\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 561 | loss: 0.59848 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 562 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.59846\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 563 | loss: 0.59846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 564 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 565 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 566 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 567 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 568 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 569 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 570 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.59841\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 571 | loss: 0.59841 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.59841\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 572 | loss: 0.59841 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.59841\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 573 | loss: 0.59841 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.59840\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 574 | loss: 0.59840 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.59840\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 575 | loss: 0.59840 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.59840\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 576 | loss: 0.59840 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.59840\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 577 | loss: 0.59840 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 578 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 579 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 580 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 581 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 582 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 583 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 584 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 585 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 586 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 587 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 588 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 589 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 590 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 591 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 592 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 593 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 594 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 595 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 596 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 597 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 598 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 599 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 600 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 601 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 602 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 603 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 604 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 605 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 606 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 607 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 608 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 609 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 610 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 611 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 612 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 613 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 614 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 615 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 616 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 617 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 618 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 619 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 620 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 621 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 622 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 623 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 624 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 625 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 626 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 627 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 628 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 629 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 630 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 631 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 632 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 633 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 634 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 635 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 636 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 637 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 638 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 639 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 640 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 641 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 642 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 643 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 644 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 645 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 646 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 647 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 648 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 649 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 650 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 651 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 652 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 653 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 654 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 655 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 656 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 657 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 658 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 659 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 660 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 661 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 662 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 663 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 664 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 665 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 666 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 667 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 668 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 669 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 670 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 671 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 672 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 673 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 674 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 675 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 676 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 677 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 678 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 679 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 680 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 681 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 682 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 683 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 684 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 685 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 686 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 687 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 688 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 689 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 690 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 691 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 692 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 693 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 694 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 695 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 696 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 697 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 698 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 699 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 700 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 701 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 702 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 703 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 704 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 705 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.59918\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 706 | loss: 0.59918 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.59910\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 707 | loss: 0.59910 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.59902\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 708 | loss: 0.59902 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.59895\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 709 | loss: 0.59895 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.59889\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 710 | loss: 0.59889 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.59883\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 711 | loss: 0.59883 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.59878\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 712 | loss: 0.59878 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.59874\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 713 | loss: 0.59874 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.59870\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 714 | loss: 0.59870 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.59866\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 715 | loss: 0.59866 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.59863\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 716 | loss: 0.59863 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.59860\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 717 | loss: 0.59860 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 718 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.59855\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 719 | loss: 0.59855 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.59852\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 720 | loss: 0.59852 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.59850\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 721 | loss: 0.59850 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.59849\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 722 | loss: 0.59849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 723 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.59846\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 724 | loss: 0.59846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 725 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 726 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 727 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.59841\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 728 | loss: 0.59841 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.59840\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 729 | loss: 0.59840 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 730 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 731 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 732 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 733 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 734 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 735 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 736 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 737 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 738 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 739 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 740 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 741 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 742 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 743 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 744 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 745 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 746 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 747 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 748 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 749 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 750 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 751 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 752 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 753 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 754 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 755 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 756 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 757 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 758 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 759 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 760 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 761 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 762 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 763 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 764 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 765 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 766 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 767 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 768 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 769 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 770 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 771 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 772 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 773 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 774 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 775 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 776 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 777 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 778 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 779 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 780 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 781 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 782 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 783 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 784 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 785 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 786 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 787 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 788 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 789 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 790 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 791 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 792 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 793 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 794 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 795 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 796 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 797 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 798 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 799 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 800 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 801 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 802 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 803 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 804 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 805 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 806 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 807 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 808 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 809 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 810 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 811 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 812 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 813 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 814 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 815 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 816 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 817 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 818 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 819 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 820 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 821 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 822 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 823 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 824 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 825 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 826 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 827 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 828 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 829 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 830 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 831 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m0.62328\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 832 | loss: 0.62328 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m0.62078\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 833 | loss: 0.62078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m0.61854\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 834 | loss: 0.61854 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m0.61651\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 835 | loss: 0.61651 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m0.61469\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 836 | loss: 0.61469 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m0.61305\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 837 | loss: 0.61305 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m0.61158\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 838 | loss: 0.61158 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m0.61025\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 839 | loss: 0.61025 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m0.60905\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 840 | loss: 0.60905 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m0.60701\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 841 | loss: 0.60701 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m0.60701\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 842 | loss: 0.60701 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m0.60614\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 843 | loss: 0.60614 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m0.60535\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 844 | loss: 0.60535 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m0.60465\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 845 | loss: 0.60465 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m0.60401\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 846 | loss: 0.60401 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m0.60344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 847 | loss: 0.60344 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m0.60293\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 848 | loss: 0.60293 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m0.60246\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 849 | loss: 0.60246 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m0.60205\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 850 | loss: 0.60205 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m0.60167\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 851 | loss: 0.60167 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m0.60133\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 852 | loss: 0.60133 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m0.60103\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 853 | loss: 0.60103 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m0.60076\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 854 | loss: 0.60076 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m0.60051\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 855 | loss: 0.60051 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m0.60029\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 856 | loss: 0.60029 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m0.60009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 857 | loss: 0.60009 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m0.59991\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 858 | loss: 0.59991 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m0.59975\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 859 | loss: 0.59975 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.59960\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 860 | loss: 0.59960 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.59947\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 861 | loss: 0.59947 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.59935\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 862 | loss: 0.59935 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.59925\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 863 | loss: 0.59925 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m0.62414\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 864 | loss: 0.62414 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m0.62155\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 865 | loss: 0.62155 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m0.61922\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 866 | loss: 0.61922 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.61713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 867 | loss: 0.61713 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.61525\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 868 | loss: 0.61525 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.61355\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 869 | loss: 0.61355 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m0.61203\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 870 | loss: 0.61203 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m0.61065\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 871 | loss: 0.61065 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m0.60942\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 872 | loss: 0.60942 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m0.60830\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 873 | loss: 0.60830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m0.63229\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 874 | loss: 0.63229 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m0.62889\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 875 | loss: 0.62889 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m0.62583\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 876 | loss: 0.62583 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m0.62307\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 877 | loss: 0.62307 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m0.62059\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 878 | loss: 0.62059 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m0.61836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 879 | loss: 0.61836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m0.61636\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 880 | loss: 0.61636 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m0.61455\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 881 | loss: 0.61455 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m0.61292\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 882 | loss: 0.61292 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m0.61146\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 883 | loss: 0.61146 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m0.63513\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 884 | loss: 0.63513 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m0.63144\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 885 | loss: 0.63144 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m0.62813\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 886 | loss: 0.62813 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m0.62514\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 887 | loss: 0.62514 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m0.62246\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 888 | loss: 0.62246 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m0.62004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 889 | loss: 0.62004 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m0.61787\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 890 | loss: 0.61787 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m0.61591\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 891 | loss: 0.61591 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m0.63840\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 892 | loss: 0.63840 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m0.63439\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 893 | loss: 0.63439 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m0.63078\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 894 | loss: 0.63078 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m0.62753\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 895 | loss: 0.62753 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m0.62461\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 896 | loss: 0.62461 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m0.62197\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 897 | loss: 0.62197 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m0.61961\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 898 | loss: 0.61961 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m0.61747\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 899 | loss: 0.61747 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m0.61556\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 900 | loss: 0.61556 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m0.61383\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 901 | loss: 0.61383 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m0.61228\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 902 | loss: 0.61228 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m0.61088\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 903 | loss: 0.61088 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m0.60962\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 904 | loss: 0.60962 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m0.60849\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 905 | loss: 0.60849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m0.60747\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 906 | loss: 0.60747 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m0.60655\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 907 | loss: 0.60655 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m0.60572\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 908 | loss: 0.60572 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m0.60498\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 909 | loss: 0.60498 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m0.60431\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 910 | loss: 0.60431 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m0.60371\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 911 | loss: 0.60371 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m0.60317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 912 | loss: 0.60317 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.60268\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 913 | loss: 0.60268 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.60224\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 914 | loss: 0.60224 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.60184\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 915 | loss: 0.60184 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m0.60149\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 916 | loss: 0.60149 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m0.60117\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 917 | loss: 0.60117 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m0.60088\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 918 | loss: 0.60088 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m0.60062\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 919 | loss: 0.60062 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m0.60039\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 920 | loss: 0.60039 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m0.60018\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 921 | loss: 0.60018 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m0.59999\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 922 | loss: 0.59999 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m0.59982\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 923 | loss: 0.59982 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m0.59966\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 924 | loss: 0.59966 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m0.59953\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 925 | loss: 0.59953 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m0.59940\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 926 | loss: 0.59940 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m0.59929\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 927 | loss: 0.59929 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m0.59919\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 928 | loss: 0.59919 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m0.59910\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 929 | loss: 0.59910 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m0.59902\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 930 | loss: 0.59902 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m0.59895\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 931 | loss: 0.59895 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m0.59888\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 932 | loss: 0.59888 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m0.59882\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 933 | loss: 0.59882 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m0.59877\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 934 | loss: 0.59877 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m0.59872\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 935 | loss: 0.59872 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m0.59867\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 936 | loss: 0.59867 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.59864\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 937 | loss: 0.59864 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m0.59860\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 938 | loss: 0.59860 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 939 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m0.59854\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 940 | loss: 0.59854 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m0.59852\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 941 | loss: 0.59852 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m0.59849\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 942 | loss: 0.59849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 943 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m0.59846\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 944 | loss: 0.59846 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m0.59844\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 945 | loss: 0.59844 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 946 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m0.59841\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 947 | loss: 0.59841 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m0.59840\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 948 | loss: 0.59840 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 949 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 950 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 951 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 952 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 953 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 954 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 955 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 956 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 957 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m0.59833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 958 | loss: 0.59833 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 959 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.59832\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 960 | loss: 0.59832 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 961 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 962 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 963 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m0.59831\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 964 | loss: 0.59831 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 965 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 966 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m0.59830\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 967 | loss: 0.59830 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m0.59902\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 968 | loss: 0.59902 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m0.59895\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 969 | loss: 0.59895 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m0.59888\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 970 | loss: 0.59888 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m0.59882\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 971 | loss: 0.59882 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m0.59877\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 972 | loss: 0.59877 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m0.59872\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 973 | loss: 0.59872 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m0.59867\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 974 | loss: 0.59867 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m0.59863\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 975 | loss: 0.59863 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m0.59860\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 976 | loss: 0.59860 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m0.59857\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 977 | loss: 0.59857 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m0.59854\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 978 | loss: 0.59854 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m0.59851\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 979 | loss: 0.59851 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m0.59849\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 980 | loss: 0.59849 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m0.59847\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 981 | loss: 0.59847 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m0.59845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 982 | loss: 0.59845 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m0.59843\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 983 | loss: 0.59843 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m0.59842\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 984 | loss: 0.59842 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m0.59840\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 985 | loss: 0.59840 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m0.59839\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 986 | loss: 0.59839 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m0.59838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 987 | loss: 0.59838 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m0.59837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 988 | loss: 0.59837 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m0.59836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 989 | loss: 0.59836 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m0.59835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 990 | loss: 0.59835 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m0.59834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 991 | loss: 0.59834 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m0.62263\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 992 | loss: 0.62263 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m0.62020\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 993 | loss: 0.62020 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m0.61800\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 994 | loss: 0.61800 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m0.61603\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 995 | loss: 0.61603 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m0.61426\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 996 | loss: 0.61426 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m0.61266\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 997 | loss: 0.61266 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m0.61122\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 998 | loss: 0.61122 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m0.60993\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 999 | loss: 0.60993 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.60876\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1000 | loss: 0.60876 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Final Updated Weights: [[-2.7882712]\n",
      " [ 4.0761952]]\n",
      "Expected:  [False, True, True, False]\n",
      "Predicted:  [False, True, False, False]\n",
      "Efficiency: 75.00%\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "Y = [[0], [1], [1], [0]]\n",
    "\n",
    "# Define the network architecture\n",
    "input_layer = input_data(shape=[None, 2])\n",
    "hidden_layer = fully_connected(input_layer, 2, activation='relu')  # Changed activation function to ReLU\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='sigmoid')  # Output layer remains sigmoid\n",
    "\n",
    "# Define the regression layer using the output layer\n",
    "regression_layer = regression(output_layer, optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
    "\n",
    "# Create the model using the regression layer\n",
    "model = tflearn.DNN(regression_layer)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, n_epoch=1000, show_metric=True)\n",
    "# Get the final updated weights of the model\n",
    "final_weights = model.get_weights(output_layer.W)\n",
    "print(\"Final Updated Weights:\", final_weights)\n",
    "# Predict the output\n",
    "predicted = model.predict(X)\n",
    "predicted_classes = [i[0] > 0.5 for i in predicted]  # Use 0.5 as the threshold for sigmoid\n",
    "\n",
    "# Convert Y to list of bool values\n",
    "expected_classes = [i[0] > 0.5 for i in Y]  # Use 0.5 as the threshold for sigmoid\n",
    "\n",
    "# Compare and calculate efficiency\n",
    "correct_predictions = sum(1 for expected, predicted in zip(expected_classes, predicted_classes) if expected == predicted)\n",
    "total_predictions = len(expected_classes)\n",
    "efficiency = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "print(\"Expected: \", expected_classes)\n",
    "print(\"Predicted: \", predicted_classes)\n",
    "print(\"Efficiency: {:.2f}%\".format(efficiency))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c6b3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
